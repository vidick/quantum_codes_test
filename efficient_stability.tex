  \documentclass[11pt]{article}
\usepackage{booktabs}
\usepackage{fullpage}
\usepackage{titlesec}
%\newcommand{\sectionbreak}{\clearpage}
\usepackage{amsmath,amsfonts,amsthm,mathrsfs,xspace,graphicx}
\usepackage[backref,colorlinks,citecolor=blue,bookmarks=true]{hyperref}
\usepackage{mathpazo}
\usepackage{nicefrac}
\usepackage{endnotes}
\usepackage{color}
\usepackage{float}
\usepackage{xcolor}
\usepackage{mdframed}
\usepackage{bbm}
\usepackage{suffix} % for *-version commands
\usepackage{times}
\usepackage{tabularx}
\usepackage{makecell}
\usepackage{amssymb,latexsym}
%\usepackage{IEEEtrantools}
\usepackage[capitalize]{cleveref}
\usepackage{enumitem}
\usepackage{tikz}
\usepackage{tikz-cd}
\usepackage{multirow}
\usepackage[section]{placeins}
\usepackage[affil-it]{authblk}
\usepackage{comment}

\mdfdefinestyle{figstyle}{ %
  linecolor=black!7, %
  backgroundcolor=black!7, %
  innertopmargin=10pt, %
  innerleftmargin=25pt, %
  innerrightmargin=25pt, %
  innerbottommargin=10pt %
}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{theorem*}{Theorem}

\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{conjecture}[theorem]{Conjecture}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{claim}[theorem]{Claim}
\newtheorem{fact}[theorem]{Fact}
\newtheorem{corollary}[theorem]{Corollary}

\newtheorem{remark}[theorem]{Remark}

\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}

\newcommand{\beq}{\begin{eqnarray}}
\newcommand{\eeq}{\end{eqnarray}}

\newcommand{\code}{\mathscr{C}}
\newcommand{\strategy}{\mathscr{S}}
\newcommand{\algebra}{\mathscr{A}}

\newcommand{\ket}[1]{|#1\rangle}
\newcommand{\bra}[1]{\langle#1|}
\newcommand{\ketbra}[2]{\ket{#1}\!\bra{#2}}
\newcommand{\ip}[2]{\langle #1 \! | #2 \rangle}
\newcommand{\proj}[1]{\ket{#1}\!\bra{#1}}
\newcommand{\Tr}{\mbox{\rm Tr}}
\newcommand{\Id}{\ensuremath{I}}
\DeclareMathOperator*{\Expectation}{\mathbb{E}}
\newcommand{\Es}[1]{\Expectation_{#1}}

\newcommand{\reg}[1]{{\textsf{#1}}}
\newcommand{\ol}[1]{\overline{#1}}

\newcommand{\field}{\mathbb{F}_2}
\newcommand{\C}{\ensuremath{\mathbb{C}}}
\newcommand{\N}{\ensuremath{\mathbb{N}}}
\newcommand{\bbN}{\ensuremath{\mathbb{N}}}
\newcommand{\complex}{\ensuremath{\mathbb{C}}}
\newcommand{\real}{\ensuremath{\mathbb{R}}}
%\newcommand{\natural}{\ensuremath{\mathbb{N}}}

\newcommand{\bij}{\pi}
\newcommand{\qp}{\tau}
\newcommand{\dlS}{\ensuremath{\rm dlS}}

\newcommand{\F}{\ensuremath{\mathbb{F}}}
\newcommand{\M}{\ensuremath{\mathbb{M}}}
\newcommand{\ot}{\otimes}
\newcommand{\Fp}{\F_p}
\newcommand{\Fq}{\field}
\newcommand{\BH}{\textsc{BH}}
\newcommand{\ld}{\textsc{ld}}
\newcommand{\com}{\textsc{com}}
\newcommand{\sq}{\textsc{sq}}
\newcommand{\downsize}{\kappa}
\newcommand{\tobin}{\flat}
\newcommand{\downsizem}{\chi}

\newcommand{\K}{\ensuremath{\mathbb{K}}}
\newcommand{\R}{\ensuremath{\mathbb{R}}}
\newcommand{\Z}{\ensuremath{\mathbb{Z}}}

\newcommand{\mA}{\ensuremath{\mathcal{A}}}
\newcommand{\mB}{\ensuremath{\mathcal{B}}}
\newcommand{\mC}{\ensuremath{\mathcal{C}}}
\newcommand{\mE}{\ensuremath{\mathcal{E}}}
\newcommand{\mD}{\ensuremath{\mathcal{D}}}
\newcommand{\mF}{\ensuremath{\mathcal{F}}}
\newcommand{\mG}{\ensuremath{\mathcal{G}}}
\newcommand{\mH}{\ensuremath{\mathcal{H}}}
\newcommand{\mK}{\ensuremath{\mathcal{K}}}
\newcommand{\mM}{\ensuremath{\mathcal{M}}}
\newcommand{\mI}{\ensuremath{\mathcal{I}}}
\newcommand{\mJ}{\ensuremath{\mathcal{J}}}
\newcommand{\cM}{\ensuremath{\mathcal{M}}}
\newcommand{\mP}{\ensuremath{\mathcal{P}}}
\newcommand{\mQ}{\ensuremath{\mathcal{Q}}}
\newcommand{\mR}{\ensuremath{\mathcal{R}}}
\newcommand{\mS}{\ensuremath{\mathcal{S}}}
\newcommand{\mT}{\ensuremath{\mathcal{T}}}
\newcommand{\mU}{\ensuremath{\mathcal{U}}}
\newcommand{\mX}{\ensuremath{\mathcal{X}}}
\newcommand{\mY}{\ensuremath{\mathcal{Y}}}

\newcommand{\Inv}{\ensuremath{\textsc{Inv}}}
\newcommand{\GEN}{\ensuremath{\textsc{GEN}}}
\newcommand{\SAMP}{\ensuremath{\textsc{SAMP}}}
\newcommand{\epr}{\ensuremath{\textsc{epr}}}
\newcommand{\RM}{\ensuremath{\textsc{RM}}}
\newcommand{\RS}{\ensuremath{\textsc{RS}}}
\newcommand{\bRM}{\ensuremath{\textsc{RM2}}}
\newcommand{\Had}{\ensuremath{\textsc{Had}}}
\newcommand{\HRM}{\ensuremath{\textsc{HRM}}}


\newcommand{\Alg}{\mathcal{A}}
\newcommand{\ind}{\ensuremath{\mathrm{ind}}}
\newcommand{\cc}{\mathrm{com}}
\newcommand{\ac}{\mathrm{ac}}

\newcommand{\setft}[1]{\mathrm{#1}}
\newcommand{\Density}{\setft{D}}
\newcommand{\Pos}{\setft{Pos}}
\newcommand{\Proj}{\setft{Proj}}
\newcommand{\Channel}{\setft{C}}
\newcommand{\Unitary}{\setft{U}}
\newcommand{\Herm}{\setft{Herm}}
\newcommand{\Obs}{\setft{Obs}}
\newcommand{\Lin}{\setft{L}}
\newcommand{\Trans}{\setft{T}}
\DeclareMathOperator{\poly}{poly}
\DeclareMathOperator{\negl}{negl}
\newcommand{\dset}{G}

\newcommand{\val}{\ensuremath{\mathrm{val}}}
\newcommand{\valco}{\ensuremath{\mathrm{val}^{\mathrm{co}}}}
\newcommand{\ia}{\Id_\alice}
\newcommand{\ib}{\Id_\bob}

\newcommand{\desc}[1]{\overline{\cal{#1}}}
\newcommand{\supp}{\textsc{Supp}}
\newcommand{\Gen}{\textsc{Gen}}
\newcommand{\Enc}{\textsc{Enc}}
\newcommand{\Dec}{\textsc{Dec}}

\newcommand{\GenTrap}{\textsc{GenTrap}}
\newcommand{\Invert}{\textsc{Invert}}
\newcommand{\lossy}{\textsc{lossy}}

\newcommand{\rand}{\textrm{rand}}
\newcommand{\had}{\textsc{Had}}


\newcommand{\eps}{\varepsilon}
\newcommand{\ph}{\ensuremath{\varphi}}


%\newcommand{\ac}{\textsc{ac}}
\newcommand{\GX}{\textsc{Gap-Maxcut}}
\newcommand{\GNI}{\textsc{Graph Non-Isomorphism}}


\newcommand{\Acc}{\textsc{Acc}}
\newcommand{\Samp}{\textsc{Samp}}
\newcommand{\Ext}{\ensuremath{\text{Ext}}}

\newcommand{\BD}{\mathbb{QB}}
\newcommand{\DD}{\mathbb{D}}
\newcommand{\DDb}{\mathbb{D'}}
\newcommand{\Pot}{\Phi}
\newcommand{\inj}{J}
\newcommand{\mZ}{\mathcal{Z}}
\newcommand{\mN}{\mathcal{N}}
\newcommand{\vs}{\vspace{2mm}~\newline\noindent}
\newcommand{\vb}{\vspace{3mm}\noindent}
\newcommand{\sX}{\mathcal{X}}
\newcommand{\sA}{\mathcal{A}}
\newcommand{\sB}{\mathcal{B}}
\newcommand{\sY}{\mathcal{Y}}
\newcommand{\sR}{\mathcal{R}}


\newcommand{\trnq}[1]{\left[ {#1} \right]_q}

\DeclareMathOperator{\polylog}{polylog}
\newcommand{\mx}[1]{\mathbf{{#1}}}
\newcommand{\vc}[1]{\mathbf{{#1}}}
\newcommand{\abs}[1]{\left\vert {#1} \right\vert}
\newcommand{\norm}[1]{\left\| {#1} \right\|}
\newcommand{\for}{\text{for }}

\DeclareMathOperator{\arcsinh}{arcsinh}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\sgn}{sgn}
%\newcommand{\dlS}{\ensuremath{\rm dlS}}


\newcommand{\E}{\mathop{\mathbb{E}}\displaylimits} % Expectation

\newcommand{\unif}{\mathcal{U}}
\newcommand{\pt}{\textrm{pt}}
\newcommand{\sample}{\textrm{sample}}
\newcommand{\test}{\textrm{test}}
\newcommand{\free}{\mathcal{F}}
\newcommand{\plane}{\mathcal{P}}
\newcommand{\lines}{\mathcal{L}}
\newcommand{\clines}{\mathcal{CL}}
\newcommand{\pl}{\mathbf{p}}
\newcommand{\individual}{\textrm{individual}}
\newcommand{\blocks}{\textrm{blocks}}
\newcommand{\liness}{\textrm{lines}}
\newcommand{\lp}{\mathcal{LP}}
\newcommand{\Pl}{\ensuremath{\mathrm{Pl}}}
\newcommand{\Ln}{\ensuremath{\mathrm{Lines}}}
\newcommand{\mode}{\mathfrak{m}}
\newcommand{\ECC}{\ensuremath{\textsc{ECC}}}
\newcommand{\EC}{\ensuremath{\textsc{EC}}}
\newcommand{\ENC}{\ensuremath{\textsc{ENC}}}
\newcommand{\cktval}{\ensuremath{\textsc{CKTVAL}}}

\newcommand{\eq}{\mathrm{eq}}
\newcommand{\var}{\mathrm{var}}

\newcommand{\GL}{\mathrm{GL}}
\newcommand{\Matrix}{\mathrm{M}}
\newcommand{\End}{\mathrm{End}}
\newcommand{\Aut}{\mathrm{Aut}}

\newcommand{\game}{\mathfrak{G}}
\newcommand{\sampler}{\mathcal{S}}
\newcommand{\decider}{\mathcal{D}}
\newcommand{\verifier}{\mathcal{V}}


\newcommand{\type}{\mathcal{T}}
\newcommand{\lt}{\mathcal{L}}
\newcommand{\rt}{\mathcal{R}}
\newcommand{\checker}{\mathcal{C}}


\newcommand{\gamestyle}[1]{\ensuremath{\textsc{#1}}\xspace}
\newcommand{\qld}{\gamestyle{QLD}}
\newcommand{\ms}{\gamestyle{MS}}
\newcommand{\pauli}{\gamestyle{P}}
%\newcommand{\bp}{\gamestyle{BP}}
\newcommand{\ora}{\gamestyle{Orac}}
\newcommand{\pcp}{\gamestyle{PCP}}
\newcommand{\ar}{\gamestyle{AR}}
\newcommand{\intro}{\gamestyle{Intro}}

\newcommand{\labelstyle}[1]{\ensuremath{\textsc{#1}}\xspace}
\newcommand{\EPR}{\labelstyle{EPR}}
\newcommand{\aux}{\labelstyle{aux}}
\newcommand{\ancilla}{\labelstyle{anc}}
\newcommand{\msc}{\labelstyle{MC}}
\newcommand{\msv}{\labelstyle{MV}}
\newcommand{\vertex}[1]{\labelstyle{V#1}}
\newcommand{\edge}[1]{\labelstyle{N#1}}
\newcommand{\basis}{\labelstyle{W}}
\newcommand{\xpt}{\labelstyle{X}}
\newcommand{\zpt}{\labelstyle{Z}}
\newcommand{\rxpt}{\labelstyle{R}_\xpt}
\newcommand{\rzpt}{\labelstyle{R}_\zpt}
\newcommand{\dir}[1]{\labelstyle{V#1}}
\newcommand{\coord}{\labelstyle{I}}
\newcommand{\intercept}{\labelstyle{U}}
\newcommand{\plf}{\labelstyle{Pl}}
\newcommand{\lnf}{\labelstyle{Ln}}
\newcommand{\ptf}{\labelstyle{Pt}}
\newcommand{\full}{\labelstyle{full}}
\newcommand{\opt}{\labelstyle{opt}}
\newcommand{\partition}{\mathcal{B}}

\newcommand{\tvarstyle}[1]{\mathsf{#1}}
\newcommand{\tvar}{\ensuremath{\tvarstyle{t}}}
\newcommand{\lvar}{\ensuremath{\tvarstyle{u}}}
\newcommand{\rvar}{\ensuremath{\tvarstyle{v}}}
\newcommand{\pvar}{\ensuremath{\tvarstyle{p}}}
\newcommand{\ovar}{\ensuremath{\tvarstyle{o}}}
\newcommand{\trole}{\ensuremath{v}} % used in intro types

\newcommand{\types}{\labelstyle{T}}

\newcommand{\decode}{\labelstyle{Decode}}

%\newcommand{\alice}{\labelstyle{Alice}}
%\newcommand{\bob}{\labelstyle{Bob}}
\newcommand{\alice}{\labelstyle{A}}
\newcommand{\bob}{\labelstyle{B}}

\newcommand{\oracle}{\labelstyle{Oracle}}
\newcommand{\ab}{\{\alice, \bob\}}

\newcommand{\typestyle}[1]{\ensuremath{\textsc{#1}}\xspace}
\newcommand{\Type}{\typestyle{Type}}
\newcommand{\Plane}{\typestyle{Plane}}
\renewcommand{\line}{\mathbf{\ell}}
\newcommand{\Llane}{\typestyle{Line}}
\newcommand{\Point}{\typestyle{Point}}
\newcommand{\HPoint}{\typestyle{HPoint}}
\newcommand{\Line}{\typestyle{Line}}
\newcommand{\ALine}{\typestyle{ALine}}
\newcommand{\DLine}{\typestyle{DLine}}
\newcommand{\Pair}{\typestyle{Pair}}
\newcommand{\Constraint}{\typestyle{Constraint}}
\newcommand{\Variable}{\typestyle{Variable}}
\newcommand{\Pauli}{\typestyle{Pauli}}
\newcommand{\Sample}{\typestyle{Sample}}
\newcommand{\Read}{\typestyle{Read}}
\newcommand{\MeasureX}{\typestyle{MeasureX}}
\newcommand{\Hide}[1]{\typestyle{Hide}_{#1}}
\newcommand{\HideX}[1]{\typestyle{HideX}_{#1}}
\newcommand{\Target}[1]{\typestyle{Target}_{#1}}
\newcommand{\Oracle}{\typestyle{Oracle}}
\newcommand{\Introspect}{\typestyle{Intro}}
\newcommand{\Intro}{\typestyle{Intro}}
\newcommand{\Simple}{\typestyle{Simple}}
\newcommand{\Eval}{\typestyle{Eval}}
\newcommand{\Agg}{\typestyle{Agg}}
\newcommand{\Input}{\typestyle{Input}}
\newcommand{\Skip}{\typestyle{Skip}}
\newcommand{\Alice}{\typestyle{Alice}}
\newcommand{\Bob}{\typestyle{Bob}}
\newcommand{\Edge}{\typestyle{Alice}}
\newcommand{\Vertex}{\typestyle{Bob}}
\newcommand{\Anchor}{\typestyle{Anchor}}
\renewcommand{\Game}{\typestyle{Game}}
\newcommand{\AB}{\{\alice, \bob\}}
\newcommand{\ctrl}{\labelstyle{c}}
\newcommand{\target}{\labelstyle{t}}

\newcommand{\abc}[1][\delta]{\otimes I_\bob \simeq_{#1} I_\alice \otimes}

\newcommand{\ldc}{k} % number of copies of classical ld tests

\newcommand{\class}[1]{\ensuremath{\mathsf{#1}}\xspace}
\newcommand{\NP}{\class{NP}} %
\newcommand{\IP}{\class{IP}} %
\newcommand{\EXP}{\class{EXP}} %
\newcommand{\NEXP}{\class{NEXP}} %
\newcommand{\QMA}{\class{QMA}} %
\newcommand{\QMIP}{\class{QMIP}} %
\WithSuffix\newcommand\QMIP*{\ensuremath{\class{QMIP}^*}} %
\newcommand{\PSPACE}{\class{PSPACE}} %
\newcommand{\PCP}{\class{PCP}} %
\newcommand{\MIP}{\class{MIP}} %
\newcommand{\MIPco}{\class{MIP}^{\mathrm{co}}} %
\newcommand{\RE}{\class{RE}} %
\newcommand{\coRE}{\class{coRE}}
\newcommand{\NEEXP}{\class{NEEXP}} %
\newcommand{\NEEEXP}{\class{NEEEXP}}
\WithSuffix\newcommand\MIP*{\ensuremath{\class{MIP}^*}} %
\newcommand{\QIP}{\class{QIP}} %


\newcommand{\Ent}{\mathscr{E}}
\newcommand{\compr}{\textsc{Compr}}
\newcommand{\halt}{\textsc{Halt}}
\newcommand{\machine}{\cal{M}}
\renewcommand{\cal}[1]{\mathcal{#1}}
\newcommand{\Kleene}{\cal{K}}
\newcommand{\qldparams}{\mathsf{qldparams}}
\mathchardef\mhyphen="2D
\newcommand{\Fqldparams}{\F_2\mhyphen\mathsf{qldparams}}
\newcommand{\introparams}{\mathsf{introparams}}
\newcommand{\ldparams}{\mathsf{ldparams}}
\newcommand{\tmldparams}{\mathsf{tmldparams}}
\newcommand{\pcpparams}{\mathsf{pcpparams}}

\newcommand{\TMtoSAT}{\mathrm{TMtoSAT}}
\newcommand{\TMtoLD}{\mathrm{TMtoLD}}
\newcommand{\BoundedHalting}{\mathrm{BH}}
\newcommand{\timecomplexity}{\mathsf{TIME}}
\newcommand{\TIME}{\mathsf{TIME}}
\newcommand{\answer}{\mathsf{ANS}}
\newcommand{\MS}{\mathrm{MS}}

\newcommand{\accept}{\typestyle{Accept}}
\newcommand{\reject}{\typestyle{Reject}}

\newcommand{\anch}{\gamestyle{Anch}}
\newcommand{\ans}{\gamestyle{ANS}}
%%%%%%%self testing macros%%%%%%%%%%

\newcommand{\local}{\mathrm{local}}
%\newcommand{\aux}{\mathrm{aux}}


\newcommand{\G}{\mG}
\newcommand{\XZ}{\mathcal{B}}
\newcommand{\hilb}{\mathcal{H}}


%\newcommand{\tmstyle}[1]{\ensuremath{\textsf{#1}}}
\newcommand{\tmstyle}[1]{\ensuremath{\mathsf{#1}}}
\newcommand{\Compress}{\tmstyle{Compress}}
\newcommand{\ComputeRepetitions}{\tmstyle{ComputeRepetitions}}
\newcommand{\ComputeSampler}{\tmstyle{ComputeSampler}}
\newcommand{\RawIntroSampler}{\tmstyle{RawIntroSampler}}
\newcommand{\ComputeIntroSampler}{\tmstyle{IntroSampler}}
\newcommand{\RawIntroDecider}{\tmstyle{RawIntroDecider}}
\newcommand{\ComputeIntroDecider}{\tmstyle{IntroDecider}}
\newcommand{\ComputeIntroVerifier}{\tmstyle{IntroVerifier}}
\newcommand{\ComputeOracleVerifier}{\tmstyle{OracleVerifier}}
\newcommand{\ComputeAnsVerifier}{\tmstyle{AnsRedVerifier}}
\newcommand{\ComputeParrepVerifier}{\tmstyle{RepeatedVerifier}}
\newcommand{\ComputePCPVerifier}{\tmstyle{PCPVerifier}}
\newcommand{\ComputeFixedPoint}{\tmstyle{ComputeFixedPoint}}
\newcommand{\detype}{\tmstyle{Detype}}

\newenvironment{gamespec}{
  \begin{mdframed}[style=figstyle]}{
  \end{mdframed}}

\newcommand{\zero}{\mathrm{zero}}

%%%%%%%From NW19:%%%%%%%%%%
\newcommand{\polymeas}[3]{\mathrm{PolyMeas}(#1,#2,#3)}
\newcommand{\simulpolymeas}[4]{\mathrm{PolyMeas}(#1,#2,#3, #4)}

\newcommand{\eval}{\mathrm{eval}}

%\newcommand{\coin}{o}
\newcommand{\succinctdecider}{\ensuremath{\mathsf{SuccinctDecider}}}
\newcommand{\circuit}{\mathcal{C}}
\newcommand{\formula}{\mathcal{F}}
\newcommand{\bin}{\mathrm{binary}}
\newcommand{\pcpeval}{\Xi}
\newcommand{\pcpverifier}{\mathcal{M}_\ar}
\newcommand{\qlen}{Q}
\DeclareMathOperator{\ev}{eval}

\newcommand{\hx}{\hat{x}}
\newcommand{\hz}{\hat{z}}
\newcommand{\htvar}{\hat{\tvar}}
\newcommand{\soundness}{\mathrm{sound}}

\newcommand{\rep}{\gamestyle{Rep}}
\newcommand{\sep}{\gamestyle{Sep}}

\newcommand{\binary}[1]{\mathrm{binary}_{#1}}
\newcommand{\num}[1]{\mathrm{number}_{#1}}
\newcommand{\canbasis}[1]{\mathrm{basis}(#1)}
\newcommand{\canH}[3]{H_{\mathrm{canon}, #1, #2, #3}}
\newcommand{\canlilh}[3]{h_{\mathrm{canon}, #1, #2, #3}}
\newcommand{\canin}[3]{\pi_{\mathrm{canon},#1,#2,#3}}
\newcommand{\canenc}[4]{g_{\mathrm{canon},#1,#2,#3,#4}}


% \usepackage{showlabels}
% \renewcommand{\showlabelfont}{\tiny\ttfamily\color{red}}

\bibliographystyle{alpha}

\newif\ifnotes\notestrue
%\newif\ifnotes\notesfalse

\input{marginnotes}
\begin{document}

\title{Efficiently stable presentations from error-correcting codes}

\author[1]{Michael Chapman}
\author[2]{Thomas Vidick}
\author[3]{Henry Yuen}
\affil[1]{Courant Institute of Mathematical Sciences, 
	New York University, USA}
\affil[2]{ Faculty of Mathematics and Computer Science, Weizmann Institute of Science, Israel}
\affil[3]{Department of Computer Science, Columbia University, USA}

\date{\today}
\maketitle

\noteswarning


\begin{abstract}
\mnote{After reading the abstract a few more times, I agree with Henry. I commented out the things that seemed to me superfluous. Regarding the last remark of "more gen and relations means more stability", I have counter examples of that. So I prefer to not state it, even heuristically, that way}We introduce a notion of \emph{efficient stability} for finite presentations of groups. Informally, a finite presentation using generators $S$ and relations $R$ is \emph{stable} if any map from $S$ to unitaries 
%(say, in some finite von Neumann algebra) 
that approximately satisfies the relations (in the tracial norm) is close to the restriction of a representation of $G$ to the subset $S$. This notion and variants thereof have been extensively studied in recent years, in part motivated by connections to property testing in computer science. The novelty in our work is the focus on \emph{efficiency}, which, informally, places an onus on small presentations --- in the sense of encoding length.  
%(of size, say, logarithmic in the group size)
The goal in this setup is to achieve non-trivial tradeoffs between the presentation length and its modulus of stability.
%---as, intuitively, more generators and relations place more constraints on the approximate homomorphism, making stability easier to achieve---whereas we wish to minimize the number of variables and constraints. 


\mnote{Here I genuinely changed the phrasing. I don't think it is currently very good, but it is better than it was. Feel free to iterate:} Equipped with this tradeoff in mind, we analyze various natural examples of presentations. We provide a general method for constructing presentations of $\Z_2^k$ from linear error-correcting codes. We observe that the resulting presentation has a weak form of stability exactly when the code is  \emph{locally testable}.\mnote{I have a problem with the notion of locally testable. The notion reffers ususally to testable LDPCs. We do not need the low density to define our notions and construction, only the testable part. I think we should change it to just testable codes... What do you think? This appears throughout the intro... It won't be a major change} This raises the question of whether locally testable codes give rise to genuinely stable presentations using this method.  While we cannot show that in general, we leverage recent results in the study of non-local games in quantum information theory (Ji et al., Discrete Analysis 2021) to show that a specific instantiation of our construction, based on the Reed-Muller family of codes, leads to a stable presentation of $\Z_2^k$ of size $\poly\log(k)$ only. As an application, we combine this result with recent work of de la Salle (arXiv:2204.07084) to re-derive  the quantum low-degree test of Natarajan and Vidick (IEEE FOCS'18), which is a key building block in the recent refutation of Connes' Embedding Problem via complexity theory (Ji et al., arXiv:2001.04383). 
\end{abstract}


\section{Introduction}

\paragraph{Motivation.}
A linear error-correcting code $\code$ is a $k$-dimensional subspace of the vector space $\F^n$ over a finite field $\F$ that has certain combinatorial properties. The foremost of these is the \emph{minimal distance} $d$, which is defined as the smallest Hamming weight (number of nonzero coordinates) $|c|$ of a nonzero vector  $c\in\code$. In general one would like to design families of codes of increasing length $n$, such that both $k$ and $d$ are bounded below by a positive linear function of $n$. Such codes are referred to as ``good'' codes.

A finer property which concerns us here is the \emph{soundness} of the code, a parameter that is connected to the notion of \emph{local testability}. A code can be (non-uniquely) specified through a \emph{parity-check matrix} $h\in\F^{m\times n}$ as $\code = \ker h$. The rows of $h$ are thought of as constraints (``parity checks'') that specify $\code$ as a subspace of $\F^n$. A code is called locally testable \emph{with soundness $\rho$} if for every $x\in \F^n$, $\frac{1}{m}|hx|\geq \rho \, \frac{1}{n}\, d(x,\code)$, where $d(x,\code)$ denotes the minimum of $|x-c|$ over $c\in \code$.  Ideally one would like to design families of good codes such that in addition $\rho$ is bounded below by a constant independent of $n$.\footnote{Note that in principle a code can have a small minimal distance $d$, and still be locally testable with soundness $\rho>0$. So a family of codes can be ``locally testable'' without being ``good.''} This is a challenging task, and the construction of families of good locally testable codes was only achieved very recently~\cite{LTC_DELLM,LTC_Panteleev_Kalachev}. 

The terminology ``locally testable'' comes from an interpretation of $\frac{1}{m}|hx|$ as the probability of rejection of a natural ``tester'' for $\code$, i.e.\ an algorithm that on input $x$ checks a randomly chosen row $h_i$ of $h$ and accepts if and only if $h_i\cdot x = \sum_j h_{ij} x_j =0$.  Thus a code is called locally testable if words that are far from the code have a high probability of being rejected according to this tester. This notion plays a central role in applications of codes to complexity theory~\cite{babai1991non,PCP_thm}, and continues to be actively studied. See e.g.~\cite{LTC_DELLM,LTC_Panteleev_Kalachev} for a recent breakthrough on the topic. 

We make an observation that connects the study of locally testable codes to questions of stability in group theory and motivates our work. Let $\code=\ker h$ be a linear code as above, and suppose for simplicity that $\F=\F_2$ is the binary field. Consider the finitely presented group 
\begin{align}
 G(h) \,=\, \langle S:R\rangle \,=\, \big\langle &x_1,\ldots,x_n \,:\quad  x_j^2=e\quad \forall 1\leq j\leq n\;,\notag\\
& \quad \prod_{1\leq j \leq n} x_j^{h_{ij}} = e\;,\quad [x_{j_1},x_{j_2}]^{h_{ij_1} h_{ij_2}}=e\quad \forall 1\leq i\leq m\,\forall 1\leq j_1,j_2\leq n\,\big\rangle\;.\label{eq:gh-intro}
\end{align}
Here a commutation relation between two generators  $[x_{j_1},x_{j_2}]=e$ is imposed only when needed for the relations $\prod_{1\leq j \leq n} x_j^{h_{ij}} = e$ to make sense, i.e.\ two generators are required to commute only if they both take part in the same equation, which is the case if and only if $h_{ij_1}h_{ij_2}=1$ for some $i$. 

We observe that $1$-dimensional representations, i.e.\ maps from $S=\{x_1,\ldots,x_n\}$ to $\{-1,1\}$ that satisfy all relations $R$, are in one-to-one correspondence with elements of $\code$. Moreover, \emph{approximate} $1$-dimensional representations, i.e.\ maps from  $S=\{x_1,\ldots,x_n\}$ to $\{-1,1\}$ that satisfy a fraction $1-\eps$ of all relations for small $\eps$, can be identified with words $x\in\F_2^n$ such that $\frac{1}{m}|hx|\leq C\eps$ for some constant $C$ depending on the ratio $m/n$.\footnote{In principle we could allow the map to range over $U(\C)$ instead of $\{-1,1\}$. In general we will allow this; but for the purposes of this introduction it is simpler to restrict to the $\{-1,1\}$-valued case (which corresponds to considering the relations $x_j^2=e$ as ``hard'' constraints that always need to be satisfied).} In particular, we notice that $\code$ is locally testable with soundness $\rho$ if and only if $\eps$-approximate $1$-dimensional representations of $G(h)$ are $\nicefrac{\eps}{\rho}$-close to genuine $1$-dimensional representations. 

\paragraph{Group stability.}
This observation immediately raises many questions. The problem of relating approximate representations of a group to exact representations of it is termed \emph{stability} in group theory, and has a long history. There are of course many flavors of the problem, depending on how one defines closeness (should it be the operator norm or the Hilbert-Schmidt norm? Should closeness hold for every relation, or every pair of group elements, or is it sufficient that it holds on average? Etc.) We will review some relevant results in this area below. For now, we mention Voiculescu's famous counter-example~\cite{voiculescu1983asymptotically} about approximately commuting unitaries, which was motivated by a question of Halmos on pairs of approximately commuting Hermitian operators~\cite{halmos1976some}. Using the terminology of stability, Voiculescu showed that the presentation $\Z^2 = \langle x,y:[x,y]=e\rangle$ is \emph{not} stable with respect to the operator norm. However, much more recently Glebsky~\cite{glebsky2010almost} showed that the same presentation \emph{is} stable with respect to the normalized Hilbert-Schmidt norm. 

This example and many others show that the notion of stability is, in general, highly sensitive to the notion of closeness considered. Returning to our main concern, so far we have argued that 
stability of approximate \emph{$1$-dimensional} representations of the presentation $G(h)$ is connected to local testability of the code $\ker h$. In the case of $1$-dimensional representations of course the choice of norm does not matter; however, the choice of measuring the error on average over relations, as opposed to e.g.\ taking the maximum, is one in which we depart from most of the literature. We will motivate this choice further below; but before we can continue we must pause to introduce the key definitions that our work builds on. For the purposes of the introduction we focus the discussion on finite-dimensional representations; in the main paper we handle the general case of representations in a tracial von Neumann algebra. Let $\mU(\C^d)$ denote the unitary operators on $\C^d$, and for a set $S$ let $\mF(S)$ denote the free group generated by the elements of $S$. For $X\in \C^{d\times d}$ let $\|X\|_{hs}^2 = \frac{1}{d}\Tr(X^* X)$ denote the (normalized) Hilbert-Schmidt norm.\footnote{This norm is also commonly called the normalized \emph{Frobenius} norm. Following \cite{dechiffre_glebsky_lubotzky_thom_2020}, it became common in stability theory to call the normalized version Hilbert--Schmidt and the un-normalized version Frobenius. In any case, in the main part of this paper, we relate to it as the tracial norm because of the von Neumann algebraic framework we use.}

\begin{definition}[Almost homomorphism]\label{def:approx-hom-intro}
Let $G = \langle S:R\rangle $ be a finitely presented group and $\mu_R$ a distribution on $R$. An $(\eps,\mu_R)$-almost homomorphism of $G$ is a homomorphism $\phi:\mF(S)\to\mU(\C^d)$ for some $d\geq 1$ such that
\[ \Es{r\sim \mu_R} \big\|  \phi(r) - \Id \big \|_{hs}^2 \,\leq\, \eps\;.\]
\end{definition}

As already mentioned this definition makes two important choices: firstly, to measure closeness in the Hilbert-Schmidt norm, and secondly, to measure it on average over the choice of a relation. Next we give our definition for a finitely presented group to be stable; see Definition~\ref{def:eff-stab} for the general setting. 

\begin{definition}[Stability]\label{def:eff-stab-intro}
Let $G = \langle S:R\rangle $ be a finitely presented group, $\mu_S$ a distribution on $S$ and $\mu_R$ a distribution on $R$. For $\delta:[0,1]\to[0,1]$ such that $\lim_{t\to 0}\delta(t)=0$ and an integer $d\geq 1$ we say that the presentation $G=\langle S:R\rangle$ is $(\delta,\mu_S,\mu_R,d)$-stable if for every $(\eps,\mu_R)$-almost homomorphism $\phi: \mF(S) \to \mU(\C^d)$ there is a unitary representation $\psi: G \to \mU(\C^d)$ such that
\[ \Es{s\sim \mu_S} \big\|  \phi(s) - \psi(s) \big \|_{hs}^2 \,\leq\, \delta(\eps)\;.\]
We refer to any function $\delta$ satisfying the above as a ``modulus of stability'' of the presentation.
\end{definition}

\begin{remark}[The $L^\infty$ analogue]\label{rem:L^infty_analogue_defn}
    As mentioned  before, it is common to call a homomorphism $\phi\colon \mF(S)\to \mU(\complex^d)$ an $\eps$-almost homomorphism of $G=\langle S\colon R\rangle,$  if $\max_{r\in R}\Vert \phi(r)-\Id\Vert_{hs}^2\leq \eps$. Furthermore, the distance between two homomorphisms $\phi,\psi\colon \mF(S)\to \mU(\complex^d)$ is ususally taken to be $\max_{s\in S}\Vert \phi(s)-\psi(s)\Vert_{hs}^2$. The notion of stability induced by these definitions of `almost' and `close' is more commonly used. Note that when studying a fixed finitely presented group, and without caring about the exact modulus of stability, there is no difference between the two definitions.  But, when one cares about the modulus of stability, which is the case  when viewing stability as a property testing problem, our framework is the more natural one. 
\end{remark}

In this paper we also consider a version of \emph{flexible} stability, i.e.\ the representation $\psi$ is allowed to range in $U_{d'}(\C)$ for some $d'\neq d$; see Definition~\ref{def:eff-stab} for the general definition. This requires a more careful definition of closeness; for now we restrict our attention to the simpler definition. % and for the purposes of this introduction we restrict ourselves to the simpler definition. 

We can now ask the question: is $G(h)$, the group presentation defined in~\eqref{eq:gh-intro}, stable according to Definition~\ref{def:eff-stab-intro}? One can verify that with $\mu_R$ and $\mu_S$ the uniform distribution on $R$ and $S$ respectively, $G(h)$ is $(\delta,\mu_S,\mu_R,1)$-stable for $\delta=\eps/\rho$ if and only if $\code = \ker h$ is locally testable with soundness $\rho>0$. But what about higher-dimensional approximate representations? Are these also stable, or does one need to make further requirements on $\code$ beyond local testability? We do not yet have a comprehensive answer to these questions. However, the answer cannot be straightforward: even deducing basic properties about the group $G(h)$ given its presentation -- let alone its stability properties -- appears to be a challenging task. For example, there are examples of parity check matrices $h$ for which the group $G(h)$ is non-Abelian or even non-amenable; see Remark~\ref{rk:non-abelian}.

\paragraph{Efficient stability.}
Faced with the apparent difficulty of studying the general question, it is time to refine our focus and formulate the question which we \emph{do} address. To start, let us explicitly note that 
while stability has previously (for the most part) been studied as a question about a group, our formulation makes it a question about a \emph{presentation} of the group. In particular it is known~\cite{gowers2017inverse,de2019operator} that for finite groups $G$ (which are the only groups we consider in this paper) the multiplication table presentation, which has $|G|$ generators for every group element and $|G|^2$ relations for every pairwise product, is $\delta(\eps)=C\eps$-flexibly stable\footnote{Here we assume that $\mu_R,\mu_S$ are uniform over the relations and generators of the multiplication table presentation, respectively. Furthermore, the results of~\cite{gowers2017inverse,de2019operator} apply to a notion of \emph{flexible} stability, where the nearby exact representation may act on a space of larger, but not too much larger, dimension. See  Definition \ref{def:close}.} for some constant $C$ that is independent of the group. This holds even for approximate representations in arbitrary tracial von Neumann algebras. 

\mnote{The following two paragraphs are problematic. The size of $G(h)$ is independent of $n,k$ in general, even if it is finite. The only case in which you can bound the size of $G(h)$ according to $n,k$ is when it is \textbf{abelian}, and we insisted on not assuming that. I feel like we should add all commutation relations before discussing this part.} However the results of~\cite{gowers2017inverse,de2019operator} do not imply the same quantitative stability bounds for $G(h)$ with respect to its defining presentation~\eqref{eq:gh-intro} (even if $G(h)$ is given to be finite). The reason to prefer the presentation~\eqref{eq:gh-intro} as opposed to the multiplication table presentation of $G(h)$ is that~\eqref{eq:gh-intro} is much more succinct: if $n,k$ are linearly related then it has $\textrm{poly}(k)$ generators and relations, as opposed to $2^k$ and $2^{2k}$ respectively. Such a gain is essential when one recalls the interpretation of the presentation $G(h)$ as a ``tester'' for $G$ --- the size of the presentation is then directly related to the amount of \emph{randomness} required by the tester (to sample a random relation); and in computer science applications randomness is seen as an essential resource (we discuss this more below, in the context of quantum computing). 

%Now observe that, if $G(h)$ happens to be Abelian, then it provides a \emph{different} presentation~\eqref{eq:gh-intro} of $\Z_2^k$, where $k$ is the dimension of $\ker h$. This presentation could be much smaller --- if $n,k$ are linearly related then it has $O(k)$ generators and relations, as opposed to $2^k$ and $2^{2k}$ respectively. Such a gain is essential when one recalls the interpretation of the presentation $G(h)$ as a ``tester'' for $G$ --- the size of the presentation is then directly related to the amount of \emph{randomness} required by the tester (to sample a random relation); and in computer science applications randomness is seen as an essential resource (we discuss this more below, in the context of quantum computing). 

Can such ``efficient'' presentations of $G(h)$ still be stable? The naive approach, of extending an $\eps$-approximate homomorphism of $G(h)=\langle S:R\rangle$ into an $\eps'$-approximate homomorphism of the multiplication table presentation of $\Z_2^k$, leads to $\eps'=\Omega(k\eps)$ and hence a logarithmic dependence of the modulus of stability on the group size. Is it possible to do better? Glebsky's result for the case of $\Z^2$ mentioned earlier suggests that it is in some cases  possible -- but in what generality?

The main result of this paper is to exhibit presentations of $\Z_2^k$ (and of slightly more complex $2$-groups built on them, e.g. the \emph{Pauli}, or \emph{Weyl-Heisenberg}, group ubiquitous in quantum information theory) that are \emph{efficiently stable}: the size of the presentation is quasi-polynomial in $k$ (as opposed to exponential), yet the modulus of stability only depends poly-logarithmically on $k$. These presentations are constructed from specific error-correcting codes, namely the Reed-Muller polynomial codes, which are known to have good local testability properties~\cite{babai1991non}. Our main result on group stability can be stated as follows (see Theorem~\ref{thm:z2-stab} for the precise statement).

\begin{theorem*}[Main, informal]
For every integer $k\geq 1$ there is a presentation $\Z_2^k = \langle S_k:R_k\rangle$ such that $|S_k|,|R_k| = 2^{\poly\log(k)}$ and furthermore this presentation is $(\delta,\mu_{S_k},\mu_{R_k},d)$-stable for all $d \in \N$, where $\delta(\eps)=\poly(\log k,\eps)$, $\mu_{S_k}$ is uniform over the generators and $\mu_{R_k}$ is some distribution over the relations. 
\end{theorem*}

Most of the technical legwork required to prove the theorem is due to prior work in the study of nonlocal games in quantum computing, and in particular~\cite{ji2020quantum} (we explain this connection below). Our contribution in the present work is to make an explicit connection with stability and show how the former results can be ``imported'' to obtain new stability results such as the one stated in our main theorem above. 

We do not know of any other presentation of $\Z_2^k$, arguably the simplest example one could think of, that is stable with similar parameters as the ones stated in the theorem. It would be very interesting to discover different such presentations, built from locally testable error-correcting codes or not, for this group or others. 

\paragraph{Nonlocal games in quantum information theory.}
To motivate our focus on \emph{efficient} stability we now sketch a connection between our results and problems in quantum complexity theory and in particular the theory of nonlocal games that motivate us. As a result we will recover a key technical result used in the proof of the complexity result $\sf MIP^* = \sf RE$~\cite{ji2020mip} and its corresponding resolution of the Connes' Embedding Problem.

 A \emph{nonlocal game} $\game$ is specified by the following data: finite question and answer sets $\mX$ and $\mA$ respectively, a distribution $\mu$ on $\mX\times \mX$, and a decision predicate $D:\mX\times \mX\times \mA\times \mA\to \{0,1\}$ (see Section~\ref{sec:nl-games} for details). The interpretation of $\game=(\mX,\mu,\mA,D)$ as a game is as follows. A ``referee'' is imagined to sample a pair of ``questions'' $(x,y)\sim \mu$. Each question is sent to a different player, who is tasked with responding with an answer $a,b\in \mA$ respectively. Finally, the referee decides that the players win the game if and only if $D(x,y,a,b)=1$. Interestingly, the maximum success probability of the players in this game, where the probability is over the referee's choice of questions and any randomness in the player's strategy, and the maximum is taken over all allowed strategies, depends on whether one relies on ``classical'' or ``quantum'' interpretations of the game to determine appropriate mathematical formalization of the set of strategies that the players may employ. While a classical viewpoint naturally models a strategy as a pair of functions $f,g:\mX\to\mA$, one for each player, quantum mechanics invites one to consider a broader set of strategies in which an additional form of coordination between the players is allowed in the form of \emph{shared quantum entanglement}. Understanding when there is a gap between the resulting maxima, and how large this gap can be, is of great interest in the foundations of quantum mechanics. To study this question one is drawn to investigate the structure of optimal quantum strategies in a game, and how to design games that enforce a specific structure --- informally, forcing as much ``non-classicality'' in winning strategies as possible. Beyond their foundational appeal, the theory of nonlocal games has had a very large impact in quantum cryptography (such as the analysis of device-independent quantum key distribution protocols~\cite{vazirani2019fully,arnon2019simple}) and quantum complexity, in particular the theory of multiprover interactive proof systems~\cite{cleve2004consequences}.

For concreteness let us focus on a class of games called \emph{linear constraint system} (LCS) games. These games were introduced in~\cite{cleve2014characterization} and their study plays a central role in the celebrated result by Slofstra showing non-closure of the set of quantum correlations~\cite{slofstra2019set}. A linear constraint system game is parametrized by a matrix $h\in \F^{m\times n}$. In the game $\game_h$, the referee selects a pair $(i,j)\in \{1,\ldots,m\}\times\{1,\ldots,n\}$ uniformly at random conditioned on $h_{ij}=1$. They send $i$ to the first player and $j$ to the second. The first player returns values in $\F$ for \emph{each} $j'$ such that $h_{ij'}\neq 0$, whereas the second players returns a single value in $\F$. The players win if the first player's answers satisfy the parity constraint, and the players' answers are consistent (the first player's answer associated with index $j$ matches the second player's answer). 

Now we see that to each matrix $h$ we have associated a group $G(h)$, and a game $\game_h$. Moreover, and quite interestingly, there is a one-to-one correspondence between representations of $G(h)$ and \emph{perfect strategies} in $\game_h$, i.e.\ strategies that have success probability $1$ in the game.\footnote{To be precise, the group here is $G(h)$ to which have been added pairwise commutation conditions $[x_j,x_{j'}]=e$ whenever there is an $i$ such that $h_{ij}$ and $h_{ij'}$ are both nonzero. This correspondence was established for finite-dimensional strategies, and finite-dimensional representations, in~\cite{cleve2014characterization}. Extensions to infinite-dimensional strategies and representations have appeared in~\cite{cleve2017perfect}. See also e.g.~\cite{kim2018synchronous} for generalizations to the broader class of \emph{synchronous games}.}
This correspondence enables one to ``embed'' group representations into quantum strategies, thereby forcing them to demonstrate a high level of complexity; this is the approach at the heart of~\cite{slofstra2019set}. Going further, for applications one is often required to understand not only optimal but also near-optimal strategies, whose success probability is e.g.\ $1-\eps$. The same correspondence associates to such strategies approximate homomorphisms of $G(h)$~\cite{slofstra2018entanglement}. Here once can see that measuring closeness on average over the choice of relation is a natural choice, which is all but forced by the definition of a game, where the questions are selected according to some pre-specified distribution. 

To summarize, approximate stability results for $G(h)$ enable one to obtain structural results about near-optimal strategies in $\game_h$ --- such a result is known as a \emph{rigidity} result in quantum information. A rigidity result about a game called the quantum low-degree test~\cite{natarajan2018low} is at the heart of the proof of $\sf MIP^* = \sf RE$. The analysis of this test requires an efficient stability result for the Weyl-Heisenberg group. Informally, the reason that the stability result needs to be for an efficient presentation of the Weyl-Heisenberg group \mnote{We mix Weyl-Heisenberg with Pauli all the time. In the main text we call them Pauli, and mention that they are a special case of a Heisenberg group. I like the Weyl-Heisenberg name, since we ignore the y operators in this case, and I thought they are formally part of the Pauli group. But, since we already use notations with P throughout, it would be probably easier to change to Pauli here as well. }, as opposed to e.g.\ the multiplication table presentation, is because to obtain the final result it is necessary that the ``complexity'' of the test, or game, is smaller than the ``complexity'' of the object, or group being tested. Of course here we are loose about what we mean by ``complexity,'' and refer to~\cite{ji2021mip,vidickmip} for high-level explanations. The quantum low-degree test is described and analyzed in Section~\ref{sec:pbt}. We end by mentioning an open question: if one was able to obtain $|S_k|,|R_k|=\poly(k)$ while also having $\delta(\eps)=\poly(\eps)$ in the informal theorem stated above, then this result would likely, through the connection we just described, have consequences for the efficient verification of quantum computations in the framework of interactive proof systems---see e.g.~\cite{coladangelo2019verifier,natarajan2023bounding} for a sample of known results in this direction. 

\paragraph{Related works on stability.} The general question of group stability was first formulated by Ulam~\cite{ulam1960collection}, and later studied  by Kazhdan for the case of the operator norm~\cite{kazhdan1982e}. See the introduction of \cite{ioana2020stability} for a thorough history of these problems through the lens of approximate commutation (cf.  \cite{von1942approximative,voiculescu1983asymptotically,glebsky2010almost}). A major contribution was done by \cite{hadwin2018stability}, in which they characterized the stable amenable groups according to properties of their space of characters. 

Stability of finite groups, with respect to the multiplication table representation, is shown in~\cite{gowers2017inverse}. 
One can also consider representations in permutations, see~\cite{glebsky2009almost,becker2022stability}.  Specifically, the analogous problem of efficient stability in permutations is still open. See the open problems section of \cite{CL_part2}. Both stability in permutations and in unitaries equipped with the Hilbert--Schmidt metric are closely related to the notions of sofic and hyperlinear groups, cf. \cite{glebsky2009almost,becker2020group}. 

\tnote{more? open questions?}\mnote{If we have open problems, maybe we should collect them at the end? Not sure about that. Did you think of any open problems other than the permutation analogue of the quantum soundness of the low-deg test?}


\paragraph{Outline.}
We start in Section~\ref{sec:efficient} by giving a precise definition of stability that we work with, and give examples to motivate and illustrate the definition. In Section~\ref{sec:pres-codes} we give a general method for constructing presentations from codes, and apply the method to the spacial case of the Reed-Muller code. This leads in Section~\ref{sec:eff-z2k} to the statement and proof of our main result, an efficiently stable presentation for $\Z_2^k$. Finally in Section~\ref{sec:quantum} we elaborate on the connection with the theory of nonlocal games and detail our applications to this area. 




\paragraph{Acknowledgments.} 
MC acknowledges with gratitude the Simons Society of Fellows and is supported by a grant from the Simons Foundation (N. 965535). 
TV is supported by a research grant from the Center for New Scientists at the Weizmann Institute of Science, a Simons Investigator award, AFOSR Grant No. FA9550-22-1-0391, and ERC Consolidator Grant VerNisQDevS (101086733). HY is supported by AFOSR award FA9550-21-1-0040, NSF CAREER award CCF-2144219, and the Sloan Foundation.


\section{Efficient stability}
\label{sec:efficient}

In this section we give definitions associated with the notion of ``efficient stability'' used in the paper. We reformulate some previously known results in this framework, and give examples that will be used later on. 


\subsection{Algebra background and notation}

  Here we call \emph{tracial von Neumann algebra} a pair $(\mM,\tau)$ of a von Neumann algebra $\mM$ together with a normal faithful tracial state $\tau$ on $\mM$, which we often refer to as the \emph{trace}. The main example of interest is $\mM=M_n(\C)$, the algebra of $n\times n$ complex matrices, with $\tau$ the dimension-normalized trace, which we denote $\tr(M)=\frac{1}{n}\Tr(M)$. 	We write $\|x\|_\tau=\tau(x^*x)^{1/2}$ to denote the $2$-norm on $\mM$ with respect to $\tau$ --- which agrees in the case of $M_n(\complex)$ with the Hilbert--Schmidt norm $\|x\|_{hs}$ discussed in the introduction.
	
	Let $B(\ell_2)$ be the von Neumann algebra of bounded operators on $\ell_2$, the Hilbert space of convergent sequences in $\C^\Z$ equipped with the usual Euclidean norm (for which we let $(e_i)_{i \in \Z}$ denote the standard basis). We denote $\mM_\infty = \mM \overline{\otimes} B(\ell_2)$, where the overline denotes closure for the operator topology. $\mM_\infty$ is a von Neumann algebra equipped with the (infinite) trace $\tau_\infty = \tau \otimes \Tr$, with $\Tr(X)=\sum_{i\in \Z} e_i^T X e_i$ the trace on $B(\ell_2)$. We generally identify $\mM$ with the ``corner'' $\mM\otimes \Id_{1}\subset \mM_\infty$, where $\Id_1$ is the projection on the $1^{\rm st}$ coordinate in $\complex^\Z$.

\subsection{Efficiently stable presentations}

Suppose given a finite presentation of a (possibly infinite) group $G$ using generators $S$ and relations $R$. Informally, we say that the presentation is \emph{stable} if any map from $S$ to unitaries that approximately respects the relations $R$ is close, in an appropriate sense, to a representation of $G$. Furthermore, we will say that the presentation is \emph{efficient} if it is stable and provides a good trade-off between its size (the number of relations used and their length) and how the closeness to a representation depends on the error in satisfying the relations $R$. All the notions referred to informally in the preceding sentences --- ``approximately,'' ``close,'' good trade-off,'' etc., can be formalized in a variety of ways, leading to generally incomparable definitions. Here we present the formalization that is most natural to us, and is motivated by applications to quantum information and complexity. 


Given a set $S$, we let $\mF(S)$ denote the free group generated by $S$. We identify functions from $S$ to $H$, where $H$ is any group, with homomorphisms from $\mF(S)$ to $H$. If $R$ is a subset of $\mF(S)$ then the quotient of $\mF(S)$ by the normal subgroup generated by $R$ is denoted $\langle S:R\rangle$. 

We start with the notion of an almost-homomorphism, which formalizes what it means for a map defined on $S$ to approximately satisfy the relations $R$. The notion we give is a small variant of the notion of $\eps$-\emph{almost homomorphism} from a finitely presented group to a unital tracial $C^*$-algebra $\mA$ introduced in~\cite[Section 2]{hadwin2018stability}. %Informally, an $\eps$-almost homomorphism of $G=\langle S:R\rangle$ is a map from $S$ to $\mU(\mA)$ that approximately respects all relations in $R$. 
We give a variant of their definition that quantifies the error in an average sense. Below, when $\mu$ is a distribution over a finite set $\mX$ and $f:\mX\to \R$ we write $\Es{x\sim \mu} f(x)$ for the expectation of $f$ under $\mu$. 

\begin{definition}[Almost homomorphism]\label{def:approx-hom}
Let $G = \langle S:R\rangle $ be a finitely presented group, $\mu$ a distribution on $R$, and $(\mM,\tau)$ a tracial von Neumann algebra. An $(\eps,\mu)$-almost homomorphism of $G$ on $(\mM,\tau)$ is a homomorphism $\phi:\mF(S)\to\mU(\mM)$ such that
\[ \Es{r\sim \mu} \big\|  \phi(r) - \Id \big \|_\tau^2 \,\leq\, \eps\;.\]
\end{definition}

We note that this notion depends on the presentation $\langle S:R\rangle$ of $G$, not only on the group itself. 
When the distribution $\mu$ is uniform over the set $R$, we simply write $\eps$-homomorphism. The definition is consistent with the usual notion of a homomorphism that factors through $G$, which is recovered when $\eps=0$ as long as $\mu_R$ and $\mu_S$ are fully supported. 

A stability result is a statement that $\eps$-homomorphisms are close to homomorphisms. To measure the distance between homomorphisms into different algebras we make the following definition. 


\begin{definition}[Closeness for unitaries]\label{def:close}
Let $\{U_i\}\subseteq \mM$ and $\{V_i\}\subseteq \mN$ be two families of unitaries on  tracial algebras $(\mM,\tau^\mM)$ and $(\mN,\tau^\mN)$ respectively, indexed by the same set $\mI$. For $\delta\geq0$ and $\mu$ a measure on $\mI$ we say that $\{U_i\}$ and $\{V_i\}$ are $(\delta,\mu)$-close if there exists a projection $P\in\mM_\infty$ of finite trace such that $\mN=P\mM_\infty P$ and $\tau^\mN=\tau_\infty/\tau_\infty(P)$, and a partial isometry $w\in P \mM_\infty \Id_\mM$ such that 
\[ \Es{i\sim\mu} \big\| U_i - w^* V_i w \big\|_{\tau}^2 \,\leq\,\delta,\ \footnote{We denote the norm by $\|\cdot\|_{\tau}$ and not $\|\cdot\|_{\tau^\mM}$ for clarity of the notations. The von Neumann algebra in which we take the norm should be understood from context, and will usually be $\mM$. }\]
and 
\[\max\big\{ \tau^\mM(\Id_\mM-w^*w)\,,\; \tau^\mN(P-ww^*)\big\} \,\leq\, \delta\;.\]
If $\phi:\mI\to \mU(\mM)$ and $\psi:\mI\to \mU(\mN)$ then we say that $\phi$ and $\psi$ are $(\delta,\mu)$ close if the families $\{\phi(i)\}$ and $\{\psi(i)\}$ are. 
If the measure $\mu$ is omitted then it is understood to be the uniform measure on $\mI$.
\end{definition}


We now give our definition of stability.

\begin{definition}[Stability]\label{def:eff-stab}
Let $G = \langle S:R\rangle $ be a finitely presented group. Let $\mC$ be a class of tracial von Neumann algebras. Let $\mu_S$ be a distribution on $S$ and $\mu_R$ a distribution on $R$. Let $\delta:[0,1]\to[0,1]$ be a function satisfying $\lim_{t\to 0}\delta(t)=0$. The presentation $G=\langle S:R\rangle$ is $(\delta,\mu_S,\mu_R,\mC)$-stable if for every $(\cM,\tau)$ in $\mC$, every $(\eps,\mu_R)$-almost homomorphism of $G$ is $(\delta(\eps),\mu_S)$-close to a unitary representation of $G$ on some $(\mN,\tau^\mN)\in \mC$. We refer to the function $\delta$ as the \emph{modulus of stability} of the presentation.\footnote{Every function that satisfies this condition is a modulus of stability for $G=\langle S\colon R\rangle$, but we occasionally refer that way to the best possible $\delta$ in the definition.}
\end{definition}

\begin{remark}\label{rk-mus}
Fixing a distribution $\mu_R$ on $R$ only, there is a natural induced distribution $\mu_S$ on $S$ which is obtained by sampling $r\in R$ from $\mu_R$, and then sampling an $s\in S$ according to the atomic measure induced by $R$ (seen as a multiset). For example, if $r=aba$ then conditioned on having chosen $r$, $a$ is given probability $2/3$ and $b$ is given probability $1/3$. Throughout this text, $\mu_S$ is always chosen as this induced distribution and so we often omit it from the notation.
\end{remark}

Definition~\ref{def:eff-stab} specifies what it means for a presentation to be stable, but not when the presentation is \emph{efficiently} stable. 
As mentioned in the introduction, the goal is to optimise the tradeoff between the encoding length of the presentation and the resulting modulus of stability. We now choose a complexity measurement for presentations:
\begin{definition}[Length of a presentation]\label{def:length_of_pres}
    Let $G=\langle S\colon R\rangle$ be a finite presentation. The \emph{length} of the presentation  will be  $$\ell(G)=|S|+ \sum_{r\in R}|r|,$$ where $|r|$ is the length of the word $r\in \mF(S)$ written in the basis $S$.\footnote{Another popular notion of length is the bit length of the encoding of $\langle S\colon R\rangle$, where exponents in $r\in R$ can be written in binary. Up to a factor of $\log |S|$, our notion is stricter than that. See \cite{babai1997short}.}
\end{definition}

The search for the shortest possible presentations of finite groups, and in particular of finite simple groups, contained many twists and turns. Clearly, the shortest presentation of some groups, e.g. $G=\Z_2^k$, needs to be of size at least $\poly\log|G|$. On the other hand, it turns out that there are finite simple groups with minimal presentation length $\poly\log\log|G|$, which was a big surprise (see \cite{guralnick2008presentations} and the references therein). Also, all finite groups (without ${}^2G_2(q)$ composition factors) have a presentation of length $O(\log^3(|G|))$. Thus, we can say that a presentation is ``efficient'', if its length is not much larger than the shortest possible one. This can be phrased in various ways, and certain choices of parameters can be applied in different ways. Our exact choice of tradeoff parameters between length and modulus of stability, which we shall refer to as efficiently stable,  is motivated by natural examples which we outline next.



\subsection{General results}

As was shortly reviewed in the introduction, and specifically in the related works subsection, many results about various notions of stability are known.  Here, we give two results that are most relevant to our work. First of all, 
for a finite group $G$ we can always write $G=\langle S:R\rangle$ where $S = G$ and $R=\{ g\cdot h \cdot (gh)^{-1} =e \}$. We refer to this presentation as the \emph{multiplication table presentation}\tnote{was ``exhaustive''; edited terminology}. If we let $\mu_S$ and $\mu_R$ be the uniform distribution on $S$ and on $R$ respectively then Definition~\ref{def:eff-stab} reduces to a widely used notion of \emph{flexible (Hilbert-Schmidt) stability}. In particular, for finite groups the following result is known~\cite{gowers2017inverse,de2019operator}. We adopt the formulation from~\cite[Theorem 1.4]{de2022spectral}.

\begin{theorem}\label{thm:gh}
Let $G$ be a finite group and $\mC$ the class of all tracial von Neumann algebras. Let $\mu_S$ and $\mu_R$ be the uniform distribution on $S=G$ and $R=\{ g\cdot h \cdot (gh)^{-1}=e \}$ respectively. Then $G=\langle S:R\rangle$ is $(c\eps,\mu_S,\mu_R,\mC)$-stable, where $c>0$ is a universal constant independent of $G$.
\end{theorem}

Next we state for later use a result from~\cite{de2022spectral} which allows to combine stability results. The results in~\cite{de2022spectral} are rather general and apply to direct products and certain central extensions of a class of finite groups. Here, we will only use the following specialization to the case of the central extension of $\Z_2^k \times \Z_2^k$ by $\{-1,1\}$ given by $\gamma(a,b)=(-1)^{a\cdot b}$, with $a\cdot b$ the inner product modulo $2$. For a measure $\mu$ on $\Z_2^k$, define its inverse spectral gap 
\[ \kappa = \max_{a\neq 0} \frac{1}{1-\Es{b\sim\mu}(-1)^{a\cdot b}}\;.\footnote{Note that this is indeed the inverse of the spectral gap of the random walk operator on $\Z_2^k$ induced by $\mu$. Equivalently, by viewing $\mu$ as an element of the group ring $\complex[\Z_2^k]$, it acts on it from the left, and thus has a spectral decomposition and a spectral gap.}\] 

\begin{theorem}[\cite{de2022spectral} Corollary 2.6]\label{thm:dls-gap}
Let $\mu$ be a measure on $\Z_2^k$ with inverse spectal gap $\kappa$. Let $\phi_X,\phi_Z: \Z_2^k \to \mU(\mM)$ be two homomorphisms such that
\[ \Es{a,b\sim \mu} \big\| \phi_X(a)\phi_Z(b)-(-1)^{a\cdot b} \phi_Z(b)\phi_X(a)\big\|_\tau^2 \,\leq\,\eps\;.\]
Then there is an $\mN=P\mM_\infty P$ and homomorphisms $U_X,U_Z:\Z_2^k\to\mU(\mN)$ and $\delta=O(\kappa^2\eps)$ such that $\phi_X$ and $U_X$ are $(\delta,\mu)$-close, $\phi_Z$ and $U_Z$ are $(\delta,\mu)$-close, and moreover $U_X(a)U_Z(b)=(-1)^{a\cdot b}U_Z(b)U_X(a)$ for all $a,b\in\Z_2^k$.
\end{theorem}
\begin{corollary}
    Theorem \ref{thm:dls-gap} essentially tells us the following: if we are given an almost homomorphism of the Pauli group \eqref{eq:defn_Pauli_as_Heisenberg}, then we can fix it to a homomorphism in two steps. First, fix its restriction to the $X$ and $Z$ observables independently. Then, apply the theorem to get a homomorphism from the whole Pauli group. This idea is spelled out in detail in the proof sketch of Corollary \ref{cor:Pauli-brading_is_stable}.
\end{corollary}



	\subsection{Measurements and orthonormalization}
	\label{sec:measurements}
	
	Before giving some examples, we introduce the notion of a \emph{positive operator-valued measure} (POVM), or more simply \emph{measurement}. This is a notion that comes from quantum mechanics and will be useful to formulate some of our statements.  
  If $\mM$ is a tracial von Neumann algebra, a measurement on $\mM$ with outcome set $\mA$ is a finite collection of positive semidefinite operators $\{P_a\}_{a\in \mA}$ such that $\sum_a P_a = \Id_\mM$. A measurement is \emph{projective} if for all $a$, $P_a$ is a projection. 
	
	In our results we will make use of the following elementary but powerful result, which allows us to ``pull back'' projective measurements through an isometry. The result is an application of \emph{orthonormalization}, which transforms a nearly-orthogonal measurement to a nearby orthogonal measurement. See e.g.~\cite{kempe2011parallel,ji2020quantum} or~\cite[Theorem 1.2]{de2021orthogonalization} for the version that we use here. 
	
\begin{lemma}\label{lem:pull-back}
Let  $(\mM,\tau^\mM)$ be a tracial von Neumann algebra, $P\in\mM_\infty$ a projection of finite trace, $\mN=P\mM_\infty P$ and $\tau^\mN=\tau_\infty/\tau_\infty(P)$, and $w\in P \mM_\infty \Id_\mM$ a partial isometry. Let 
\[ \eps = \max\big\{ \tau^\mM\big(\Id_\mM - w^* w\big)\,,\;\tau^\mN\big( P- w w^*\big)\big\}\;.\] 
 Then for any projective measurement $\{T_a\}_{a \in \mA}$ on $\mN$, where $\mA$ is a finite set, there is a projective measurement $\{Q_a\}_{a \in \mA}$ on $\mM$ such that 
\begin{equation}
\label{eq:pull-back} \sum_{a \in \mA} \big\| Q_a - w^* T_a w\big\|_{\tau}^2 \,\leq \ 56\eps\;.
\end{equation}
\end{lemma}	

\begin{proof}
If $\eps\geq \frac{1}{2}$ the conclusion is straightforward. This is because, whatever projective measurement $\{Q_a\}_{a\in \mA}$ one chooses, we have
\[
\|Q_a-w^*T_aw\|_\tau^2\leq 2\|Q_a\|_\tau^2+2\|w^*T_aw\|_\tau^2,
\] 
and 
\[
\sum_{a\in \mA} \|Q_q\|_\tau^2,\ \sum_{a\in \mA} \|w^*T_aw\|_\tau^2\leq 1.
\]
So, assume $\eps<\frac{1}{2}$. 
Define 
\[\tilde{Q}_a = w^* T_a w  + \frac{1}{|\mA|}\big(\Id_\mM - w^* w\big) \in \mM\;.\]
Then $\{\tilde{Q}_a\}$ is a POVM on $\mM$. Moreover, 
\begin{align*}
\sum_a \tau^\mM \big( \tilde{Q}_a^2 \big) &\geq \sum_a \tau^\mM \big( \big(w^* T_a w \big)^2 \big) \\
&= \sum_a \tau^\mM \big(  w^* T_a w w^*T_a w \big)\\
&= \sum_a \tau^\mM \big(  w^* T_a  P T_a w \big) - \sum_a \tau^\mM \big( w^* T_a  ( P - w w^*) T_a w \big)\\
&\geq 1 - \eps -  \sum_a \tau_\infty \big( w^* T_a  ( P - w w^*) T_a w \big)\\
&\geq 1 - \eps -  \tau_\infty\Big(\big( P - w w^*\big)\Big(\sum_a  T_a w w^* T_a\Big)\Big)\\ 
&\geq 1- \eps- \tau_\infty\big( P- w w^*\big)\;,
\end{align*}
where the third line uses that $T_aPT_a=T_a$, $\sum_a T_a = \Id_\mN$ and the definition of $\eps$ for the first term, and for the second the fact that for $A\in\mM$, $\tau^\mM(A)=\tau_\infty(A)$ by definition of $\tau_\infty$ and the identification of $\mM$ with a ``corner'' in $\mM_\infty$, the fourth line uses cyclicity of the trace for the second, and the last uses $\|ww^*\|_\infty,\|\sum_a T_a\|_\infty\leq 1$.\footnote{The notation $\|\cdot\|_\infty$ refers to the operator norm.} By assumption, 
\begin{align}
\tau_\infty\big( P- w w^*\big) \,\leq\, \eps\, \tau_\infty(P)\,\leq \frac{\eps}{1-\eps}\;,\label{eq:bound_on_P-ww*_in_trace_infty}
\end{align}
where the last inequality is because by definition, $\tau^N(P)=1$, thus
\[1-\eps \,\leq\, \tau^\mN(ww^*) \,=\, \frac{\tau_\infty(ww^*)}{\tau_\infty(P)}\,=\, \frac{\tau_\infty(w^*w)}{\tau_\infty(P)}  \,\leq\, \frac{1}{\tau_\infty(P)}\]
since $\tau_\infty(w^* w) = \tau^\mM(w^* w)$ and $w^*w\leq I_\mM$. Overall, 
\begin{equation}\label{eq:square_greater_1-3eps}
    \sum_a \tau^\mM \big( \tilde{Q}_a^2 \big) \,\geq\, 1-\eps-\frac{\eps}{1-\eps}\,\geq\, 1-3\eps\;.
\end{equation}
To conclude we apply~\cite[Theorem 1.2]{de2021orthogonalization} to obtain a projective measurement $\{Q_a\}$ on $\mM$ such that 
\begin{equation*}
\sum_a \big\|{Q}_a - \tilde{Q}_a \big\|^2_\tau \,=\, 27\eps\;.
\end{equation*}
Finally,
\begin{align*}
\sum_a \big\|{Q}_a - w^*{T}_a w\big\|^2_\tau &= \sum_a \Big\|{Q}_a - \tilde{Q}_a  + \frac{1}{|\mA|}\big(I_\mM - w^* w\big) \Big\|^2_2\\
&\leq  \sum_a 2\big\|{Q}_a - \tilde{Q}_a\big\|_\tau^2  + 2\frac{1}{|\mA|}\big\|I_\mM - w^* w\big\|_\tau^2 \\
&\leq 54 \eps + 2 \tau^\mM( (I_\mM - w^* w)^2 ) \\
&\leq 54 \eps + 2 \tau^\mM(I_\mM - w^* w ) \\
&\leq 56 \eps\;,
\end{align*}
where the second line is by the triangle inequality, the fourth line is due to the fact that $I_\mM - w^* w$ is positive and has operator norm at most $1$, and the last line is by $\tau^\mM(I_\mM - w^* w ) \leq \eps$.
\end{proof}

\begin{comment}
    \begin{claim}\label{claim:L^1_dist_on_reps)_implies_L^infty_dist}
    Let $\phi_1\colon G\to \mU(\mM)$ and $\phi_2\colon G\to \mU(\mN)$ be representations of a finite group $G\cong \langle S\colon R\rangle$, where $\mN=PM_\infty P$  with  $\tau_\infty(P)<\infty$, and equipped with the appropriate trace. Let $w\in P\mM_\infty \Id_\mM$ be a partial isometry from $\mM$ to $\mN$, and assume both
    \[
    \Expectation_{x\in G}\Vert \phi_1(x)-w^*\phi_2(x)w\Vert_\tau ^2\leq \eps\quad \textrm{and}\quad \max\{\tau^\mM(\Id_\mM-w^*w),\tau^\mN(P-ww^*)\}\leq \eps.
    \]
    Then 
    \[
        \forall x\in G\ \colon\ \Vert \phi_1(x)-w^*\phi_2(x)w\Vert_\tau ^2\leq 12\eps.
    \]
    Namely, an $L^1$ bound on the distance between two representations implies an $L^\infty$ bound on their distance. In particular, the average distance along every generating set $S$ of $G$ is bounded by the expected distance over all of $G$.
\end{claim}
\begin{proof}
    The following idea is standard, and can be traced back, for example, to \cite{blum1990self}. As before, we can assume $\eps<\frac{1}{2}$, otherwise the claim is trivial. For every $x,y\in G$, we have 
    \begin{align}
      \Vert \phi_1(x)-w^*\phi_2(x)w\Vert_\tau&=\Vert \phi_1(y)\phi_1(y^{-1}x)-w^*\phi_2(y)\phi_2(y^{-1}x)w\Vert_\tau \notag\\
    &=\Vert \phi_1(y)\phi_1(y^{-1}x)-\phi_1(y)w^*\phi_2(y^{-1}x)w+\phi_1(y)w^*\phi_2(y^{-1}x)w \notag\\ 
    &-w^*\phi_2(y)ww^*\phi_2(y^{-1}x)w+w^*\phi_2(y)ww^*\phi_2(y^{-1}x)w-w^*\phi_2(y)\phi_2(y^{-1}x)w\Vert_\tau\notag \\
    &\leq \Vert \phi_1(y^{-1}x)-w^*\phi_2(y^{-1}x)w\Vert_\tau+\Vert \phi_1(y)-w^*\phi_2(y)w\Vert_\tau\notag\\
    &+\Vert w^*\phi_2(y)(ww^*-P)\phi_2(y^{-1}x)w\Vert_{\tau}.\label{eq:lower_bound_stab_standard_pres}
\end{align}
Now, the third summand in the last line of \eqref{eq:lower_bound_stab_standard_pres} can be bounded using  the  methods which appeared in the proof of Lemma \ref{lem:pull-back}:
\begin{align}
    \Vert w^*\phi_2(y^{-1}x)(ww^*-P)\phi_2(y)w\Vert_{\tau}^2&=\tau^\mM(w^*\phi_2^{-1}(y^{-1}x)(ww^*-P)\phi_2^{-1}(y)ww^*\phi_2(y)(ww^*-P)\phi_2(y^{-1}x)w)\notag\\
    &\leq \tau^\infty(w^*\phi_2^{-1}(y^{-1}x)(ww^*-P)\phi_2^{-1}(y)ww^*\phi_2(y)(ww^*-P)\phi_2(y^{-1}x)w)\notag\\
     &\leq \tau^\infty((ww^*-P)\phi_2^{-1}(y)ww^*\phi_2(y)(ww^*-P)\phi_2(y^{-1}x)ww^*\phi_2^{-1}(y^{-1}x))\notag\\
     &\leq \tau^\infty((ww^*-P)\phi_2^{-1}(y)ww^*\phi_2(y)(ww^*-P))\notag\\
     &\leq \tau^\infty(\underbrace{(ww^*-P)^2}_{P-ww^*}\phi_2^{-1}(y)ww^*\phi_2(y))\notag\\
     &\leq \frac{\eps}{1-\eps}\ \ ,\label{eq:lower_bound_stab_standard_pres1}
\end{align}
where we use the cyclicity of the trace, the fact $\mM$ is a corner and the evaluated operator is positive, the fact $\phi_2(y^{-1}x)ww^*\phi_2^{-1}(y^{-1}x)$ and $\phi_2^{-1}(y)ww^*\phi_2(y)$ are  contractions, as well as \eqref{eq:bound_on_P-ww*_in_trace_infty}.
Combining \eqref{eq:lower_bound_stab_standard_pres} and \eqref{eq:lower_bound_stab_standard_pres1}, we deduce that 
\begin{align*}
    \Vert \phi_1(x)-w^*\phi_2(x)w\Vert_\tau^2&=\Expectation_{y\in G}\Vert \phi_1(x)-w^*\phi_2(x)w\Vert_\tau^2\\
    &\leq 3\Expectation_{y\in G} [\Vert \phi_1(y^{-1}x)-w^*\phi_2(y^{-1}x)w\Vert_\tau^2+\Vert \phi_1(y)-w^*\phi_2(y)w\Vert_\tau^2\\
    &+\Vert w^*\phi_2(y)(ww^*-P)\phi_2(y^{-1}x)w\Vert_\tau^2 ]\\
    &\leq 3(\eps +\eps +\frac{\eps}{1-\eps})\leq 12\eps.
\end{align*}
\end{proof}
\end{comment}


\subsection{Examples}
\label{sec:examples}

As a first example we spell out the application of Theorem~\ref{thm:gh} to the case of $G=\Z_2^k$. 
Below, when we write $\Es{i\in \mX}$ where $\mX$ is a finite set, we mean the expectation over $i$ chosen uniformly at random from $\mX$, i.e.\ $\frac{1}{|\mX|} \sum_{i\in \mX}$. 

\begin{corollary}\label{cor:lin-test} %\tnote{Stated this for finite dimensions. Not sure what we want in the end}
Let $(\mM,\tau)$ be a tracial von Neumann algebra and $\phi:\Z_2^k \to \mU(\mM)$ such that 
\[ \Es{x,y\in \Z_2^k} \big\| \phi(x)\phi(y)-\phi(x+y) \big\|_{\tau}^2 \,\leq\,\eps\;.\]
Then there is a %$d'=(1+O(\eps))d$, an isometry $w:\C^d \to \C^{d'}$ and a 
projective measurement $\{P_u\}_{u\in \Z_2^k}$ on $\mM$ such that 
\[ \Es{x\in \Z_2^k} \Big\| \phi(x) -\Big(\sum_u (-1)^{u\cdot x} P_u\Big)  \Big\|_{\tau}^2 \,=\, O(\eps)\;.\]
\end{corollary} 

\begin{proof}
Any $\phi$ as in the corollary statement is an $(\eps,U_R)$-almost homomorphism of $\Z_2^k$ into $(\mM,\tau)$ for the multiplication table presentation. Applying Theorem~\ref{thm:gh}, $\phi$ is $O(\eps)$-close to a homomorphism from $\Z_2^k$ to some $(\mN,\tau^\mN)$. Because $\Z_2^k$ is Abelian, such a homomorphism is given by commuting unitaries $(U_x)_{x\in\Z_2^k}$ on $\mN$. Moreover, since $\Z_2^k$ is a $2$-group, each $U_x$ satisfies $U_x^2=\Id$, hence $U_x=U_x^*$.

For every $u\in  \Z_2^k$ let $Q_u = \Es{x} (-1)^{u\cdot x} U_x$. Then each $Q_u$ is a projection on $\mN$ such that $\sum_u Q_u=\Id$, and $U_x = \sum_u (-1)^{u\cdot x} Q_u$. Furthermore, by the conclusion of Theorem~\ref{thm:gh} it holds that 
\begin{equation}\label{eq:lin-test-1}
   \Es{x\in \Z_2^k} \Big\| \phi(x) - w^*\Big(\sum_u (-1)^{u\cdot x} Q_u\Big)w  \Big\|_{\tau}^2 \,=\, O(\eps)\;,
\end{equation}
for some partial isometry $w\in P\mM_\infty I_\mM$ as in Definition~\ref{def:close}.
Using Lemma~\ref{lem:pull-back}, we find a projective measurement $\{P_u\}$ on $\mM$ that satisfies 
\begin{equation}\label{eq:lin-test-1b}
 \sum_u \big\| P_u - w^* Q_u w \big\|_\tau^2 \,=\, O(\eps)\;.
\end{equation}
Thus
\begin{align}
\Es{x\in \Z_2^k}  \Big\| \sum_u (-1)^{u\cdot x} \big(P_u - w^* Q_u w\big) \Big\|_\tau^2
&=\Es{x\in \Z_2^k} \sum_{u,v} (-1)^{(u+v)\cdot x} \tau\big(\big(P_u - w^* Q_u w\big)\big(P_v - w^* Q_v w\big)\big) \notag\\
&= \sum_u \big\| P_u - w^* Q_u w\big\|_\tau^2\notag\\
&= O(\eps)\;,\label{eq:lin-test-2}
\end{align}
where the second line uses $\Es{x} (-1)^{w\cdot x} = 0$ if $w\neq 0$, and $1$ otherwise, and the last line is by~\eqref{eq:lin-test-1b}. Plugging back into~\eqref{eq:lin-test-1} and using the triangle inequality shows the corollary.  
\end{proof}

The multiplication table presentation of $\Z_2^k$ is quite long,  in the sense of Definition \ref{def:length_of_pres}. It has as many generators as the group size, and quadratically as many relations, which gives a length of $O(2^{2k})$. 
There are much shorter presentations of $\Z_2^k$, for example the straightforward

\begin{equation}\label{eq:z2-efficient}
 \Z_2^k = \langle x_1,\ldots,x_k : [x_i,x_j]=e, x_i^2=e \; \forall i\neq j \rangle\;,
\end{equation}
where $[x_i,x_j]=x_ix_jx_i^{-1}x_j^{-1}$ is the group commutator. 
Its length is $O(k^2)$, which is polylogarithmic in the group size instead compared to the polynomial length of the multiplication table presentation. By \cite{hadwin2018stability}, every presentation of a finite group has \textbf{some} modulus of stability.
The following two lemmas show that, though the presentation \eqref{eq:z2-efficient} has a linear modulus of stability, it deteriorates by a constant factor $k$. In some sense, these two examples are on opposite sides of the efficient stability tradeoof: \eqref{eq:z2-efficient} is short but has a bad modulus of stability, while the multiplication table presentation is very long, while having an essentially optimal modulus of stability. As we keep recalling, the goal of this paper is to provide an example of a somewhat short presentation of $\Z_2^k$, which has a good enough modulus of stability to deduce the main technical results needed for MIP*=RE \cite{ji2020mip}.



\begin{lemma}[Lemma 3.8 in~\cite{slofstra2019set}]\label{lem:eff-z2}
Let $\mC$ be the class of tracial von Neumann algebras. Let $\mu_R$ be the equal mixture of the uniform distribution on all words $[x_i,x_j]$ ($i\neq j$) and the uniform distribution on all words $x_i^2$. Let $\mu_S$ be the uniform distribution on $\{x_1,\ldots,x_k\}$. Then 
  for every $k$, there is a $\delta_k = O_k(\eps)$ such that the presentation~\eqref{eq:z2-efficient} is $(\delta_k,\mu_S,\mu_R,\mC)$-stable. Furthermore, the close representation can be taken on the same algebra.
\end{lemma}

As one would expect, the dependence of $\delta_k$ on $k$ depends on both the diameter of $\Z_2^k$ for the presentation~\eqref{eq:z2-efficient}, and certain values of its \emph{Dehn function} --- namely, the minimal volume of a Van Kampen diagram with perimeters of length $3$. By expressing each element of $\Z_2^k$ as a product of generators in the natural way, and by applying Corollary~\ref{cor:lin-test}, it is possible to show that $\delta_k=O(k^2\eps)$ in Lemma~\ref{lem:eff-z2}. With more work one can get $\delta_k=O(k\eps)$, see~\cite[Theorem 3.2]{chao2017overlapping}. This turns up to be  tight, as the next lemma shows. 

\begin{lemma}\label{lem:lower_bound_on_stability_rate_standard_presentation_Z_2^k}
    Let $\mu_R$ and $\mu_S$ be as in Lemma~\ref{lem:eff-z2}. % be the uniform distribution over the commutation relations in the presentation $\langle S\colon R\rangle$ from \eqref{eq:z2-efficient}, and $\mu_S$ the marginal distribution from $\mu_R$, which is the uniform one on $S=\{x_1,...,x_k\}$. 
    There is a $(\nicefrac{1}{\binom{k}{2}},\mu_R)$-almost homomorphism of $\langle S\colon R\rangle$ which not $(\nicefrac{1}{16k},\mu_S)$-close to any homomorphism (according to Definition~\ref{def:close}). 
\end{lemma}


Lemma~\ref{lem:lower_bound_on_stability_rate_standard_presentation_Z_2^k} implies that the modulus of stability of \eqref{eq:z2-efficient} is $\Omega(k\eps)$ as $\eps\to 0$. This is because for any $\eps>0$ such that $\eps\leq 1/\binom{k}{2}$ we can create an $(\eps,\mu_R)$-almost homomorphism of $\langle S\colon R\rangle$ by taking direct sums of one copy of the almost-homomorphism $\phi$ from Lemma~\ref{lem:lower_bound_on_stability_rate_standard_presentation_Z_2^k}, which ranges into $\mU(\C^{2^{k+1}})$, with $R=\lceil 2^{k+1}/(\binom{k}{2}\eps)\rceil$ copies of the trivial representation of $G(h)$. Clearly, a $\delta$-close homomorphism implies, by restriction, a $\delta R$-close homomorphism to $\phi$. Hence $\delta R \geq 1/(16k)$, which gives $\delta=\Omega(k\eps)$ as claimed.  

\begin{proof}[Proof of Lemma \ref{lem:lower_bound_on_stability_rate_standard_presentation_Z_2^k}]
Let $\{A_i\}_{i=1}^k$ be permutations acting on the set $\field^{k+1}$ as follows: For every $i\neq 1$, $A_i$ flips the $i^{\rm th}$ bit. The permutation $A_1$ always flips the $1^{\rm st}$ bit, and  flips the $(k+1)^{\rm th}$ bit conditioned on the $2^{\rm nd}$ bit being $1$. Namely, each $A_i$ is a NOT gate applied from the $2^{\rm nd}$ to  the $i^{\rm th}$ bit, while $A_1$ is a NOT gate applied on the first bit composed with a CNOT gate applied to the $(k+1)^{\rm th}$ bit. The von Neumann algebra $\mM$ containing the $A_i$'s is the one acting on $\complex^{\field^{k+1}}$ with its standard normalized trace $\tau^\cM(X)=\frac{1}{2^{k+1}}\Tr(X)$.

Now, all of the $A_i$'s are order $2$ unitaries, thus satisfy the order $2$ relations in \eqref{eq:z2-efficient} perfectly. Furthermore, 
\[
\Expectation_{i\neq j\in [k]}\left[\Vert A_iA_jA_iA_j-\Id_\mM\Vert_\tau^2\right]=\frac{1}{\binom{k}{2}}\Vert A_1A_2A_1A_2-\Id_\mM\Vert_\tau^2=\nicefrac{2}{\binom{k}{2}},
\]
because $A_1A_2A_1A_2$ is the permutation that flips the $(k+1)$-st bit. 
Thus, the map $x_i\mapsto A_i$ is a $(\nicefrac{1}{\binom{k}{2}},\mu_R)$-almost homomorphism of $\Z_2^k$ with respect to \eqref{eq:z2-efficient}. 

Recall that given our von Neumann algebra $\mM$, the algebra $\mM_\infty$ acts on the Hilbert space $\complex^{\field^{k+1}}\otimes \complex^\Z$. Let $\{e_v\otimes e_t\mid v\in \field^{k+1},t\in \Z\}$ be the standard basis of this Hilbert space.
Let $\{B_i\}_{i=1}^k$ be order $2$ unitaries which pairwise commute in $\mN=P\mM_\infty P $, and assume  there is a partial isometry $w=PU\Id_\mM\in P\mU(\mM_\infty)\Id_\mM$ and  $0<\eps\leq \sqrt{2}-1$ such that 
\[
\Expectation_{i\in [k]} \Vert A_i-w^* B_iw\Vert_\tau^2\ ,\qquad  \tau^\mM(\Id_\mM-w^*w)\leq  \eps.
\]
This is a slightly weaker condition than for the $B_i$'s to be $(\eps,\mu_S)$-close to the $A_i$'s, as in Definition \ref{def:close}. Furthermore, we can assume without loss of generality that $U=\Id_\infty$, otherwise we replace $\mN$ by $U^*\mN U$ and $P$ by $U^* PU$. Thus, we are given that 
\[
\Expectation_{i\in [k]} \Vert A_i-\Id_\mM  B_i\Id_\mM\Vert_\tau^2\ ,\qquad  \tau^\mM(\Id_\mM-\Id_\mM P\Id_\mM)\leq  \eps.
\]
Thus, 
\[
\begin{split}
    \Vert \Id_\mM-\Id_\mM P\Id_\mM\Vert_\tau^2 &=\tau^{\mM}(\Id_\mM\underbrace{-2\Id_\mM P\Id_\mM+\Id_\mM P^2\Id_\mM}_{=-\Id_\mM P\Id_\mM})\leq \eps.
\end{split}
\]
Hence, 
\begin{align*}
    \sqrt{2}&=\Vert A_1A_2A_1A_2-\Id_\mM\Vert_\tau\\
    &\leq \Vert A_1A_2A_1A_2-\Id_\mM P\Id_\mM\Vert_\tau+\eps\\
    &=\Vert A_1A_2A_1A_2-\Id_\mM B_1B_2B_1B_2\Id_\mM\Vert_\tau+\eps\\
    &\leq \Vert \Id_\mM(A_1-B_1)A_2A_1A_2\Vert_\tau+\Vert \Id_\mM B_1(A_2-B_2)A_1A_2\Vert_\tau\\
    &+\Vert \Id_\mM B_1B_2(A_1-B_1)A_2\Vert_\tau+\Vert \Id_\mM B_1B_2B_1(A_2-B_2)\Id_\mM\Vert_\tau+\eps\\
    &=(\heartsuit)+\eps
\end{align*}
Since the $A_i$'s are unitaries in $\mM$, and by abusing notation and denoting $\Vert X \Vert_\tau=\tau_\infty(X^*X)$, we have 
\begin{align*}
    (\heartsuit)&= \Vert \Id_\mM(A_1-B_1)\Id_\mM\Vert_\tau+\Vert \Id_\mM B_1(A_2-B_2)\Id_\mM\Vert_\tau\\
    &+\Vert \Id_\mM B_1B_2(A_1-B_1)\Id_\mM\Vert_\tau+\Vert \Id_\mM B_1B_2B_1(A_2-B_2)\Id_\mM\Vert_\tau\\
    &\leq \Vert (A_1-B_1)\Id_\mM\Vert_\tau+\Vert (A_2-B_2)\Id_\mM\Vert_\tau
    +\Vert (A_1-B_1)\Id_\mM\Vert_\tau+\Vert (A_2-B_2)\Id_\mM\Vert_\tau\\
    &=(\spadesuit).
\end{align*}
But,
\begin{align*}
     \Vert (A_1-B_1)\Id_\mM\Vert_\tau^2=  \Vert \Id_\mM(A_1-B_1)\Id_\mM\Vert_\tau^2+\Vert (\Id_\infty-\Id_\mM)(A_1-B_1)\Id_\mM\Vert_\tau^2,
\end{align*}
and since $(\Id_\infty -\Id_\mM)A_1=0$ and $\Id_\mM A_1=A_1\Id_\mM$, we have
\begin{align*}
    \Vert (\Id_\infty-\Id_\mM)(A_1-B_1)\Id_\mM\Vert_\tau^2= \Vert (\Id_\infty-\Id_\mM)B_1\Id_\mM\Vert_\tau^2=\Vert (\Id_\infty-\Id_\mM)B_1A_1\Id_\mM\Vert_\tau^2.
\end{align*}
%\tnote{I couldn't follow the last equality above, what allows you to insert $A_1$? An alternate way of going about it is to first show
%\begin{align*}
%\big\|\tau(\Id_\mM)-\tau(\Id_\mM B_1^* \Id_\mM B_1 \Id_\mM)\big|
%&=\big\|\tau(\Id_\mM A_1^* \Id_\mM A_1 \Id_\mM )-\tau(\Id_\mM B_1^* \Id_\mM B_1 \Id_\mM)\big|\\
%&\leq \big| \tau(\Id_\mM (A_1-B_1)^* \Id_\mM A_1\Id_\mM )\big| + \big|\tau(\Id_\mM B_1^*\Id_\mM (A_1-B_1)\Id_\mM )\big|\\
%&\leq 2 \big\| \Id_\mM (A_1-B_1)\Id_\mM\big\|_\tau\;,
%\end{align*}
%by Cauchy-Schwwarz. Then, 
%\begin{align*}
%  \Vert (A_1-B_1)\Id_\mM\Vert_\tau^2 &= \tau\big(\Id_\mM (A_1-B_1)^*(A_1-B_1)\Id_\mM\big)\\
%  &= \tau(\Id_\mM) + \tau(\Id_\mM B_1^*B_1 \Id_\mM) - \tau(\Id_\mM A_1^* B_1 \Id_\mM) - \tau(\Id_\mM B_1^* A_1 \Id_\mM)\\
%  &\leq \tau(\Id_\mM) + \tau(\Id_\mM B_1^*\Id_\mM B_1 \Id_\mM) - \tau(\Id_\mM A_1^* \Id_\mM B_1 \Id_\mM) - \tau(\Id_\mM B_1^* \Id_\mM A_1 \Id_\mM) + 2 \big\| \Id_\mM (A_1-B_1)\Id_\mM\big\|_\tau\\
%  &\leq 3\Vert \Id_\mM (A_1-B_1)\Id_\mM\Vert_\tau\;,
%\end{align*}
%where the third line uses the previous set of equations to relate the second terms, and $A_1\Id_\mM=A_1$ for the last terms.
%This is worse than your bound because of the missing square on the last line, which is due to the first bunch of equations. %I think it gives a similar trade-off in the end? 
%}
Here the second equality is because by definition, 
\begin{align*}
    \Vert(\Id_\infty-\Id_\mM)B_1\Id_\mM\Vert_\tau^2=\sum_{\substack{v'\in \field^{k+1} \\ j\neq 1}}\sum_{v\in \field^{k+1}} |(e_{v'}\otimes e_j)^*B_1e_v\otimes e_1|^2=(\diamondsuit)\;,
\end{align*}
but since $A_1$ permutes $\{e_v\otimes e_1\}_{v\in \field^{k+1}}$, we have
\begin{align*}
    (\diamondsuit)=\sum_{\substack{v'\in \field^{k+1} \\ j\neq 1}}\sum_{v\in \field^{k+1}} |(e_{v'}\otimes e_j)^*B_1A_1e_v\otimes e_1|^2=\Vert (\Id_\infty-\Id_\mM)B_1A_1\Id_\mM\Vert_\tau^2\;.
\end{align*}
Now, for every $v\in \field^{k+1}$, we have
\[
1-|(e_v\otimes e_1)^*B_1A_1e_v\otimes e_1|^2\leq |1-(e_v\otimes e_1)^*B_1A_1e_v\otimes e_1|^2\leq \Vert \Id_\mM(\Id_\infty-B_1A_1)e_v\otimes e_1\Vert_2^2.
\]
On the other hand, since $B_1A_1$ is a contraction, 
\begin{align*}
    1-|(e_v\otimes e_1)^*B_1A_1e_v\otimes e_1|^2
    &\geq \Vert B_1A_1 e_v\otimes e_1\Vert_2^2-|(e_v\otimes e_1)^*B_1A_1e_v\otimes e_1|^2\\
    &=\sum_{(v',j')\neq (v,1)}|(e_{v'}\otimes e_j)^*B_1A_1e_v\otimes e_1|^2\\
    &\geq \Vert (\Id_\infty-\Id_\mM)B_1A_1 e_v\otimes e_1\Vert_2^2\;.
\end{align*}
Therefore, by averaging the combined inequalities over $v\in \field^{k+1}$, we get
\[
\Vert (\Id_\infty -\Id_\mM)B_1A_1\Id_\mM\Vert_\tau^2\leq  \Vert \Id_\mM(\Id_\infty-B_1A_1)\Id_\mM\Vert_\tau^2=\Vert A_1-\Id_\mM B_1\Id_\mM\Vert_\tau^2\;.
\]
\begin{comment}
=\frac{1}{2^{k+1}}\sum_{\substack{v\in \field^{k+1}}} \sum_{\substack{v'\in \field^{k+1}\\ j'\neq 1}} \vert (e_{v'}\otimes e_j)^*B_1 e_v\otimes e_1\vert^2.
\end{comment}
Plugging all of this back to $(\spadesuit)$, we get
\begin{align*}
    (\sqrt{2}-\eps)^2&\leq (\spadesuit)^2\\
    &\leq 8\Vert(A_1-B_1)\Id_\mM\Vert^2+8\Vert(A_2-B_2)\Id_\mM\Vert^2\\
    &\leq 16 \Vert \Id_\mM (A_1-B_1)\Id_\mM\Vert^2+16 \Vert \Id_\mM (A_2-B_2)\Id_\mM\Vert^2\\
    &\leq 16k \eps,
\end{align*}
and since we assumed $\eps<\sqrt{2}-1$ we deduce that 
\[
\eps>\frac{1}{16k}.
\]
This finishes the proof.
\end{proof}

\begin{remark}
    This construction (viewed in a different way) was used by Kozlov--Meshulam \cite{kozlov2019quantitative} to upper bound the Cheeger constant of the $k$-dimensional hypercube --- see Section 4.1 therein.
\end{remark}

\begin{remark}
As discussed in the introduction (see Remark \ref{rem:L^infty_analogue_defn}), it is more common in the literature on stability to use a $L^\infty$ analogue of Definition~\ref{def:eff-stab}, where the notion of almost-homomorphism and closeness are both measured by taking a supremum over relations and generators respectively, as opposed to averaging according to distributions $\mu_R,\mu_S$. 
A slight modification of the example given in  the proof of Lemma~\ref{lem:lower_bound_on_stability_rate_standard_presentation_Z_2^k} provides a lower bound also in that setup. The idea is as follows: In the construction we provided, the pair $(1,2)$ played a special role, since $A_1$ was a CNOT conditioned on the second bit. We can thus define the analogous construction for every pair $(i,j)$ where $1\leq i<j\leq k$. By tensoring all of these constructions along the pairs $(i,j)$, we get $k$ permutations acting on $\binom{[k]}{2}\times \field^{k+1}$, which in turn provide a lower bound in the $L^\infty$ setup. The proof is similar to the above, and since this is a slight digression from our main theme, we omit the details. 
\end{remark}

In the next section we will obtain presentations of $\Z_2^k$ that have a much better length/modulus tradeoff than the one given in~\eqref{eq:z2-efficient} or the multiplication table presentation. In the meantime, we give one last example. To formulate it we recall the definition of the Pauli matrices
	\begin{equation}\label{eq:def-pauli-1} \sigma^X = \begin{pmatrix} 0 & 1 \\ 1 & 0 \end{pmatrix}\;,\qquad \sigma^Z = \begin{pmatrix} 1 & 0 \\ 0 & -1\end{pmatrix}\;,
	\end{equation}
	and more generally for $a,b\in \Z_2^k$ let 
	\begin{equation}\label{eq:def-pauli-2}
	\sigma^X(a) = \bigotimes_{i=1}^k (\sigma^X)^{a_i}\qquad\text{and}\qquad\sigma^Z(b) = \bigotimes_{i=1}^k (\sigma^Z)^{b_i}\;.
	\end{equation}
These are self-adjoint unitary operators called Pauli observables. Each observable $\sigma^X(a)$ (resp. $\sigma^Z(b)$) corresponds to the \emph{Pauli measurement} $\{ \sigma^X_a \}_{a \in \Z_2^k}$ (resp. $\{ \sigma^Z_b \}_{b \in \Z_2^k}$) where (in a slight abuse of notation)  
	%	We slightly abuse notation and write 
	\[    \sigma^X_a = \Es{\alpha\in\F_2^k} (-1)^{a\cdot \alpha} \sigma^X(\alpha)\qquad\text{and}\qquad\sigma^Z_b = \Es{\beta\in\F_2^k} (-1)^{b\cdot\beta} \sigma^Z(\beta).\]
	It is easy to verify that $\{\sigma^X_a\}_a$ and $\{\sigma^Z_b\}_b$ are projections summing to identity.	
	
For an integer $k\geq 1$,  the Pauli group $\pauli_k$ is the group generated by the Pauli matrices $\sigma^X(a)$, $\sigma^Z(b)$ introduced in~\eqref{eq:def-pauli-2}. It can also be defined more abstractly as follows. Let $\gamma: \Z_2^k\times \Z_2^k \to \{-1,1\}$ be given by $\gamma(a,b)=(-1)^{a\cdot b}$. Then $\pauli_k$ is the central extension of $\Z_2^k\times \Z_2^k$ by $\{-1,1\}$ given by $\gamma$. This group 
is also known as the Heisenberg group 
\begin{equation}\label{eq:defn_Pauli_as_Heisenberg} H_{2k+1} = \left \{ \begin{pmatrix} 1 & a & c \\ 0 & I_{k \times k} & b \\ 0 & 0 & 1 \end{pmatrix} \right\}\subseteq {\mathrm{GL}}_{k+2}(\F_2)\;.
\end{equation}
 
We consider the following presentation for the Pauli group \mnote{This is not the correct presentation. We use only $(a,0)$ and $(0,b)$ as generators (and not all pairs as currently written). Also, the anti commutation relation is in the other direction isn't it? I don't want to mess something because I am not sure which presentation you were aiming for, but this has typos in it for sure. Lastly, the commutation with $J$ should be of pairs $(a,0)$ and $(0,b)$ and not just $a$ and $b$}:
\begin{align*}
 \pauli_k \,=\, \big\langle \{J\}\cup  \{(a,b): a,b\in \Z_2^k\} &: (a,0)^2=(0,b)^2=J^2=e,\; [a,J]=[b,J]=e,\\
&\qquad  (a,0)(b,0) = J^{a\cdot b} (a,b) \; \quad \forall a,b\big\rangle\;.
\end{align*}
This presentation is not quite the multiplication table presentation (it has $2^{2k}+1$ generators, whereas $|\pauli_k|=2^{2k+1}$), but it is not far from it.  \mnote{The number of generators should be $2^{k+1}+1$ and not $2^{2k}+1$.}
Applying Theorem~\ref{thm:gh} we obtain the following consequence.%, which we again state only for the case of a subclass of approximate homomorphisms and the class of finite-dimensional matrix algebras\tnote{again, not sure what we want ultimately}. 

\begin{corollary}[Pauli braiding test]\label{cor:Pauli-brading_is_stable}
Let $\phi_X,\phi_Z:\Z_2^k \to \mU(\mM)$ be such that for all $W\in \{X,Z\}$,
\[ \Es{a,b\in \Z_2^k} \big\| \phi_W(a)\phi_W(b)-\phi_W(a+b) \big\|_\tau^2 \,\leq\,\eps\;,\]
and
\[ \Es{a,b\in \Z_2^k} \big\| \phi_X(a)\phi_Z(b)- (-1)^{a\cdot b} \phi_Z(b)\phi_X(a) \big\|_{\tau}^2 \,\leq\,\eps\;.\]
Then there is a projection $P\in \mM_\infty$ such that if $\mN=P\mM_\infty P$ then $\mN\simeq (M_2(\C))^{\otimes k} \otimes \mN'$ for some $\mN'$, and a
partial isometry $w\in P\mM_\infty I_\mM$ such that for all $W\in \{X,Z\}$, 
\[ \Es{W\in \Z_2^k} \big\| \phi_W(a) - w^* \big(\sigma_W(a)\otimes \Id_{\mN'}\big) w \big\|_{\tau}^2 \,=\, O(\eps)\;.\]
\end{corollary}


Since this statement already appears in~\cite{natarajan2017quantum} (restricted to approximate homomorphisms into the finite-dimensional unitaries, and with slightly worse dependence on $\eps$), and we will not need it here, we only sketch the proof. 

\begin{proof}[Proof sketch]
\mnote{This proof sketch is very confusing. We think of the elements of $P_k$ as $\pm \sigma_X(a)\sigma_Z(b)$, not as $J^{\pm 1}(a,b)$. This is a parametrization of the generators in the specific presentation we provided, and which does not play a role here in the proof. Actually, this is part of what is confusing. The corollary is essentially that almost homomorphisms w.r.t the above presentation of $P_k$ can be translated to almost homs of $P_k$ w.r.t the multiplication table pres without changing the $\eps$ too much. We developed the proper language to make Corollary \ref{cor:Pauli-brading_is_stable} much shorter. We should have just stated that the presentation we gave for $P_k$ is stable, and furthermore, that when $J$ is mapped to $-1$, then the close by representation must be of the form $\Id\otimes P_k$. Anyway, maybe we can discuss this a bit and then I'll do the changes. Didn't want to mess up if this is the way you wanted everything to look like.  }
Define $\phi:\pauli_k \to \mU(\mM)$ by $\phi(J^c (a,b))= (-1)^c \phi_X(a)\phi_Z(b)$, where $c\in \{\pm 1\}$ and $a,b\in \Z_2^k$. Then it is not hard to verify that the assumptions of the corollary imply that  $\phi$ is an $O(\eps)$-almost homomorphism for the multiplication table presentation of $\pauli_k$. Applying Theorem~\ref{thm:gh} we find a unitary representation $\phi'$ of $\pauli_k$ on some $(\mN,\tau^\mN)$ that is $O(\eps)$-close to $\phi$. To conclude we observe that the only irreducible unitary representation of $\pauli_k$ that sends $J$ to $-1$ is the representation by the Pauli matrices; furthermore, all other irreducible representations are $1$-dimensional. From there it is not hard to show that, if we restrict $\phi'$ to its support on the Pauli matrix representation, the result remains $O(\eps)$-close to $\phi$. We omit the details. 
\end{proof}

Similarly to Lemma~\ref{lem:eff-z2} we can state a short version of the preceding corollary, with a bad modulus of stability, which applies to the presentation
\begin{align}
 \pauli_k = \big\langle x_1,\ldots,x_k,z_1,\ldots,z_k &: x_i^2=z_i^2=J^2=e,\; [x_i,J]=[z_i,J]=e,\notag\\
&\qquad  [x_i,x_j]=[z_i,z_j]=[x_i,z_j]=e, [x_i,z_i]=J \quad \forall i\neq j \big\rangle\;.\label{eq:pauli-efficient}
\end{align}

\begin{lemma}\label{lem:eff-pauli}
  Let $\mC$ be the class of tracial von Neumann algebras. Let $\mu_R$ be the following sampling procedure: With equal probability do one of the following
  \begin{itemize}
      \item Choose $J^2=e$.
      \item Sample $i\in [k]$ uniformly and choose $x_i^2=e$ (respectively, $z_i^2=e$).
      \item Sample $i\in [k]$ uniformly and choose $[x_i,z_i]=J$.
      \item Sample $i\neq j\in [k]$ uniformly at random and choose $[x_i,x_j]=e$ (respectively, $[z_i,z_j]=e$ or $[x_i,z_j]=e$).
  \end{itemize}
  Let $\mu_S$ be the marginal of $\mu_R$, as described in Remark~\ref{rk-mus}. Then 
 the presentation~\eqref{eq:pauli-efficient} is $(O(k\eps),\mu_S,\mu_R,\mC)$-stable.
\end{lemma}

\begin{proof}
This follows from Lemma~\ref{lem:eff-z2} and Theorem~\ref{thm:dls-gap}, in a similar manner to our proof sketch of Corollary \ref{cor:Pauli-brading_is_stable}.
\end{proof}

\section{Presentations from codes}
\label{sec:pres-codes}

In this section we present our main result, which is an ``efficient'' stable presentation of $\Z_2^k$. Most of the technical work required to show this result is done in~\cite{ji2020mip}. Here, we introduce the language required to reformulate their result in the framework of this paper. 

As a first step, we introduce a general method for translating any binary linear error-correcting code into a presentation of $\Z_2^k$. Later we apply this method to the specific case of the Reed-Muller code (composed with the Hadamard code to obtain a binary code). However, the general method may be of independent interest. 

\subsection{Presentations from codes}
\label{sec:pres-code}\mnote{Why the same headline for the subsection as the section itself? Maybe we should change}

For $q$ a prime power we let $\F_q$ denote the finite field with $q$ elements. 
For $n,k,d$ integer, a $[n,k,d]_q$ linear code $\code$ is a $k$-dimensional subspace of $\F_q^n$ such that for all $x\in \code$ such that $x\neq 0$, the Hamming weight $|x|$ (i.e.\ the number of nonzero coordinates of $x$) is at least $d$. The parameter $n$ is called the \emph{length} of the code, $k$ its \emph{dimension} and $d$ its \emph{distance}. A code can be specified by a \emph{parity check matrix} $h\in \F_q^{m\times n}$ such that $\code = \ker h$. 

For the remainder of this section we specialize the discussion to the case where $q=2$. 
We make the simple but key observation that a parity check matrix for a code of dimension $k$ implies a finite group presentation in the following way. Introduce $n$ generators $S=\{x_1,\ldots,x_n\}$. Each of the generators is required to be an involution: $x_i^2=e$. For each row $i\in \{1,\ldots,m\}$ of the parity check matrix $h$, introduce a relation 
\[ R_i\,:\; \prod_{1\leq j \leq n} x_j^{h_{ij}}=e\;, \]
that ``verifies'' the parity check associated with the $i$-th row of $h$. Finally, to guarantee that $R_i$ is independent of the order in which the $x_j$ are multiplied, whenever $j\neq j'$ are such that $h_{ij}$ and $h_{ij'}$ are both nonzero we require that $x_j$ and $x_{j'}$ commute. This can be written succinctly using a relation 
\[ R'_{ijj'}\,:\; [x_j,x_{j'}]^{h_{ij} h_{ij'}}=e\;.\]
The presentation obtained in this way defines a group $G=G(h)$, already introduced in~\eqref{eq:gh-intro} and which with the present notation reads
\begin{equation}\label{eq:def-gh-pres}
 G(h) \,=\, \big\langle x_1,\ldots,x_n \,:\, x_j^2=e\,,\; R_i\,,\; R'_{ijj'}\,,\quad \forall 1\leq i\leq m,\, 1\leq j< j' \leq n\big\rangle\;.
\end{equation}
Note that we made the dependence of $G(h)$ on $h$ explicit. This is because in general, the group defined in this way may depend on $h$, and not only on $\code$. If however we further impose \emph{all} pairwise commutation relations then we obtain the following. 

\begin{lemma}\label{lem:com-code}
Let $R''_{jj'}$ be the commutation relation $[x_j,x_{j'}]=e$. Then
\[ \Z_2^k \,=\, \big\langle x_1,\ldots,x_n \,:\, x_j^2=e\,,\; R_i\,,\; R''_{jj'}\,,\quad \forall 1\leq i\leq m,\, 1\leq j< j' \leq n\big\rangle\;.\]
\end{lemma}

\begin{proof}
The group defined by the right-hand side is obviously Abelian and a $2$-group, so it is of the form $\Z_2^{k'}$ for some $k'$. In fact, it is equal to the quotient of $\Z_2^n$ by the subgroup generated by the $\prod_{1\leq j \leq n} x_j^{h_{ij}}$. So it is $\Z_2^k$ where $k=n-\dim\textrm{im}\ h = \dim\ker h=\dim \code$.  
\end{proof}

\begin{remark}\label{rk:non-abelian}
There exists matrices $h$ such that $G(h)$ is not $\Z_2^k$, and in fact is not Abelian. For an example, see~\cite[Example 2.16]{paddock2022arkhipov}. For that example, $n=12$, $k=7$, and the parity check matrix $h$ can be described explicitly as follows: the $7$ rows of $h$ are indexed by the vertices of the complete bipartite graph $K_{3,4}$, the $12$ columns are indexed by the $12$ edges of $K_{3,4}$, and the entry $(i,j)$ of $h$ is $1$ if and only if the edge $j$ is incident on vertex $i$. As shown in~\cite{paddock2022arkhipov}, $G(h)$ is not Abelian. By considering $K_{3,6}$ instead of $K_{3,4}$, one in addition obtains a non-Abelian \emph{infinite} group. Using similar arguments it is possible to construct $h$ such that $G(h)$ is not amenable, etc.; see the discussion in~\cite[Section 6]{paddock2022arkhipov}.
\end{remark}


For readability it is convenient to reformulate the parity check matrix as a \emph{tester} for the code. This allows us to give a more succinct, ``algorithmic'' definition of a parity check matrix for a given code. Informally, the tester takes as input a word $w\in \F_2^n$ and determines if $w\in \code$ by selecting a parity check at random and evaluating it. 
 Specifically we give the following definition. (For the sake of later use, we state the definition for the case of a general prime power $q$.)

\begin{definition}[$r$-local linear tester]\label{def:code-test}
Let $\code$ be an $[n,k,d]_q$ linear code and $r\in \N$.
An \emph{$r$-local linear tester for $\code$} is a pair $M = (h,\nu)$ where $h \in \F^{m \times n}$ is a parity check matrix for $\code$, whose every row has Hamming weight at most $r$, and $\nu$ is a distribution over $\{1,\ldots,m\}$. 
\end{definition}

An $r$-local linear tester $M=(h,\nu)$ for $\code$ induces a pair of distributions $(\nu_R,\nu_S)$ on the relations and generators of the presentation $G(h)$\eqref{eq:def-gh-pres} in a natural way: For the generators, we let $\nu_S$ be induced from $\nu$ by first sampling $j\sim \nu$ and then a uniformly random $i$ such that $h_{ji}\neq 0$. For the relations, we let $\nu_R$ be the uniform mixture of the distribution $\nu_S$ on relations $x_j^2=e$, the distribution $\nu$ on relations $R_i$, and the distribution $\nu\times \nu_S\times \nu_S$ on relations $R'_{jii'}$.


We end this section with an example, the \emph{Hadamard code}. This code can be defined for any  $t\geq 1$ and it is a $[T,t,T/2]_2$ linear code, where $T=2^t$. For simplicity we write  $\code_\had$ to denote this code, omitting $t$. The Hadamard code is the subspace of linear functionals from $\field^t$ to $\field$ out of all such functions. As a linear space, $\code_\had$ can be described as  $(a\cdot b)_{a\in \field^t} \in \field^{\field^t}\cong \field^T$, for all $b\in \field^t$, where $ a\cdot b=\sum_{i=1}^t a_ib_i$ is again the dot product modulo $2$.  \mnote{The last definition was more confusing than clarifying. I changed it. }

A parity check matrix for $\code_\had$ is the matrix $h_\had\in \F_2^{T^2\times T}$ defined as follows. Identify the rows of $h_\had$ with pairs $(x,y)\in \F_2^t\times \F_2^t$, and the columns of $h_\had$ with $\F_2^t$. Then the $(x,y)$-th row of $h_\had$ has nonzero entries at positions $x,y$ and $x+y$ only. 
The corresponding $3$-local linear tester is $M_\had = (h_\had,\nu)$ where $\nu$ is the uniform distribution over $\F_2^t \times \F_2^t$. This tester can be described algorithmically, see Figure~\ref{fig:test-had}. 

\begin{figure}[!htbp]
  \centering
  \begin{gamespec}
	Given access to some $g\in \F_2^T$, where $T=2^t$, identify $g$ with a function $g:\F_2^t\to\F_2$. Perform the following. 
\begin{enumerate}
\item Select $(x,y)\in \F_2^t \times \F_2^t$ uniformly at random. 
\item Accept if and only if $g(x)+g(y)+g(x+y)=0$.  	
    \end{enumerate}
  \end{gamespec}
  \caption{A $3$-local linear tester for $\code_{\had}$}
  \label{fig:test-had}
\end{figure}

\begin{remark}
Since each pair of coordinates $(x,y)$ appears together in at least one parity check, we can apply Lemma~\ref{lem:com-code} to deduce that $G(h_\had)=\Z_2^t$. 
\end{remark}

We state our first stability result for a code-based presentation, the presentation $G(h_\had)$ defined as~\eqref{eq:def-gh-pres} where $h_\had$ is defined above. To state the result we need to specify distributions $\mu_S$ and $\mu_R$. We let $\mu_S$ be uniform over the $2^t$ generators, and $\mu_R$ the uniform distribution over the relations $R_{i}$. (Here, there is no need to place any weight on the relations $x_i^2=e$, or on the commutation relations $R'_{ijj'}$, because it can be seen that they follow from the other relations.)  

\begin{lemma}\label{lem:had-stab}
Let $\mC$ be the class of all tracial von Neumann algebras. 
The presentation $\Z_2^t= G(h_\had)$, together with the distributions $\mu_S$ and $\mu_R$ defined above, is $(\delta,\mu_S,\mu_R,\mC)$ stable with $\delta(\eps)=O(\eps)$. 
\end{lemma}

\begin{proof}
This an immediate consequence of Theorem~\ref{thm:gh}, because $G(h_\had)$ is the multiplication table presentation for $\Z_2^t$.
\end{proof}



\subsection{The Reed-Muller code over $\F_q$}
\label{sec:rmq}

We introduce a family of codes that will lead to interesting presentations $G(h)$, whose stability we are able to analyze.
Fix integers $m,t \in \N$ and let $q=2^t$ and $M = 2^m$. Let $\mP(q,m,d)$ be the vector space over $\F_q$ that consists of all $m$-variate polynomials $f$ over $\F_q$ of individual degree at most $d$, that is all functions of the form
\[
	f(x_1,\ldots,x_m) = \sum_{\alpha \in \{0,1,\ldots,d\}^m} c_\alpha\,
  x_1^{\alpha_1} \cdots x_m^{\alpha_m}\;,
\]
where $\{c_\alpha\}$ is a collection of coefficients in $\F_q$. It is easy to verify that $\mP(q,m,d)$ has dimension $k = (d+1)^m$ over $\F_q$. It follows that the linear span of all $(f(x))_{x\in \F_q^m}$, when ranging over all possible $\{c_\alpha\}$, defines a $[q^m,(d+1)^m,D]_q$ linear code over $\F_q$, where $D\geq (1-md/q)q^m$ follows from the Schwartz-Zippel lemma.

\begin{lemma}[Schwartz-Zippel lemma~\cite{Sch80,Zip79}]
  \label{lem:schwartz-zippel}
  Let $f, g: \F_q^m \to \F_q$ be two unequal polynomials with total degree at most $d$. Then
  \begin{equation*}
    \Pr_{x \sim \F_q^m}\big(f(x) = g(x)\big) \leq \frac{d}{q}\;.
  \end{equation*}
\end{lemma}

The resulting code is called the \emph{Reed-Muller code} $\code_\RM$ with parameters $q,m,d$. For $m=1$, one obtains the \emph{Reed-Solomon code} $\code_\RS$. A useful feature is that $\code_\RM$ can be seen as the $m$-fold tensor product of $\code_\RS$, i.e.\ $\code_\RM = \code_\RS^{\otimes m}$ as vector spaces over $\F_q$. 

We define a local linear tester $M_{\RM}$ for the code $\code_\RM$ over $\F_q$. The tester is described as an algorithmic procedure in Figure~\ref{fig:RM-tester}. %From this description it is straightforward to deduce a description of the tester as a distribution $\nu$ on subsets of $\F_q^n$, where $n=q^m$, together with vectors $v_S\in \F_q^S$ for every $S$ in the support of $\nu$. 
The description makes use of interpolation coefficients, which are defined as follows. Fix $d+1$ distinct values $t_0,\ldots,t_d \in \F_q$. Then for all $u,v \in \F_q$ and $i \in \{0,\ldots,d\}$ define the interpolation coefficients
 \begin{equation}\label{eq:interp-coeff}
 \alpha_{u,v,i} = \prod_{\substack{i'=0\\i'\neq i}}^{d}  \frac{v - (u + t_{i'})}{t_i - t_{i'}}~.
 \end{equation}
These are defined so that any polynomial $f:\F_q\to\F_q$ of degree at most $d$ satisfies
%\[ f(v)\,=\, \sum_{i=0}^{d} \alpha_{u,v,i} \, f(u+i)\;.\]
that for all $v \in \F_q$, 
\[ f(v)\,=\, \sum_{i=0}^{d} \alpha_{u,v,i} \, f(u+t_i)\;.\]

The tester verifies this relation along a randomly chosen \emph{axis-aligned direction}.  For all points $u \in \F_q^m$ and $j \in \{1,\ldots,m\}$, we say that the line through $u$ parallel to the $j$-th axis is the set of points $\{ u + te_j : t \in \F_q \}$ where $e_j=(0,\ldots,0,1,0,\ldots,0)\in \F_q^m$, where the unique $1$ is in the $j$-th position. 


\begin{figure}[!htbp]
  \centering
  \begin{gamespec}
Given access to some $g\in \F_q^n$, where $n=q^m$, identify $g$ with a function $g:\F_q^m\to \F_q$. Perform the following.
\begin{enumerate}
	\item Sample	$u\in \F_q^m$ and $j\in \{1,\ldots,m\}$ uniformly at random. Let $v$ be a uniformly random point on the line through $u$ parallel to the $j$-th axis.
	\item 
	Accept if and only if $g(v) = \sum_{i=0}^{d} \alpha_{u,v,i} g(u+t_i e_j)$. 
    \end{enumerate}
  \end{gamespec}
  \caption{A local test for $\code_{\RM}$}
  \label{fig:RM-tester}
\end{figure}

A parity check matrix $h_{\RM} \in \F^{S \times q^m}$ for $\code_{\RM}$, where $S = q^m \times m \times q$, is as follows. Identify the rows with triples $(u,j,t) \in \F_q^m \times \{1,\ldots,m\} \times \F_q$. The $(u,j,t)$-th row of $h_{\RM}$ is the vector in $\F_q^m$ that for $i \in \{0,\ldots,d\}$ has the value $\alpha_{u,v,i}$ for $v = u + t e_j$ in the coordinate indexed by $u + t_i e_j$, the value $-1$ in the coordinate indexed by $u + te_j$, and the value $0$ everywhere else. 

Rubinfeld and Sudan~\cite{rubinfeld1996robust} (building on the work of Babai, Fortnow, and Lund~\cite{babai1991non}) showed that $h_{\RM}$ is indeed a parity check matrix for $\code_{\RM}$. Furthermore, they showed that the parity check matrix gives rise to a $(d+2)$-local tester for $\code_{\RM}$. 

%\begin{theorem}\label{thm:mrm-sound}
%$M_\RM$ has quantum soundness $\delta(\eps)=\poly(m,d)\cdot \poly(\eps,n^{-1})$.
%\end{theorem}

%\begin{proof}
%In~\cite{ji2022quantum} it is shown that the game $G_{\code_\RM,M_\RM}$ (played using $\F_q$ as the base field) is $(\delta,\nu)$-robust, where $\nu$ is the uniform distribution over $\F_q^m \subseteq \mX$ and $\delta$ satisfies $\delta(\eps)=\poly(m,d)\cdot \poly(\eps,n^{-1})$. The theorem follows by the second item of Proposition~\ref{prop:sound-game}. 
%\end{proof}


\subsection{Code composition}
\label{sec:code-comp}

 The Reed-Muller code from the previous section is defined over $\F_q$, for $q$ a prime power. We can transform any $q$-ary code, for $q=2^t$, into a binary code using the idea of \emph{code composition} which we now describe. 

%For $q=2^t$ and $a\in \F_q$ we let $\kappa(a)\in\F_2^t$ denote binary representation of $a$, taken in a fixed but usually left implicit self-dual basis of $\F_{q}$ over $\F_2$. 

Let $\kappa: \F_q \to \F_2^t$ denote an invertible linear map such that $\kappa(a)$ is the $\F_2$-representation of $a \in \F_q$ over some (implicitly specified) self-dual basis of $\F_q$ over $\F_2$. We extend $\kappa$ and its inverse $\kappa^{-1}$ to vectors over $\F_q$ coordinate-wise. We let $\tr(\cdot):\F_q\to\F_2$ denote the trace over $\F_2$. Because we chose a self-dual basis for the binary representation, the trace satisfies $\tr(ab)=\kappa(a)\cdot\kappa(b)$  where the right-hand side means the $\F_2$-inner product of the vectors $\kappa(a), \kappa(b)$. For more details on the map $\kappa$ and its properties, see~\cite[Section 3.3]{ji2020mip}.

Let $q=2^t$ and $\code$ an $[n,k,d]_q$ linear code. Let $\code_{\Had}$ be the Hadamard code over $\F_2^t$ (introduced at the end of Section~\ref{sec:pres-code}). 
Let $\code'$ be the $[qn,tk,d']$ linear code over $\F_2$ defined as follows. Given $a\in (\F_2^t)^{k}$, first map $a\mapsto a'=\kappa^{-1}(a) \in \F_q^{k}$. Then encode $a'$ to $b'=\code(a')\in \F_q^n$. Finally, return $b=\code_\Had(\kappa(b'))\in(\F_2^q)^n$, where $\code_\Had$ is applied component-wise. Using that $\code_\Had$ has distance $q/2$, it is easy to verify that this code has distance $d'\geq dq/2$.

Given an $r$-local tester $M=(h,\nu)$ for $\code$, there is a natural $\max(r,3)$-local tester $M'$ for $\code'$ which can be described as follows. Index coordinates of $\code'$ by pairs $(i,\alpha)\in [n]\times\F_2^t$, fixing a bijection between $[qn]$ and $[n]\times \F_2^t$.  We describe an $r$-local \mnote{shouldn't this be max(r,3)-local} tester $M' = (h',\nu')$ for $\code'$. Informally, $h'$ contains two type of checks. First, the $A$-checks consist in the repetition of $n$ copies of the checks for the Hadamard code, one for each Hadamard-code encoding of an $\F_q$-symbol from $\code$. Second, the $B$-checks implement the checks of $\code$ specified by $M$, directly on the Hadamard encoding. More precisely, define $h'$ to be the block matrix $h'=\begin{pmatrix} A \\ B \end{pmatrix}$ where 
\begin{itemize}
	\item $A \in \F^{nq^2 \times nq}$ is itself a block-diagonal matrix where the diagonal blocks are the $q^2 \times q$ parity check matrix for the Hadamard code. 
	In other words, $A$ can be viewed as $I_{n\times n} \otimes h_\had$ where $h_\had \in \F_2^{q^2 \times q}$ is the parity check matrix for the Hadamard code. 
	\item $B \in \F^{\ell q \times nq}$ is viewed as having rows indexed by pairs $(p,\gamma) \in \{1,\ldots,\ell\} \times \F_q$ and columns indexed by pairs $(i,x) \in \{1,\ldots,n\} \times \F_2^t$. The entry in row $(p,\gamma)$ and column $(i,x)$ is $1$ if and only if $h_{pi} \neq 0$ and $x = \kappa(\gamma h_{pi})$.
\end{itemize}
Define the distribution $\nu'$ as the uniform mixture of the uniform distribution on the rows of the $A$ block matrix and the uniform distribution on the rows of the $B$ block matrix. 

\begin{claim}
$h'$ is a parity check matrix for $\code'$.
\end{claim}

\begin{proof}
Let $x\in \F_2^{qn}$ be such that $h'x=0$. Since the $A$-checks enforce that each block of $k$ symbols contains the Hadamard-code encoding of an $\F_q$ symbol, $x$ can be decoded to $x'\in \F_q^n$ such that for each $(i,x)\in \{1,\ldots,n\}\times \F_2^t$, $x_{(i,x)} = \kappa(x'_i)\cdot x$. If the $p$-th row of $h$ enforces the check $v_p\cdot x'=0$, where $v_p\in \F_q^n$, then 
the $(p,\gamma)$-th row of $B$ enforces the check 
\begin{align*}
0&=\sum_{j=1}^n \kappa(\gamma (v_p)_j) \cdot \kappa(x'_j)\\
&= \sum_{j=1}^n \tr( \gamma (v_p)_j x'_j) \\
&= \tr(\gamma (v_p\cdot  x')\;.
\end{align*}
Therefore, $h'x=0$ is equivalent to $\tr(\gamma(v_p \cdot x'))=0$ for all $\gamma$, which is equivalent to $v_p\cdot x'=0$. Thus $\code'=\ker h'$, as desired. 
\end{proof}

\section{An efficient presentation for $\Z_2^k$}
\label{sec:eff-z2k}

Fix integers $m,t,d \in \N$ and let $q=2^t$. Let $\code_{\bRM}$ be the $[q^{m+1},t(d+1)^m,D']$ code obtained by applying the composition procedure from Section~\ref{sec:code-comp} to the $[q^m,(d+1)^m,D]_q$ Reed-Muller code $\code_\RM$ from Section~\ref{sec:rmq}. Let $N=q^{m+1}$ and $h_{\bRM}\in \F_2^{M\times N}$ the parity check matrix for $\code_{\bRM}$ obtained from the composition of the $(d+2)$-local tester for $\code_\RM$ with the $3$-local tester for $\code_\had$. Then $h_\bRM$ has $M=  q^{m+2}(1+m)$ rows, such that each row has at most $(d+2)$ nonzero entries. 
\Cref{fig:bRM-tester} presents an algorithmic interpretation of the local tester corresponding to the parity check matrix $h_{\bRM}$. 

 %Explicitly, $h_\bRM$ is the parity check matrix that arises from the tester described in Figure~\ref{fig:bRM-tester}. 

\begin{figure}[!htbp]
  \centering
  \begin{gamespec}
Given access to some $g\in \F_2^{N}$, where $n=N^{m+1}$, identify $g$ with a function $g:(\F_2^t)^m \times \F_2^t \to \F_2$. Perform one of the following tests with probability~$\tfrac{1}{2}$ each. 
\begin{enumerate}
	\item \textbf{Low-degree test:}
		Let $u \in \F_q^m$ be a uniformly random point and $j\in \{1,\ldots,m\}$ chosen uniformly at random. Let $\ell$ be the line through $u$ in the $j$-th direction. Let $e_j=(0,\ldots,0,1,0,\ldots,0)\in \F_q^m$, where the unique $1$ is in the $j$-th position. Choose a uniformly random $v\in \ell$ and $\gamma\in \F_q$ and check that 
		\[\sum_{i=0}^d g(u+t_i e_j,\kappa(\gamma \alpha_{u,v,i})) \,=\, g(v,\kappa(\gamma))\;,\]
		where the interpolation points $t_0,\ldots,t_d \in \F_q$ and the $\alpha_{u,v,i}$ are defined in~\eqref{eq:interp-coeff}.
	\item \textbf{Hadamard test:} Let $u\sim\F_q^m$ be chosen uniformly at random and $\alpha,\beta\in \F_2^t$ chosen uniformly at random. Check that 
	\[g(u,\alpha)+g(u,\beta)\,=\,g(u,\alpha+\beta)\;.\] 	
    \end{enumerate}
  \end{gamespec}
  \caption{A local test for $\code_{\bRM}$}
  \label{fig:bRM-tester}
\end{figure}

Let $G_\bRM = G(h_\bRM)$ be the group that is presented from $h_\bRM$ (recall from \Cref{sec:pres-code} that codes give rise to group presentations through the general construction~\eqref{eq:def-gh-pres}). We do not know if $G_\bRM = \Z_2^K$, with $K=t(d+1)^m$. Instead we modify the presentation $G(h_\bRM)$ by adding pairwise commutation relations in a similar manner as the presentation from Lemma~\ref{lem:com-code}. Let 
\[ G(h_\bRM) \,=\, \big\langle x_1,\ldots,x_N \;:\; \{R^\sq_k\}\,,\; \{R^\ld_k\}\,,\; \{R^\had_{k}\} \big\rangle\;,\]
where  $R^\sq_k$ ranges overal all relations of the form $x_i^2=e$ for $i\in \{1,\ldots,N\}$, $R^\ld_k$ ranges over all relations implied by the ``low-degree test'' in Figure~\ref{fig:bRM-tester} and $R^\had_{k}$ ranges over all the relations implied by the ``Hadamard test.'' For $k=(i,j)\in\{1,\ldots,N\}^2$ such that $i<j$ let $R^\com_k$ be the relation $[x_i,x_j]=e$.
Then we define
\begin{equation}\label{eq:z2k-eff}
 G' \,=\,\big\langle x_1,\ldots,x_N \;:\; \{R^\sq_k\}\,,\; \{R^\ld_k\}\,,\; \{R^\had_{k}\}\, , \; \{ R^\com_k\}\big\rangle\;.
\end{equation}
From Lemma~\ref{lem:com-code} it follows that $G'=\Z_2^K$. Our main result is an efficient stability result for this presentation. To state this we need to introduce distributions $\mu_S$ and $\mu_R$ on the generators and relations of $G'$. The distribution $\mu_R$ is obtained as follows. With probability $1/4$ each, a relation from $\{R^\sq_k\}$, $\{R^\ld_k\}$ or $\{R^\had_k\}$ is chosen uniformly at random. With probability $1/4$, a random commutation relation from $R^\com_k$ is chosen according to the uniform mixture of the following two distributions:
\begin{enumerate}
\item For the first distribution, we select $u\in \F_q^m$ uniformly at random, $j\in\{1,\ldots,m\}$ uniformly at random, and $i\neq i'\in\{0,\ldots,d\}$ uniformly at random. Then select $\alpha,\beta\in \F_2^t$ uniformly at random and check commutation between $x_{u+t_i e_j,\alpha}$ and $x_{u+t_{i'} e_j,\beta}$, where we interpret the subscripts  $u+t_i e_j,\alpha$ and $u+t_{i'} e_j,\beta$ as corresponding to some integer in $[N]= (\F_2^t)^m \times \F_2^t$ (as sets!). 

\item For the second distribution, we first select $j\in\{1,\ldots,m\}$ and $u_{m-j+2},\ldots,u_m \in \F_2^t$ uniformly at random. Then select $v,v' \in (\F_2^t)^m$ uniformly at random, conditioned on the last $(j-1)$ coordinates of each vector matching $u_{m-j+2},\ldots,u_m$. Finally, select $\alpha,\beta\in \F_2^t$ uniformly at random and check commutation between $x_{v,\alpha}$ and $x_{v',\beta}$. 
\end{enumerate}
Having defined $\mu_R$, we define $\mu_S$ as in Remark~\ref{rk-mus}. It is easy to check that in this way we obtain that $\mu_S$ is the uniform distribution over $[N] $. The following is our main technical result. 

\begin{theorem}\label{thm:z2-stab}
Let $\mC$ be the class of all tracial von Neumann algebras. 
The presentation of  $\Z_2^K$ given in~\eqref{eq:z2k-eff}, together with the distributions $\mu_S$ and $\mu_R$ defined above, is $(\delta,\mC)$ stable with $\delta(\eps)=\poly(m,d,t) \cdot\poly(\eps,q^{-1})$. 
\end{theorem}

We briefly explain a possible setting of parameters in Theorem~\ref{thm:z2-stab}. For any integer $t\geq 1$, fix $q=2^t$ and let $d=m=c t^c$ for some constant $c>0$. Then $K=t(d+1)^m = 2^{\Theta((\log q)^c \log\log q)}$ and $N=q^{m+1}= 2^{\Theta((\log q)^{c+1} \log\log q)}$. Moreover, the number of relations in~\eqref{eq:z2k-eff} is $O(N^2)$, which scakes as $2^{\poly\log K}$; and the maximum length of a relation is $d=O(\log K)$. Finally, with this choice of parameters the function $\delta(\eps)$ scales as $\poly(\log K)\cdot \poly(\eps)$. We have thus obtained a presentation of $\Z_2^K$ of size only mildly superpolynomial in $K$, and with soundness that depends polylogarithmically on $K$. 


\begin{proof}
Let $(\mM,\tau)$ be a tracial von Neumann algebra and $\phi$ be an $\eps$-homomorphism of $\langle S:R\rangle$ on $(\mM,\tau)$. 
 Here, $S = \{s_{u,a}: u\in (\F_2^t)^m, a\in \F_2^t\}$. We sometimes enumerate the items of $S$ as $S=\{x_i: i\in\{1,\ldots,N\}\}$, where $N=2^{tm+t}$ and we fixed an arbitrary bijection between $(\F_2^t)^m\times \F_2^t$ and $\{1,\ldots,N\}$. Let $R$ be the set of all relations in~\eqref{eq:z2k-eff}, i.e.\ $R= \{R_k^\sq\}\cup \{R^\ld_k\}\cup\{R^\had_k\}\cup\{R^\com_k\}$. Let $N=|S|$.

The proof strategy is to perform a reduction to~\cite[Theorem 4.1]{ji2022quantum}. Towards this, the main technical work in the proof consists in using the unitaries $\phi(s_{u,a})$ in order to define a synchronous strategy in the tensor code test from~\cite{ji2022quantum}, where the underlying code is the Reed-Solomon code with degree $d$ over $\F_q$. To define the synchronous strategy, we need ``points,'' ``lines,'' and ``pair'' measurements (see~\cite{ji2022quantum} for the terminology). Each of these is a family of projective measurements that obey certain constraints. 

The proof consists of a sequence of claims, which examine the constraints imposed on the $\phi(s_{u,a})$ by each of the four collections of relations in~\eqref{eq:z2k-eff} in turn, each time using a set of relations to evidence a particular structure among these unitaries. Eventually, this will allow us to define the required families of projective measurements from them. 

We first exploit the relations $R_k^\sq$ to show that we may assume without loss of generality that $\phi$ sends each element of $S$ to a Hermitian involution. 

\begin{claim}\label{claim:z2-stab-1}
There is an $\eps^{(1)}=O(d^2\eps)$ and an $\eps^{(1)}$-homomorphism $\phi^{(1)}$ of $\langle S:R\rangle$ on $(\mM,\tau)$ such that $\phi^{(1)}(x)$ is a Hermitian involution for all $x\in S$, and furthermore
\begin{equation}\label{eq:z2-stab-1a}
 \Es{x\sim\mu_S} \big\| \phi(x) - \phi^{(1)}(x) \big\|_\tau^2 \,\leq\, \eps^{(1)}\;.
\end{equation}
\end{claim}

\begin{proof}
Using elementary calculations (see e.g.~\cite[Lemma 3.6]{slofstra2019set}) we see that for any complex $\alpha$, 
\[ \big| \sgn\Re\alpha-\alpha\big| \,\leq\, \Big(1+\frac{1}{\sqrt{2}}\Big) \big|\alpha^2 -1 \big|\;.\]
For any $i\in \{1,\ldots,N\}$ let $\phi^{(1)}(x_i) = \sgn\Re (\phi(x_i))$. Then the claim follows since 
\[ \Es{i\in\{1,\ldots,N\}} \big\| \phi(x_i)^2-\Id \big\|_\tau^2 \,\leq\, 4\eps\;,\]
by assumption and the definition of $\mu_R$, which places weight $\frac{1}{4}$ on the relations in $R_k^\sq$. Since $\mu_S$ is uniform on $S$,~\eqref{eq:z2-stab-1a} follows. Furthermore, because all relations in $R$ have length at most $O(d)$, and $\mu_S$ is defined from $\mu_R$ as in Remark~\ref{rk-mus}, a simple averaging argument shows that $\phi^{(1)}$ is an $O(d^2\eps)$-homomorphism of $\langle S:R\rangle$ (here the factor $d^2$, as opposed to $d$, is because of the way that the error is measured in Definition~\ref{def:approx-hom}).
\end{proof}

For ease of notation we relabel $\phi^{(1)}$ and $\eps^{(1)}$ as $\phi$ and $\eps$ respectively. Next we exploit the relations $\{R^\had_k\}$ to show the following. Recall that $q=2^t$.

\begin{claim}\label{claim:z2-stab-2}
For every $u\in \F_q^m$ there is a projective measurement $\{P^u_\beta\}_{\beta\in \F_{q}}$ on $\mM$ such that 
\begin{equation}\label{eq:z2-stab-2}
 \Es{u\in \F_q^m} \Es{a\in \F_2^t} \Big\| \phi(s_{u,a}) - \sum_{\beta\in\F_q} (-1)^{a \cdot \kappa(\beta)} P^u_\beta \Big\|_\tau^2 \,=\, O(\eps)\;. 
\end{equation}
\end{claim}

\begin{proof}
Since $\mu_R$ places weight $1/4$ on relations $\{R^\had_k\}$ we deduce that 
\begin{equation}\label{eq:stab-rm-1}
\Es{u\in \F_q^m} \Es{a,b\in \F_2^t} \big\|\phi(s_{u,a})\phi(s_{u,b})\phi(s_{u,a+b})-\Id\big\|_\tau^2 \,\leq\, 4\eps\;. 
\end{equation}
Fix an $u\in \F_q^m$ and apply Lemma~\ref{lem:had-stab} for that $u$. This gives a partial isometry $w\in P\mM_\infty\Id_\mM$ and a unitary representation $\{U_a\}$ of $\Z_2^t$ on $\mN=P\mM_\infty P$ (both depending on $u$) such that 
\begin{equation}\label{eq:stab-rm-1b}
 \Es{a \in \F_2^t} \big\| \phi(s_{u,a}) - w^* U_a w \big\|_\tau^2 \,=\, O(\eps_u)\;,
\end{equation}
where $\eps_u\geq 0$ is such that $\Es{u\in \F_q^m} \eps_u = 4\eps$. Because $\{U_a\}$ are a representation of the abelian group $\Z_2^t$, there is a projective measurement $\{Q^u_b\}_{b\in \F_2^t}$ on $\mN$ such that $U_a = \sum_b (-1)^{a\cdot b} Q^u_b$. ($\{Q^u_b\}$ can be found explicitly by applying the Fourier transform, i.e.\ $Q^u_b = \sum_\alpha (-1)^{a \cdot b} U_a$.) Applying Lemma~\ref{lem:pull-back}, we deduce a projective measurement $\{P^u_\beta\}_{\beta\in \F_q}$ on $\mM$ such that (by the triangle inequality)
\begin{align*}
 \Es{a \in \F_2^t} \Big\| \phi(s_{u,a}) - \sum_{\beta\in\F_q} (-1)^{a \cdot \kappa(\beta)} P^u_\beta \Big\|_\tau^2
&\leq 2 \Es{a \in \F_2^t} \Big( \Big\| \phi(s_{u,a}) - w^*\Big(\sum_{b\in\F_2^t} (-1)^{\alpha \cdot b} Q^u_b \Big) w \Big\|_\tau^2 \\
&\qquad\qquad+   \Big\|  \sum_{b\in\F_2^t} (-1)^{a \cdot b} w^* Q^u_b w - \sum_{\beta\in\F_q} (-1)^{a \cdot \kappa(\beta)} P^u_\beta \Big\|_\tau^2\Big)\\
 &\leq\, O(\eps_u) +  \sum_{\beta\in\F_q} \Big\| w^* Q^u_{\kappa(\beta)} w - P^u_{\beta} \Big\|_\tau^2\\
&\leq O(\eps_u)\;,
\end{align*}
where the first inequality follows from the triangle inequality, the second is by~\eqref{eq:stab-rm-1b} for the first term and Parseval's identity (as in the derivation~\eqref{eq:lin-test-2}) for the second, and the last by the guarantees obtained from Lemma~\ref{lem:pull-back}. Averaging over $u$ gives the desired result.
\end{proof}

%\tnote{changed this, and modified everything downstream}
For $u\in \F_q^m$ let $\{P^{u}_\beta\}_{\beta \in \F_q}$ be the projective measurement obtained from Claim~\ref{claim:z2-stab-2}. For $\alpha\in \F_q$, let  
\[ U_{u,\alpha} = \sum_{\beta\in\F_q} (-1)^{\tr(\alpha\beta)} P^u_{\beta}\;.\]
%where $\omega_q = e^{2i\pi/q}$. (\tnote{added:}To define $\omega_q^\beta$ for $\beta\in \F_q$, we use the representative of $\beta$ in $\{0,\ldots,q-1\}$.)
Then $U_{u,\alpha} \in \mU(\mM)$. 

%We observe that
%\begin{equation}\label{eq:z2-stab-2a}
%\Es{u\in\F_q^m}\Es{\alpha\in \F_q} \big\| U_u^\alpha - \phi(s_{u,\kappa(\alpha)})\big\|_\tau^2 \,=\, O(\eps)\;.
%\end{equation}
%To see this, observe that for any $\alpha\in \F_q$, $\omega_q^\alpha = (-1)^{\tr(\alpha)}$. Thus from the definition of $U_u$ we get
%\begin{align*}
%U_u^\alpha &= \sum_\beta \omega_q^{\alpha\beta} P^u_\alpha\\
 %&= \sum_\beta (-1)^{\tr(\alpha\beta)} P^u_\alpha\\
%&= \sum_\beta (-1)^{\alpha\cdot \beta} P^u_\alpha\;,
%\end{align*}
%where in the last line we slightly abused notation and identified $\alpha,\beta\in\F_q$ with $\kappa(\alpha),\kappa(\beta)\in \F_2^t$ respectively. \eqref{eq:z2-stab-2a} then follows from~\eqref{eq:z2-stab-2}.

The next claim uses the relations $\{R^\com_k\}$.

\begin{claim}\label{claim:z2-stab-2b}
For $u\in \F_q^m$, $\alpha\in\F_q$, $j\in\{1,\ldots,m\}$ and $i\in \{0,\ldots,d\}$ let $U_{i,\alpha} = U_{u+t_ie_j,\alpha}$ and, for all $\beta\in\F_q$, $P^{(i)}_\beta = P^{u+t_ie_j}_\beta$ (leaving the dependence on $u$ and $j$ implicit). Then 
\begin{equation}\label{eq:z2-stab-2b-0a}
\Es{u\in \F_q^m} \Es{\substack{j\in\{1,\ldots,m\}\\i\neq i' \in \{0,\ldots,d\}}}\Es{\alpha,\alpha'\in \F_q} \big\| \big[ U_{i,\alpha}, U_{i',\alpha'}\big]-\Id\big\|_\tau^2\,=\, O\big(\sqrt{\eps}\big)\;, 
\end{equation}
and
\begin{equation}\label{eq:z2-stab-2b-0b}
 \Es{u\in \F_q^m} \Es{j\in\{1,\ldots,m\}} \Es{\substack{v\in \F_q^m \\v_{m-j+2}=u_{m-j+2},\ldots,v_m=u_m}}\Es{\alpha,\alpha'\in \F_q} \big\| \big[ U_{u,\alpha}, U_{v,\alpha'}\big]-\Id\big\|_\tau^2\,=\, O\big(\sqrt{\eps}\big)\;,
\end{equation}
where the expectation is over a uniformly random $u$ and $j$, and a uniformly random $v$ conditioned on its last $(j-1)$ coordinates matching those of $u$, and $[U,V]=UVU^* V^*$ is the group commutator. 
\end{claim}

\begin{proof}
Due to the test of the relations $\{R^\com_k\}$, it holds that 
\begin{align}
\Es{u\in \F_q^m} \Es{\substack{j\in\{1,\ldots,m\} \\ i\neq i' \in \{0,\ldots,d\}}} \Es{a,b\in \F_2^t} \big\| [\phi(s_{u+t_i e_j,a}),\phi(s_{u+t_{i'} e_j,b})] - \Id \big\|_\tau^2&\leq 8\eps\; ,\label{eq:z2-stab-2b-1}\\
\Es{u\in \F_q^m} \Es{j\in\{1,\ldots,m\}} \Es{\substack{v\in \F_q^m \\v_{m-j+2}=u_{m-j+2},\ldots,v_m=u_m}}\Es{a,b\in \F_2^t} \big\| [\phi(s_{u,a}),\phi(s_{v,b})]-\Id\big\|_\tau^2&\leq 8\eps\;.\label{eq:z2-stab-2b-1b}
\end{align}
Now, for any $u,v\in \F_q^m$
\begin{align*}
 &\Es{\alpha,\alpha'\in \F_q}\tau\big( U_{u,\alpha} U_{v,\alpha'} U_{u,-\alpha} U_{v,-\alpha'} \big) \\
&= \sum_{\beta,\beta',\gamma,\gamma'\in \F_q}\Es{\alpha\in \F_q} (-1)^{\tr(\alpha(\beta-\beta'))} \Es{\alpha'\in \F_q} (-1)^{\tr(\alpha'(\gamma-\gamma'))}  \tau(P^{u}_\beta P^{v}_\gamma P^{u}_{\beta'} P^{v}_{\gamma'}\big)\\
&=\sum_{\beta,\beta',\gamma,\gamma'\in \F_q}\Es{a\in\F_2^t} (-1)^{a\cdot\kappa(\beta-\beta')} \Es{a'\in\F_2^t} (-1)^{a'\cdot\kappa(\gamma-\gamma')} \tau(P^{u}_\beta P^{v}_\gamma P^{u}_{\beta'} P^{v}_{\gamma'}\big)\\
&=\Es{a,a'\in\F_2^t}  \tau\Big( \Big(\sum_{\beta\in \F_q} (-1)^{a\cdot \kappa(\beta)} P^{u}_\beta\Big) \Big(\sum_{\gamma\in \F_q} (-1)^{a'\cdot \kappa(\gamma)} P^{v}_\gamma\Big)\Big(\sum_{\beta'\in \F_q} (-1)^{a\cdot \kappa(\beta')} P^{u}_{\beta'}\Big)\Big(\sum_{\gamma'\in \F_q} (-1)^{a'\cdot \kappa(\gamma')} P^{v}_{\gamma'}\Big)\Big)\;.
\end{align*}
It follows that, for any distribution on $(u,v)$ such that both marginals are uniform over $\F_q^m$,
\begin{align}
\Es{u,v} \Es{\alpha,\alpha'\in \F_q} \big\| [U_{u,\alpha} ,U_{v,\alpha'} ]-\Id\big\|_\tau^2
&= \Es{u,v}\Es{a,a'\in \F_2^t} \Big\| \Big[\sum_{\beta\in \F_q} (-1)^{a\cdot \kappa(\beta)} P^{u}_\beta ,\sum_{\beta'\in \F_q} (-1)^{a'\cdot \kappa(\beta')} P^{v}_{\beta'} \Big]-\Id\Big\|_\tau^2\notag\\
&= \Es{u,v}\Es{a,a'\in \F_2^t} \big\| \big[ \phi(s_{u,a}),\phi(s_{v,a'})\big]-\Id\big\|_\tau^2+O\big(\sqrt{\eps}\big)\;,\label{eq:z2-stab-2b-1d}
\end{align}
where the first line is by expanding the square and using~\eqref{eq:z2-stab-2b-1d} and the second line follows from Claim~\ref{claim:z2-stab-2} and the triangle inequality. Thus~\eqref{eq:z2-stab-2b-0a} follows from~\eqref{eq:z2-stab-2b-1}, and~\eqref{eq:z2-stab-2b-0b} follows from~\eqref{eq:z2-stab-2b-1b}.
\end{proof}

Now we show the following, which essentially follows from the previous claim. 

\begin{claim}\label{claim:z2-stab-3}
For every $u\in \F_q^m$ and $j\in\{1,\ldots,m\}$, there is a projective measurement $\{R^{u,j}_\alpha\}_{\alpha\in\F_q^{d+1}}$ on $\mM$ such that 
\[ \Es{u\in \F_q^m} \Es{j\in\{1,\ldots,m\}} \Es{z_0,\ldots,z_{d}\in \F_q} \Big\| U_{0,z_0}\cdots U_{d,z_d} -  \sum_{\alpha} (-1)^{\tr(\sum z_i\alpha_i)} R^{u,j}_\alpha\Big\|_\tau^2 \,=\, \poly(d,\eps)\;.\]
Similarly, for any $u,v\in \F_q^m$ there is a projective measurement $\{R^{u,v}_{\alpha,\beta}\}_{(\alpha,\beta)\in\F_q^{2}}$ on $\mM$ such that 
\[  \Es{u\in \F_q^m} \Es{j\in\{1,\ldots,m\}} \Es{\substack{v\in \F_q^m \\v_{m-j+2}=u_{m-j+2},\ldots,v_m=u_m}} \Es{y,z\in \F_q} \Big\| U_{u,z}  U_{v,y} -  \sum_{\alpha} (-1)^{ \tr(\alpha z + \beta y)} R^{u,v}_{\alpha,\beta}\Big\|_\tau^2 \,=\, \poly(\eps)\;.\]
\end{claim}

\begin{proof}
We show the first part only, as the second part is analogous. Fix an $u\in \F_q^m$ and a direction $j\in \{1,\ldots,m\}$. Define
$\psi: (\Z_2^{t})^{d+1} \to \mU(\mM)$ by 
\[\psi(z_0,\ldots,z_{d}) \,=\, U_{0,z_0} \cdots U_{d,z_{d}}\;,\]
where for each $i\in\{0,\ldots,d\}$ and $z_i\in \F_q$, $U_{i,z_i}$ is the unitary defined in Claim~\ref{claim:z2-stab-2b} and we slightly abused notation to identify $z_i\in \Z_2^t$ with the unique $\tilde{z}_i\in \F_q$ such that $\kappa(\tilde{z}_i)=z_i$. Using Claim~\ref{claim:z2-stab-2b} and the triangle inequality we verify that the map $\psi$ is a $\delta=O(d^4\sqrt{\eps})$-approximate homomorphism of $\Z_2^{t(d+1)}$ on $\mU(\mA)$, with respect to the multiplication table presentation. To verify this first note that for any unitaries $V,W$, and any $i,i'$ we have that on average over $u$ and $j$,
\begin{align*}
\Es{\alpha,\alpha'\in \F_q} \big\| V U_{i,\alpha} U_{i',\alpha'} W^* - V U_{i',\alpha'} U_{i,\alpha}  W^*\big\|_\tau^2 \,=\, O\big(d^2 \sqrt{\eps}\big)\;,
\end{align*}
by Claim~\ref{claim:z2-stab-2b}, where the factor $d^2$ is because we require the relation to hold for all $i,i'$. Moreover, $U_{i,\alpha}U_{i,\alpha'}=U_{i,\alpha+\alpha'}$ by definition. Applying these relation $O(d^2)$ times gives
\begin{align*}
 \Es{z_0,\ldots,z_d\in\F_2^t}\Es{y_0,\ldots,y_d\in\F_2^t}\big\|\psi(z_0,\ldots,z_d)\psi(y_0,\ldots,y_d) -\psi(z_0+y_0,\ldots,z_d+y_d)\big\|_\tau^2 \,=\, O\big(d^4 \sqrt{\eps}\big)\;,
\end{align*}
as desired.
Thus we may apply Theorem~\ref{thm:gh} to obtain a partial isometry $w\in P\mM_\infty\Id_\mM$ and a family of commuting unitaries $\{V_{i,k}\}$ of order $2$ each on $\mN=P\mM_\infty P$ such that, on average over $u$ and $j$, defining $V_i^z = \prod_{k=1}^t V_{i,k}^{z_k}$,
\begin{equation}\label{eq:z2-stab-3-1}
\Es{z_0,\ldots,z_{d}\in\F_2^t} \big\| \psi(z_0,\ldots,z_{d+1}) - w^* V_0^{z_0}\cdots V_{d}^{z_{d}} w \big\|_\tau^2 \,=\, \poly(d,\eps)\;.
\end{equation}
Because $\{V_{i,z}\}$ are a representation of $\Z_2^{t(d+1)}$ (which is Abelian), there is a projective measurement $\{Q_\alpha\}_{\alpha\in \Z_2^{t(d+1)}}$ on $\mN$ such that for each $i\in\{0,\ldots,d\}$, 
\[ V_{i}^{z} \,=\, \sum_{\alpha\in (\Z_2^{t})^{d+1}} (-1)^{\alpha_{i}\cdot z} Q_\alpha\;,\]
and  
\[ V_{0}^{z_0}\cdots V_{d}^{z_{d}}  \,=\, \sum_{\alpha\in (\Z_2^{t})^{d+1}} (-1)^{\sum \alpha_{i}\cdot z_i} Q_\alpha\;.\]
Identifying $\alpha$ with an element of $\F_q^{d+1}$, and interpreting $z_i$ as an element of $\F_q$ as well,
 the preceding equation can be rewritten as
\[ V_{0}^{z_0}\cdots V_{d}^{z_{d}}  \,=\, \sum_{\alpha\in \F_q^{d+1}} (-1)^{\tr(\sum \alpha_{i} z_i)} Q_\alpha\;.\]

%($\{Q^u_\alpha\}$ can be found explicitly by applying the Fourier transform.) 
Applying Lemma~\ref{lem:pull-back}, we deduce a projective measurement $\{R^{u,j}_\alpha\}_{\alpha\in \F_q^{d+1}}$  on $\mM$ such that by~\eqref{eq:z2-stab-3-1}, on average over $u$ and $j$,
\[  \Es{z_0,\ldots,z_{d}\in\F_q} \Big\| \psi(z_0,\ldots,z_{d}) -  \sum_{\alpha\in \F_q^{d+1}} (-1)^{\tr(\sum z_i\alpha_i)} R_\alpha^{u,j}\Big\|_\tau^2 \,=\, \poly(d,\eps)\;.\]
\end{proof}



Finally we exploit the relations $\{R^\ld_k\}$ to obtain the following. 

\begin{claim}\label{claim:z2-stab-5}
Use the same notation as in Claim~\ref{claim:z2-stab-2b}. Let $u\in \F_q^m$, $\ell$ an axis-parallel line through $u$ and $v\in\ell$. Let $(\alpha_{u,v,i})_{i=0,\ldots,d}$ be the interpolation coefficients defined in~\eqref{eq:interp-coeff}. %Let $U_v = \sum_\beta \omega^\beta P^v_\beta$. 
Then 
\begin{equation}\label{eq:z2-stab-5-0}
\Es{u\in\F_q^m} \Es{\ell: u\in \ell} \Es{v\in \ell} \Es{\gamma\in\F_q} \Big\| U_{0,\gamma \alpha_{u,v,0}}\cdots U_{d,\gamma  \alpha_{u,v,d}} - U_{v,\gamma} \big\|_\tau^2 \,=\, O\big(d\sqrt{\eps}\big)\;,
\end{equation}
where the expectation is over a uniformly random axis-parallel line that contains $u$, and a uniformly random $v\in\ell$. 
\end{claim}

\begin{proof}
Write $\alpha_i$ for $\alpha_{u,v,i}$. 
We observe that 
\begin{align*}
\Es{\gamma\in\F_q} \tau\big( U_{0,\gamma\alpha_{0}}\cdots U_{d,\gamma\alpha_{d}} U_{v,-\gamma} \big)
&=  \sum_{\beta_0,\ldots,\beta_d\in\F_q}\sum_{\beta\in\F_q} \Es{\gamma\in\F_q} (-1)^{\tr(\sum \gamma \alpha_i\beta_i)} (-1)^{\tr(-\gamma\beta)} \tau\big( P^{(0)}_{\beta_0} \cdots P^{(d)}_{\beta_d} P^v_\beta \big)\\
&= \sum_{\beta_0,\ldots,\beta_d\in\F_q}\sum_{\beta\in\F_q}\Es{\gamma\in\F_2^t} (-1)^{\gamma\cdot \kappa(\sum \alpha_i\beta_i-\beta)} \tau\big( P^{(0)}_{\beta_0} \cdots P^{(d)}_{\beta_d} P^v_\beta \big)\\
&=\Es{\gamma\in\F_2^t}  \tau\Big( \Big(\sum_{\beta_0\in \F_q} (-1)^{\gamma\cdot \kappa(\alpha_0\beta_0)} P^{(0)}_{\beta_0} \Big)\cdots\Big(\sum_{\beta\in \F_q} (-1)^{-\gamma\cdot \kappa(\beta)} P^{v}_{\beta} \Big)\Big)\\
&=\Es{\gamma\in\F_q}  \tau\Big( \Big(\sum_{\beta_0\in \F_q} (-1)^{\kappa( \gamma \alpha_0)\cdot\kappa(\beta_0)} P^{(0)}_{\beta_0} \Big)\cdots\Big(\sum_{\beta\in \F_q} (-1)^{\kappa(-\gamma)\cdot \kappa(\beta)} P^{v}_{\beta} \Big)\Big)\;.
\end{align*}
By repeated application of Claim~\ref{claim:z2-stab-2}, the last expression is within $O(d\sqrt{\eps})$ of 
\[ \Es{\gamma\in\F_q}  \tau\big( \phi(s_{u+t_ie_j,\kappa(\gamma \alpha_0)})\cdots \phi(s_{v,\kappa(-\gamma)}) \big)\;.\]
The latter expression is a random relation in $R^\ld_k$, and so, on average over $u,j$ and $v$ it is $1-O(\eps)$.
\end{proof}


\begin{claim}\label{claim:z2-stab-4}
For every axis-parallel line $\ell$ there is a projective measurement $\{Q^\ell_g\}$ with outcomes $g \in \cal{P}(q,1,d)$ that range over degree-$d$ polynomials on $\ell$ such that
\[ \Es{\ell\subset \F_q^m} \Es{v\in \ell} \sum_g \tau\big( P^v_{g(v)} Q^\ell_g\big) \,\geq\, 1-\poly(d,\eps)\;, \]
where the expectation is over a uniformly random axis-parallel line $\ell$ and point $v\in \ell$. 
\end{claim}

\begin{proof}
First we show that the conclusion of Claim~\ref{claim:z2-stab-3} can be strengthened to hold for \emph{every} $z_0,\ldots,z_{d}$, instead of on average. To show this, note that for any $y_0,\ldots,y_d\in \F_q$ we can write 
\[ U_{0,z_0}\cdots U_{d,z_d}\,=\, U_{0,y_0}U_{0,z_0-y_0}\cdots U_{d,y_d}U_{d,z_d-y_d}\;.\]
By repeated application of Claim~\ref{claim:z2-stab-2b}, the term on the right-hand side satisfies 
\[ \big\| U_{0,y_0}U_{0,z_0-y_0}\cdots U_{d,y_d}U_{d,z_d-y_d}  - U_{0,y_0}\cdots U_{d,y_d}U_{0,z_0-y_0}\cdots U_{d,z_d-y_d}\big\|_\tau^2 \,=\,\poly(d,\eps)\;.\]
To show this it suffices to verify that we only need to ``commute'' pairs of terms whose exponents are independent and uniformly random. Using Claim~\ref{claim:z2-stab-3} twice, the right-hand side satisfies 
\[ \big\| U_{0,y_0}\cdots U_{d,y_d}U_{0,z_0-y_0}\cdots U_{d,z_d-y_d} - \Big(\sum_{\alpha} \omega^{\tr(\sum y_i\alpha_i)} R^{u,j}_\alpha\Big)\Big(\sum_{\alpha} (-1)^{\tr(\sum (z_i-y_i)\alpha_i)} R^{u,j}_\alpha\Big) \big\|_\tau^2 \,=\,\poly(d,\eps)\;.\]
Since $\{R^{u,j}_\alpha\}$ is a projective measurement, we get the desired conclusion: on average over $u$ and $j$, for any $z_0,\ldots,z_d\in\F_q$, it holds that
\begin{equation}\label{eq:z2-stab-4-1}
 \Big\| U_{0,z_0}\cdots U_{d,z_d} -  \sum_{\alpha} (-1)^{\tr(\sum z_i\alpha_i)} R^{u,j}_\alpha\Big\|_\tau^2 \,=\, \poly(d,\eps)\;.
	\end{equation}
	For any line $\ell \subset \F_q^m$, let $u_\ell\in \ell$ be chosen such that, for a uniformly random $\ell$ and conditioned on that $u_\ell$,~\eqref{eq:z2-stab-4-1} and~\eqref{eq:z2-stab-5-0} both hold, with right-hand side multiplied by a factor at most $2$. For any $\ell$ in the $j$-th direction and degree-$d$ polynomial $g$, define the operator $Q^\ell_g = R^{u_\ell,j}_{g(u_\ell+t_0 e_j),\ldots,g(u_\ell+t_de_j)}$.
	Combining the two equations we deduce
	\begin{equation}\label{eq:z2-stab-4-2}
 \Es{\gamma\in\F_q} \Big\| U_{v,\gamma} -  \sum_{g} (-1)^{\tr(\gamma \sum \alpha_{u_\ell,v,i} g(u_\ell+t_ie_j))} Q^{\ell}_g\Big\|_\tau^2 \,=\, \poly(d,\eps)\;.
	\end{equation}
	 By definition, $\sum \alpha_{u_\ell,v,i} g(u_\ell+t_ie_j) = g(v)$. By Fourier transform, we obtain the desired conclusion. 
\end{proof}


We are now in a position to apply~\cite[Theorem 4.1]{ji2022quantum}. For this we need to define a synchronous strategy in the tensor code test $\code^{\otimes m}$, where $\code$ is the Reed-Solomon code with degree $d$ over $\F_q$, and thus $\code^{\otimes m}$ is the code $\code_\RM$ considered in Section~\ref{sec:rmq} (see the remark right after Lemma~\ref{lem:schwartz-zippel}). For the ``points measurement'' $A^u$ we choose $P^u$. For the ``lines measurement'' $B^\ell$ we choose $Q^\ell$ from Claim~\ref{claim:z2-stab-4}. Finally, for the ``pair measurement'' $P^{u,v}$ we choose $R^{u,v}$ from Claim~\ref{claim:z2-stab-3}. By Claim~\ref{claim:z2-stab-4} this strategy succeeds with probability $1-\poly(d,\eps)$ in the ``axis-parallel lines test'', and by Claim~\ref{claim:z2-stab-3} it succeeds with probability $1-\poly(\eps)$ in the ``subcube commutation test.'' Applying~\cite[Theorem 4.1]{ji2022quantum} we deduce the existence of a projective measurement $\{G_c\}_{c\in\code^{\otimes m}}$ on $\mA$ such that for all integers $r \geq 12mt$,
\[ \Es{u\in\F_q^m} \sum_{c\in\code^{\otimes m}} \tau\big( G_c P^u_{c(u)}\big) \geq 1-\eta\;,\]
where $\eta = \poly(m,d,r) \cdot\poly(\eps,q^{-1},e^{-\Omega(r/m^2)})$. Choosing $r=\Omega(m^2 t)$, since $q=2^{t}$, the bound becomes $\poly(m,d,t) \cdot\poly(\eps,q^{-1})$.

\end{proof}


\section{Testing entanglement}
\label{sec:quantum}

In this section we give an application of our stability results to the problem of entanglement testing in quantum information. We first introduce the language of nonlocal games. Then we associate a nonlocal game to any presentation of $\Z_2^k$. Finally, we show that, if the presentation is stable, then the game is a robust  entanglement test. 
	
\subsection{Nonlocal games}
\label{sec:nl-games}

We give standard definitions on nonlocal games. For background from a computer science point of view, see~\cite{cleve2004consequences}; for the operator algebra perspective, see e.g.~\cite{kim2018synchronous}.

\begin{definition}[Game]
A game is a tuple $(\mX,\mu,\mA,D)$ where $\mX$ is a finite set, $\mu$ a distribution on $\mX\times \mX$, $\mA=(\mA(x))_{x\in\mX}$ a collection of finite sets, and 
\[ D: \big\{ (x,y,a,b) : (x,y)\in\text{supp}(\mu),a\in\mA(x),b\in\mA(y)\big\} \;\to\;\{0,1\}\]
such that $D$ is symmetric, i.e. $D(x,y,a,b)=D(y,x,b,a)$ whenever both terms are defined. We often abuse notation and write $\mu$ for the symmetrized marginal of $\mu$, i.e.\ 
\[\mu(x) := \sum_{x'\in \mX} \frac{1}{2}\big(\mu(x,x')+\mu(x',x')\big)\;.\]
\end{definition}

The interpretation of $G=(\mX,\mu,\mA,D)$ as a nonlocal game is the following. In the ``game,'' a referee is imagined to sample a pair of ``questions'' $(x,y)\sim \mu$. The question $x$ is sent to a first player, ``Alice,'' and the question $y$ is sent to a second player, ``Bob.'' Each player is tasked with responding with an answer, $a\in \mA(x)$ for Alice and $b\in \mA(y)$ for Bob. The referee accepts the players' answers if and only if $D(x,y,a,b)=1$. 

Nonlocal games provide a framework to study different kinds of bipartite correlations: depending on the level of coordination allowed between Alice and Bob, they may have varying chances of success in the game. A ``classical'' strategy consists of functions $f_A:\mX\to\mA$ for Alice and $f_B:\mX\to\mA$ for Bob; any such pair of functions leads to a probability of success in the game which can be computed in the obvious manner. 

An important motivation for studying nonlocal games is that in quantum mechanics, local strategies for the players (meaning strategies that do not require any communication between the players to determine their answer, given their question) are a larger set than the above-described classical strategies. Specifically, a \emph{quantum local} (or \emph{quantum} for short) strategy is specified by the following. 

\begin{definition}[Synchronous strategy]
If $G=(\mX,\mu,\mA,D)$ is a game and $(\mM,\tau)$ a tracial von Neumann algebra, a \emph{synchronous strategy $\strategy$ for $G$ on $(\mM,\tau)$} is, for every $x\in \mX$, a projective measurement $(P^x_a)_{a\in \mA(x)}$ on $\mM$. The value of a strategy $\strategy$ in $G$ is 
\[ \omega(G;\strategy)\,=\, \sum_{(x,y)\in\mX\times\mX}\frac{1}{2}\big(\mu(x,y)+\mu(y,x)\big) \sum_{(a,b)\in\mA(x)\times\mA(y)} D(x,y,a,b)\, \tau\big(P^x_a \,P^y_b\big) \;.\footnote{Note the symmetrization of $\mu$. This is to avoid explicitly requiring $\mu$ to be permutation-invariant in the definition of a game. We will often abuse notation and write $\Es{(x,y)\sim \mu}$ when taking expectations under the symmetrized distribution. }\]
We say that $\strategy$ is \emph{perfect} if $\omega(G;\strategy)=1$.
\end{definition}
	
The name \emph{synchronous} stems from the fact that whenever an identical pair $(x,x)$ is chosen, $\tau(P^x_a P^x_b)=0$ for $a\neq b$ due to the requirement that $\{P^x_a\}_a$ is a projective measurement. Thus a synchronous strategy always returns the same answer to the same question. More general strategies, which allow different operators $\{P^x_a\}$ and $\{Q^y_b\}$, do not automatically enforce the synchronicity condition, but we do not consider such strategies here. 

It will be convenient to have a measure of closeness for strategies. The following definition parallels Definition~\ref{def:close}. 

	\begin{definition}[Closeness for strategies]\label{def:close-meas}
Let $\{A^i_a\}\subseteq \mM$ and $\{B^i_a\}\subseteq \mN$ be two families of projective measurements on  tracial algebras $(\mM,\tau^\mM)$ and $(\mN,\tau^\mN)$ respectively, indexed by the same set $i\in \mI$ and with the same sets of outcomes $a,b\in\mA(i)$. For $\delta\geq0$ and $\mu$ a measure on $\mI$ we say that $\{A^i\}$ and $\{B^i\}$ are $(\delta,\mu)$-close if there exists a projection $P\in\mM_\infty$ of finite trace such that $\mN=P\mM_\infty P$ and $\tau^\mN=\tau_\infty/\tau_\infty(P)$, and a partial isometry $w\in P \mM_\infty \Id_\mM$ such that 
\[ \Es{i\sim\mu} \sum_{a\in\mA(i)} \big\| A^i_a - w^* B^i_a w \big\|_{\tau^\cM}^2 \,\leq\,\delta\]
and 
\[\max\big\{ \tau^\mM(\Id_\mM-w^*w)\,,\; \tau^\mN(P-ww^*)\big\} \,\leq\, \delta\;.\]
If the measure $\mu$ is omitted then it is understood to be the uniform measure on $\mI$.
\end{definition}

In Definition~\ref{def:close-meas} closeness is measured in the $L_2$ sense. The following lemma gives a consequence for distance measured in an $L_1$ sense. 


\begin{lemma}\label{lem:l1-l2}
Let $\{P_a^i\}$ and $\{Q_a^i\}$ be two families of projective measurements that are $(\eps,\mu)$-close. Then 
\begin{equation}\label{eq:l1-l2}
\Es{i\in\mI} \sum_{a\in \mA(i)} \tau\big(|P_a-w^*Q_aw|\big) \,\leq\, \eps+ 2 \sqrt{\eps}\;.
\end{equation}
\end{lemma}

\begin{proof}
Using the triangle inequality, 
\begin{align}
\Es{i} \sum_a \tau\big(|P^i_a - w^* Q^i_a w|\big) &\leq\, \Es{i}\sum_a \Big(\tau\big(|(P^i_a-(P^i_a)^2)|\big) + \tau\big(|P_a(P^i_a-w^*Q^i_aw)|\big) \notag\\
&\qquad\qquad+ \tau\big(|(P^i_a-w^*Q^i_aw)w^*Q^i_aw|\big) \notag \\
&\qquad \qquad+\tau\big(| (w^*Q^i_aw^*wQ^i_aw-w^*Q^i_aw)|\big)\Big)\;. \label{eq:lem:l1-l2}
\end{align}
The first term on the right-hand side is zero, because $P^i$ is assumed projective. The terms in the middle are bounded using H\"older's inequality:
\begin{align*}
\Es{i}\sum_a  \tau\big(|P^i_a(P^i_a-w^*Q^i_aw)|\big) &\leq \Es{i} \sum_a \|P^i_a\|_\tau \, \, \|P^i_a-w^*Q^i_aw\|_\tau\\
&\leq \Big(\Es{i}\sum_a \|P^i_a\|^\tau_2\Big)^{1/2}\Big( \Es{i}\sum_a  \|P^i_a-w^*Q^i_aw\|_\tau^2 \Big)^{1/2}\\
&\leq \sqrt{\eps}
\end{align*}
by closeness. The third term of~\eqref{eq:lem:l1-l2} is bounded in a similar fashion.
Finally the last term of~\eqref{eq:lem:l1-l2} can be bounded as 
\begin{align*}
\Es{i}\sum_a \tau\big(| w^*Q^i_aw^*wQ^i_aw-w^*Q^i_aw|\big) &= \Es{i}\sum_a \tau\big( (w^*Q^i_a(I - w^*w)Q^i_aw)\big)\\
&=  \tau\Big( (I-w^*w)\Big(\Es{i}\sum_a Q^i_aww^* Q^i_a\Big)\Big)\\
&\leq \tau(I-w^*w) \,\, \Big\|\Es{i}\sum_a Q^i_aww^* Q^i_a\Big\|\\
&\leq \eps\;.
\end{align*}
\end{proof}


We will make use of the following elementary lemma, which shows that two strategies for the same game $G$ that are close according to Definition~\ref{def:close-meas} have a close value. 

\begin{lemma}\label{lem:close-value}
Let $G=(\mX,\mu,\mA,D)$ be a game and $\strategy=\{P^x_a\}$ and $\strategy'=\{Q^x_a\}$ strategies on $\mM$ and $\mN$ respectively such that $\{P^x_a\}$ and $\{Q^x_a\}$ are $(\eps,\mu)$-close. Then 
\[ \big|\omega(G;\strategy) - \omega(G;\strategy')\big|\,\leq\, 8\sqrt{\eps} \;.\]
\end{lemma}

\begin{proof}
By definition, there exists a projection $P \in \mM_\infty$ and a partial isometry $w \in P \mM_\infty I_\mM$ such that $\mN = P \mM_\infty P$ and
\begin{align}
\omega(G;\strategy') &= \Es{(x,y)\sim\mu} \sum_{a,b} D(a,b,x,y)  \tau\big( Q^x_a \, Q^y_b \big)\notag\\
&=  \Es{(x,y)\sim\mu} \sum_{a,b} D(a,b,x,y)  \tau\big( w^* Q^x_a w\, w^* Q^y_b w\big)\notag\\
&\qquad\qquad+  \Es{(x,y)\sim\mu} \sum_{a,b} D(a,b,x,y)  \tau\big( w^* Q^x_a (P - w\, w^* ) Q^y_b w\big) \notag\\
&\qquad\qquad+ \Es{(x,y)\sim\mu} \sum_{a,b} D(a,b,x,y)  \tau\big(Q^x_a  Q^y_b (P-ww^*)\big)~.\label{eq:cv-0}
\end{align}
Here we used the fact that $Q^x_a \in \mN$ so $P Q^x_a P = Q^x_a$ for all $x,a$. 
The second term on the right-hand side can be bounded as
%\begin{align*}
%\Big|\Es{(x,y)\sim\mu} \sum_{a,b} D(a,b,x,y)  \tau\big( w^* Q^x_a (P - w\, w^* ) Q^y_b w\big)\Big|
%&=\Big| \tau\Big(  (P - w\, w^* )\Big( \Es{(x,y)\sim\mu} \sum_{a,b} D(a,b,x,y) Q^y_b ww^* Q^x_a \Big)\Big)\Big|\\
%&\leq \tau(P-ww^*) \Big\|\Es{(x,y)\sim\mu} \sum_{a,b} D(a,b,x,y) Q^y_b ww^* Q^x_a \Big\|\\
%&\leq \eps\;,
%\end{align*}
%where the first inequality is by H\"older's inequality and the last inequality uses the definition of closeness to bound the first term. To bound the second term on the right-hand side, we write it as $\|A\circ B\|$, with $\circ$ the Hadamard product, and use  $\|A\circ B\| \leq \max_{i,j} |A_{i,j}|\|B\|$. Here $A = \sum_{a,b} D(a,b) P_{a,b}$, with $P_{a,b} = \sum_{i,j} \ket{u_{i,a}} \bra{v_{j,b}}$ with $\ket{u_{i,a}}$ a basis for the range of $Q^x_a$ and $\ket{v_{j,b}}$ for the range of $Q^y_b$, and $B=\sum_{a,b} Q^y_b ww^* Q^x_a = ww^*$.  
\begin{align}
\Big|\Es{(x,y)\sim\mu} \sum_{a,b} D(a,b,x,y) & \tau\big( w^* Q^x_a (P - w\, w^* ) Q^y_b w\big)\Big|\notag\\
&\leq \Es{(x,y)\sim\mu} \Big | \tau\big( \sum_{a,b} D(a,b,x,y)   Q^y_b w w^* Q^x_a (P - w\, w^* ) \big) \Big | \notag\\
&\leq \sqrt{ \tau((P - ww^*)^2)} \cdot \sqrt{\Es{(x,y)\sim\mu} \tau\big( \big| \sum_{a,b} D(a,b,x,y)   Q^x_a w w^* Q^y_b \big|^2 \big) } \notag\\
&\leq \sqrt{\eps}\sqrt{ \Es{(x,y)\sim\mu} \tau\big( \sum_{a,b} D(a,b,x,y)   Q^y_b ww^* Q^x_a w w^* Q^y_b \big) } \notag\\
&\leq \sqrt{\eps}\sqrt{ \Es{(x,y)\sim\mu}  \sum_{a,b}  \tau\big(Q^y_b ww^* Q^x_a w w^* Q^y_b \big) } \notag \\
&=\sqrt{\eps}\sqrt{ \Es{(x,y)\sim\mu}  \sum_{b}  \tau\big(Q^y_b ww^* \big) } \notag\\
&\leq \sqrt{\eps}\;.\label{eq:cv-1}
%&=\Big| \tau\Big(  (P - w\, w^* )\Big( \Es{(x,y)\sim\mu} \sum_{a,b} D(a,b,x,y) Q^y_b ww^* Q^x_a \Big)\Big)\Big|\\
%&\leq \tau(P-ww^*) \Big\|\Es{(x,y)\sim\mu} \sum_{a,b} D(a,b,x,y) Q^y_b ww^* Q^x_a \Big\|\\
%&\leq \eps\;,
\end{align}
The third line is due to Cauchy-Schwarz and Jensen's inequality, where $|A|^2=A^*A$. The fourth line uses that $P - ww^*$ is a positive operator with operator norm at most $1$ for the first term, and that for fixed $x,y$, the measurements $\{ Q^x_a \}_a$ and $\{Q^y_b\}_b$ are projective. The fifth line is due to $D(x,y,a,b) \in \{0,1\}$. The sixth line is due to $\sum_a Q^x_a = I_\mN$. The seventh line is due to $\sum_a Q^y_b = I_\mN$. The third time on the right-hand side of~\eqref{eq:cv-0} is bounded in the same manner. 

For $x\in \mX$ such that $\mu(x)\neq 0$, denote by $\mu_x$ the (symmetrized) conditional distribution $\mu_x(y)=\frac{1}{2}(\mu(x,y)+\mu(y,x))/\mu(x)$. Then using~\eqref{eq:cv-0} and the preceding bounds,
\begin{align*}
\big|\omega(G;\strategy) - \omega(G;\strategy')\big|
 &\leq 2\sqrt{\eps}+ \Big|\Es{(x,y)\sim\mu} \sum_{a,b} D(a,b,x,y) \big( \tau\big( P^x_a \, P^y_b \big)-\tau\big( w^* Q^x_a w\, w^* Q^y_b w\big)\big)\Big|\\
&\leq  2\sqrt{\eps}+ \Big|\Es{x\sim\mu} \sum_{a}  \tau\Big( \big(P^x_a-w^* Q^x_aw\big) \, \Big( \Es{y\sim \mu_x} \sum_b D(a,b,x,y) P^y_b \Big)\Big)\Big|\\
&\qquad+ \Big|\Es{y\sim\mu} \sum_{b}  \tau\Big(\Big( \Es{x\sim \mu_y} \sum_a D(a,b,x,y) w^* Q^x_a w\Big) \big(P^y_b-w^*Q^y_bw\big) \, \Big)\Big|\\
&\leq 2\sqrt{\eps}+2\Es{x\sim\mu} \sum_{a}  \tau\big(\big| P^x_a-w^*Q^x_aw\big|\big) \\
&\leq 2\sqrt{\eps}+2(\eps + 2\sqrt{\eps}) \leq 8\sqrt{\eps}\;,
\end{align*}
where the third line uses $\tau(AB)\leq\tau(|A|)\|B\|$ and the last line is by Lemma~\ref{lem:l1-l2}.% and Jensen's inequality.
\end{proof}
	
\subsection{Some simple games}

We introduce games previously used in the literature, that will serve as building blocks. For details on the implementation of these games we refer to~\cite{de2022spectral}.

\paragraph{Commutation game.}
We call \emph{commutation game} the game $G_{\cc}=(\mX_\cc,\mu_\cc,\mA_\cc,D_\cc)$ defined in~\cite[Section 3.1]{de2022spectral}. For convenience we change the notation slightly and denote $x_{X,0}, x_{Z,0} \in \mX_{\cc}$ the two special questions, $x_{\cc,1}$ and $x_{\cc,2}$ respectively. 

\paragraph{Anti-commutation game.}
We call \emph{anti-commutation game} the game $G_\ac=(\mX_\ac,\mu_\ac,\mA_\ac,D_\ac)$ defined in~\cite[Section 3.2]{de2022spectral}. For convenience we change the notation slightly and  denote $x_{X,1}, x_{Z,1} \in \mX_{\ac}$ the two special questions, $x_{\ac,1}$ and $x_{\ac,2}$ respectively. 

\paragraph{Braiding game.}
Finally we introduce a game, which we denote $G_{\dlS}$, that is built from the previous two games and is a based on a more general class of games analyzed in~\cite[Section 3.4]{de2022spectral}.  Using notation from~\cite{de2022spectral}, the game $G_{\dlS}$ is obtained by making the following choices. The game can be constructed from any $E\in\F_2^{k\times n}$. Let 
\begin{equation}\label{eq:dls-sets}
 S_X\,=\,S_Z\,=\,\{E e_i:\,i\in\{1,\ldots,n\}\}\subseteq \field^k\;,
\end{equation}
and let $\mu_{\dlS}$ be the uniform distribution over $\Omega=S_X\times S_Z$. Let $\alpha,\beta$ be the coordinate projections on $\Omega$. Let $\Omega_+ = \{(a,b)\in \Omega:a\cdot b=0\}$ and $\Omega_-=\{(a,b)\in\Omega:a\cdot b=1\}$. Then $G_{\dlS}=(\mX_{\dlS},\mu_{\dlS},\mA_{\dlS},D_{\dlS})$ has question set 
\[ \mX_{\dlS} = \{X,Z\} \cup (\mX_{\cc}\times \Omega_+) \cup (\mX_{\ac} \times \Omega_-) \cup (\{X\}\times S_X) \cup (\{Z\}\times S_Z)\;.\]
The game itself is based on the game described in~\cite[Section 3.4]{de2022spectral}, with a small modification (the addition of the consistency test). For clarity we recall the entire game in Figure~\ref{fig:dlS}. 

\begin{figure}[!htbp]
  \centering
  \begin{gamespec}
Let $S_X,S_Z\subseteq \field^k$.  Sample $\omega = (\omega_X,\omega_Z)\in S_X \times S_Z $ uniformly at random. Let $\gamma = \omega_X \cdot \omega_Z \in \field$. Execute either of the following tests with probability $1/3$ each. 
    \begin{enumerate}
      \setlength\itemsep{1pt}
    \item \textbf{(Anti-)commutation test:} 
		\begin{enumerate}
		\item If $\gamma=0$ then sample a pair of questions $(x_c,y_c)\sim\mu_\cc$ as in the commutation game. If $x_c = x_{W,0}$ (resp.\ $y_c=x_{W,0}$) for some $W\in \{X,Z\}$ then send $(W,\omega_W)$ to Alice (resp.\ $(W,\omega_W)$ to Bob). Otherwise, send $(x_c,\omega)$ to $\alice$ (resp.\ $(y_c,\omega)$ to Bob). Accept if and only if their answers are accepted in the commutation game. 
		\item If $\gamma\neq 0$ then do the same but for the anti-commutation game. 
		\end{enumerate} 
		 \item \textbf{Consistency test:} Select $W\in\{X,Z\}$ uniformly at random. Send $W$ to $\alice$ and $(W,\omega_W)$ to $\bob$. Receive $a\in \field^k$ and $b\in \field$ respectively. Accept if and only if $a\cdot \omega_W=b$. 
    \end{enumerate}
  \end{gamespec}
  \caption{The game $G_{\dlS}$ checks (anti)commutation relations between two collections of observables.}
  \label{fig:dlS}
\end{figure}

We recall the following result from~\cite{de2022spectral} about this game. (The result from~\cite{de2022spectral} is more general, and applies to non-uniform measures on $\Omega$. We only need the consequence stated here.) Before stating the result, we introduce the notion of a \emph{qubit test}. 

For a projective measurement $P = \{P_a\}_{a \in \F_2^k}$, we use $\widehat{P}(b)$ to denote the observable
\[\widehat{P}(b) \,=\, \sum_a (-1)^{a\cdot b} P_a\;.\]
For binary outcome measurements $P = \{ P_0, P_1\}$, we write $\widehat{P}$ to denote $P_0 - P_1$. Recall the notation $\sigma^W$ for the Pauli observables introduced in Section~\ref{sec:examples}.

\begin{definition}[Qubit test]
Let $k\in \N$ and $\delta:[0,1]\to\R_+$. 
A \emph{$(k,\delta(\eps))$-qubit test} is a synchronous game $G=(\mX,\mu,\mA,D)$ such there are two sets $S_X,S_Z\subseteq \field^k$ that each span $\field^k$ and an injection $\phi:(\{X\}\times S_X) \cup (\{Z\}\times S_Z) \to \mX$ such that $\mA(\phi({X},a))=\mA(\phi({Z},b))=\field$ for all $a\in S_X$, $b\in S_Z$ and such that the following holds:
\begin{itemize}
\item (Completeness:) There is a synchronous strategy $\strategy = \{P^{x}\}_{x \in \mX}$ for $G$ on $\mM=M_{2^{k}}(\C)\otimes \mH$, for some Hilbert space $\mH$, that succeeds with probability $1$ in $G$ and is such that $\widehat{P}^{\phi({W},a)} = \sigma^W(a)$ for every $W\in\{X,Z\}$ and $a\in S_W$. 
\item (Soundness:) Let $\mu'$ denote the (renormalized) restriction of (the marginal of) $\mu$ to the image of $\phi$ in $\mX$.
Any synchronous strategy  $\strategy = \{P^{x}\}_{x \in \mX}$ on $(\mM,\tau)$ for $G$ that succeeds with probability $1-\eps$ for some $\eps\geq 0$ is $(\delta(\eps),\tilde{\mu})$-close to a strategy on some algebra $(M_{2^{k}}(\C)\otimes \mN,\tr\otimes \tau')$ where $(\mN,\tau')$ is a tracial sub-algebra of $\mM_\infty$ and such that
\[\widehat{P}^{\phi({W},a)} = \sigma^W(a)\otimes \Id_\mN\;.\]
\end{itemize}
\end{definition}

The terminology ``qubit test'' is motivated by the notion of a \emph{qubit} as introduced in~\cite{chao2017overlapping}. Informally, a qubit is a copy of the space $\C^2$ together with a pair of anticommuting observables $X,Z$ acting on it. A qubit test is then a test that forces any successful strategy for the players in it to ``contain'', as a subset of its measurement operators, a representation of (generators of) the algebra of $k$ qubits. 

\begin{theorem}[Corollary 3.9 in~\cite{de2022spectral}]\label{thm:dls-braid}
Suppose that $E\in \F_2^{k\times n}$ is such that the rows of $E$ span an $[n,k,d]_2$ linear code. The game $G_{\dlS}$ is a $(k,O(\eps))$-qubit test, where the sets $S_X$ and $S_Z$ are as in~\eqref{eq:dls-sets} and $\phi((X,a))=(X,a)$ and $\phi((Z,b))=(Z,b)$ and the $O(\eps)$ hides a (quadratic) dependence on $d/n$.  
\end{theorem}

The goal in the remaining sections is to design a qubit test where the size of the question set is $\polylog(k)$, as opposed to $\Omega(k^2)$ here. 

\subsection{The code game}
\label{sec:code-game}

In this section we associate a game $G_{\code,M}$ to any $[n,k,d]_2$ code $\code$ and $r$-local tester $M=(h,\nu)$ for it. In the game, one player is asked to provide an assignment to all generators in the support of a randomly chosen row of $h$, such that this assignment satisfies the check enforced by that row. The other player is asked to provide an assignment to a single of these variables, and checked for consistency with the first player. The formal definition follows.  

\begin{definition}
Let $\code$ be an $[n,k,d]_q$ linear code and $M(h,\nu)$ an $r$-local tester for $\code$ such that $h\in \F_2^{m\times n}$. The game $G_{\code,M}$ is defined as follows. We set 
\[\mX = \big\{ \{\eq\}\times\{1,\ldots,m\} \sqcup\{\var\}\times \{1,\ldots,n\}\big\}\;,\]
and
\[\mu((\var,i),(\eq,j))=\mu((\eq,j),(\var,i)) = \frac{1}{m} \frac{1}{|h_{j\cdot}|} 1_{h_{ji}=1}\;,\]
where $|h_{j\cdot}|$ denotes the Hamming weight of the $j$-th row of $h$. For any $j$, $\mA((\eq,j))=\F_2^{|h_{j\cdot}|}$, and for any $i\in\{1,\ldots,n\}$, $\mA((\var,i))=\F_2$. Finally $D((\eq,j),(\var,i),a,b)=1_{h_{j\cdot} a=0} 1_{a_i=b}$, where $h_{j\cdot}a$ is naturally computed as the sum, in $\F_2$, of all entries of $a$.  
\end{definition}

We show the following. For $\code$ an $[n,k,d]_2$ linear code and $M=(h,\nu)$ an $r$-local tester for $\code$, recall the presentation~\eqref{eq:def-gh-pres} of $G(h)$. We define a distribution $\mu$ on the relations defining that presentation as follows. First, sample a uniformly random $j\in\{1,\ldots,m\}$ and uniformly random $i,i'\in\{1,\ldots,n\}$, conditioned on $h_{ji}=h_{ji'}=1$ and $i\neq i'$. Then, with probability $1/3$ we return the relation $x_i^2=e$, with probability $1/3$ we return the relation $R_i$, and with probability $1/3$ we return $R'_{jii'}$. 

\begin{proposition}\label{prop:rep-game}
Let $\code$ be an $[n,k,d]_2$ linear code, $M=(h,\nu)$ an $r$-local tester for $\code$, and $\mu$ the distribution defined above. Let $\strategy = \{P^{x}\}_{x \in \mX}$ be a strategy for $G_{\code,M}$ on $(\mN,\tau^\mN)$ such that $\omega^*(G_{\code,M};\strategy)\geq 1-\eps$. Then $\phi:x_i\mapsto {\widehat{P}}^{(\var,i)}$, for $i\in\{1,\ldots,n\}$, is an $(O(r\eps),\mu)$-homomorphism of the presentation~\eqref{eq:def-gh-pres} of $G(h)$.
\end{proposition}

\begin{proof}
Let $\strategy$ be a synchronous strategy for $G_{\code,M}$  in  $(\mM,\tau)$ that succeeds with probability at least $1-\eps$. For $i\in\{1,\ldots,n\}$ let 
\[ \phi(x_i)\,=\,{\widehat{P}}^{(\var,i)}\,=\, P^{(\var,i)}_0-P^{(\var,i)}_1\;.\]
Then by definition $\phi(x_i)^2=\Id$ for all $i$. Recalling~\eqref{eq:def-gh-pres}, it remains to verify the relations $R_j$ and $R'_{jii'}$, for $1\leq i<i'\leq n$ and $1\leq j \leq m$. To show these relations, first express the assumption that $\strategy$ succeeds in $G_{\code,M}$ as
\begin{align}
1-\eps &\leq \Es{j\in\{1,\ldots,m\}} \Es{i: h_{ji}=1} \sum_{a:h_{j\cdot} a=0}\tau\big(P^{(\eq,j)}_a P^{(\var,i)}_{a_i}\big)\label{eq:rep-game-1}
\end{align}
For an equation $j$ and variables $i,i'$, let 
\[ R^{(\eq,j)}_{ii'} = \sum_a (-1)^{a_i+a_{i'}} P^{(\eq,j)}_a\qquad\text{and}\qquad R^{(\eq,j)}_{i} = \sum_a (-1)^{a_i}P^{(\eq,j)}_a\;,\]
so that, using that $\{P^{(\eq,j)}_a\}$ is a projective measurement, 
\[R^{(\eq,j)}_{ii'} \,=\, R^{(\eq,j)}_{i}R^{(\eq,j)}_{i'}\,=\,R^{(\eq,j)}_{i'}R^{(\eq,j)}_{i}\;.\]
Using this we compute
\begin{align*}
\Es{(j,i,i')\sim\mu} \|R'_{jii'}-\Id\|_\tau^2 &= \Es{(j,i,i')} \big\| \widehat{P}^{(\var,i)}\widehat{P}^{(\var,i')} - \widehat{P}^{(\var,i')}\widehat{P}^{(\var,i)}\big\|_\tau^2\\
&= \Es{(j,i,i')} \big\| \big(\widehat{P}^{(\var,i)} - R^{(\eq,j)}_{i}\big)\widehat{P}^{(\var,i')} + R^{(\eq,j)}_{i}\big(\widehat{P}^{(\var,i')}-R^{(\eq,j)}_{i'}\big)  \\
&\hskip3cm - R^{(\eq,j)}_{i'}\big(\widehat{P}^{(\var,i)}-R^{(\eq,j)}_{i}\big)- \big(\widehat{P}^{(\var,i')}- R^{(\eq,j)}_{i'}\big)\widehat{P}^{(\var,i)}  \big\|_\tau^2\\
&\leq 2\Big( \Es{(j,i,i')} \big\| \widehat{P}^{(\var,i)} - R^{(\eq,j)}_{i}\big\|_\tau^2 +\Es{(j,i,i')} \big\| \widehat{P}^{(\var,i')} - R^{(\eq,j)}_{i'}\big\|_\tau^2\Big)\\
&= 2\Big(4-2\Big(\Es{(j,i,i')} \tau\big( \widehat{P}^{(\var,i)}  R^{(\eq,j)}_{i}\big) +\tau\big(\widehat{P}^{(\var,i')}  R^{(\eq,j)}_{i'}\big)\Big)\Big)\\
&=2\Big(8-8 \Es{j\in\{1,\ldots,m\}} \Es{i:h_{ji}=1}\sum_{a} \tau\big( \widehat{P}^{(\var,i)}_{a_i}  P^{(\eq,j)}_{a}\big)\Big)\;.
\end{align*}
Here we abused notation slightly and denoted $\Es{(j,i,i')}$ the expectation for a relation $R'_{jii'}$ sampled according to $\mu$, conditioned on such a relation being sampled. The third line is the Cauchy-Schwarz inequality and uses that $\widehat{P}^{(\var,i)}$ and $R^{(\eq,j)}_{i}$ are observables, hence square to identity; the fourth line expands the norms and also uses this fact; and the fifth line uses that for observables $A=A0-A_1$ and $B=B_0-B_1$, $AB=\Id-2(A_0B_0+A_1B_1)$. The last line also uses that the marginal of $(j,i,i')\sim\mu$ on $(j,i)$ or $(j,i')$ are identical and match the distribution indicated in the last line. Using~\eqref{eq:rep-game-1} we deduce that  
\[ \Es{(j,i,i')\sim\mu} \|R'_{jii'}-\Id\|_\tau^2 \,\leq\, 16\eps\;.\]
Now we consider the relations $R_j$. For $j\in\{1,\ldots,m\}$ we denote $i_1,\ldots,i_r$ the indices such that $h_{ji}=1$ (assume for simplicity of notation that there are exactly $r$). Then 
\begin{align*}
\Es{j} \|R_{j}-\Id\|_\tau^2
 &= \Es{j} \big\| \widehat{P}^{(\var,i_1)}\cdots \widehat{P}^{(\var,i_r)}-\Id\big\|_\tau^2\\
&\leq (r+1)\Big(\Es{j} \big\| R^{(\eq,j)}_{i_1}\cdots R^{(\eq,j)}_{i_r}-\Id\big\|_\tau^2 + \sum_{t=1}^r \big\|R^{(\eq,j)}_{i_t}-\widehat{P}^{(\var,i_t)}\big\|_\tau^2\Big)\\
&\leq (r+1)\big(2-2\Es{j}\tau\big( R^{(\eq,j)}_{i_1}\cdots R^{(\eq,j)}_{i_r}\big)\big) + O(r\eps)\\
&\leq O(r\eps)\;,
\end{align*}
where the second line follows from the triangle inequality and using a telescoping sum, the third line uses the definition of $R$ and~\eqref{eq:rep-game-1}, and the last line again uses the definition of $R$ and~\eqref{eq:rep-game-1}. This concludes the proof. 
\end{proof}





\subsection{Braiding the code test}

\begin{figure}[!htbp]
  \centering
  \begin{gamespec}
Let $M=(h,\nu)$ be an $r$-local tester for the $[n,k,d]_2$ code $\code$.  Execute either of the following tests with probability $1/3$ each. 
    \begin{enumerate}
      \setlength\itemsep{1pt}
    \item \textbf{Code test:} Sample $W\in \{X,Z\}$ uniformly at random. Execute the code game $G_{\code,M}$ with both players, prepending the symbol $W$ to all questions (which now take the form $(W,\var,i)$ or $(W,\eq,j)$). 
		
    \item \textbf{(Anti-)commutation test:} Sample $(i_X,i_Z)\in \{1,\ldots,n\}^2 $ uniformly at random. Let $\omega = (E_\code e_{i_X}, E_\code e_{i_Z})$ and $\gamma =  (E_\code e_{i_X}) \cdot(E_\code e_{i_Z}) \in \field$. 
		\begin{enumerate} 
		\item If $\gamma=0$ then sample a pair of questions $(x_c,y_c)\sim\mu_\cc$ as in the commutation game. Send $(x_c,\omega)$ to $\alice$ and $(y_c,\omega)$ to Bob. Accept if and only if their answers are accepted in the commutation game. 
		\item If $\gamma\neq 0$ then do the same but for the anti-commutation game. 
		\end{enumerate} 
		 \item \textbf{Consistency test:} Sample $(i_X,i_Z)\in \{1,\ldots,n\}^2 $ and $W\in \{X,Z\}$ uniformly at random. Let $\omega=(E_\code e_{i_X}, E_\code e_{i_Z})$ and $\gamma = (E_\code e_{i_X}) \cdot(E_\code e_{i_Z}) \in \field$. Send $(W,\var,i_W)$ to $\alice$ and $(x_{W,\gamma},\omega)$ to $\bob$, where $x_{W,\gamma}$ is a question from the (anti-)commutation game. Receive $a\in \field$ and $b\in \field$ respectively. Accept if and only if $a=b$. 
    \end{enumerate}
  \end{gamespec}
  \caption{The braiding test over $\code$ verifies that the players respond consistently with a uniformly random codeword from $\code$. $E_\code \in \F_2^{k\times n}$ is a generating matrix for $\code$, and for $i\in\{1,\ldots,n\}$ we let $e_i$ be the $i$-th canonical basis vector of $\F_2^n$.}
  \label{fig:braiding-test}
\end{figure}

Let $\code$ be an $[n,k,d]_2$ linear code and $M=(h,\nu)$ an $r$-local tester for $\code$. We let $E_\code\in\F_2^{k\times n}$ be a generating matrix for $\code$, i.e.\ $E_\code$ is such that its rows are linearly independent and span the codespace. 
 The braiding test constructed from $\code$ and $M$ is a synchronous game described in Figure~\ref{fig:braiding-test}. The test combines two independent copies of the code game from Section~\ref{sec:code-game} with appropriate commutation and anti-commutation sub-tests. The braiding test is designed to force any successful strategy in it to be close, in some sense, to a representation of the Pauli group generated by observables $\sigma^X(a)$ and $\sigma^Z(b)$, $a,b\in \F_2^k$ (recall the notation from~\eqref{eq:def-pauli-2}). This is shown in the following theorem. 

\begin{theorem}\label{thm:braiding}
Let $\mC$ be a class of tracial von Neumann algebras. Let $\code$ be an $[n,k,d]_2$ linear code and $M=(h,\nu)$ an $r$-local tester for $\code$. Suppose that the presentation $G(h)$ in~\eqref{eq:def-gh-pres} is such that $G(h)=\Z_2^k$ and furthermore this presentation is $(\delta,\nu_R,\nu_S,\mC)$-stable.\footnote{The distributions $\nu_R$ and $\nu_S$ are defined from $\nu$ as described right after Definition~\ref{def:code-test}.} Then the braiding test over $\code$ is a $(k,\delta')$-qubit test with sets $S_X=S_Z=\{E_\code e_i:\,i\in\{1,\ldots,n\}\}\subseteq \field^k$, map $\phi(W,E_\code e_i)=(W,\eq,i)$ and error function $\delta' = O(\delta^{1/2}(6\eps))$.\footnote{Assume $E_\code$ has no repeated columns.} 
\end{theorem}



We will make use of the following simple fact. 


\begin{lemma}[Data-processing]\label{lem:dp}
Let $\{P_a\}$ and $\{Q_a\}$ be two POVMs on $(\mM,\tau)$ with the same outcome set $\mA$. Then for any function $f:\mA\to \mB$ for some finite set $\mB$, 
\begin{equation}\label{eq:dp}
\sum_{b\in \mB} \Big\| \sum_{a\in f^{-1}(b)} (P_a-Q_a) \Big\|_2^2 \,\leq\, \sum_{a\in \mA} \big\| P_a-Q_a\big\|_2^2\;.
\end{equation}
\end{lemma}

\begin{proof}
This follows by expanding the left-hand side and using $\tau(P_aQ_{a'})\geq 0$ for all $a\neq a'$. 
\end{proof}


\begin{proof}[Proof of Theorem~\ref{thm:braiding}]
\underline{Completeness:} We first verify completeness. For $W\in\{X,Z\}$, $i\in\{1,\ldots,n\}$ and $b\in \F_2$ let $P^{(W,\var,i)}_b = \frac{1}{2}(\Id + (-1)^b\sigma^W(E_\code e_i))$, and for $j\in\{1,\ldots,m\}$, with $m$ the number of rows of $h$, and $a\in \F_2^r$ let $P^{(W,\eq,j)}_a = \prod_{i: h_{ji}=1} P^{(W,\var,i)}_{a_i}$. Writing $(f_0,f_1)$ for the canonical basis of $\C^2$, $P^{(W,\eq,j)}_a$ is the projection on the span of all $\otimes_{i=1}^k f_{u_i}$ where $u=(u_1,\ldots,u_k)$ is such that $(u^T E_\code)_{|S_j}=a$, where $S_j$ denotes the support of $h_{j\cdot}$.   
For $(i_X,i_Z)\in \{1,\ldots,n\}^2 $ let $\omega=(E_\code e_{i_X}, E_\code e_{i_Z})$ and $\gamma =(E_\code e_{i_X}) \cdot(E_\code e_{i_Z}) $. We let $P^{x_{W,\gamma},\omega} = P^{(W,\var,i_W)}$. 

These choices already ensure that the strategy succeeds with probability $1$ in the consistency test. We verify that it succeeds in the code test. Let $j\in\{1,\ldots,m\}$. As observed above, for any $a\in\field^r$ such that $P^{W,\eq,j}_a\neq 0$ there is an $u\in \field^k$ such that $(u^TE_\code)_{|S_j}=a$, which means that $a$ is the restriction of a valid element of $\code$. 
% and $h\in \F_2^S$ any valid parity check, i.e.\ $h^T E_\code=0$, for $\code$ with support in $S$. Then $\sum_{i\in S} h_i E_\code e_i = 0$, so $\prod_{i\in S}(\sigma^W(E_\code e_i))^{h_i}=\Id$. This means that for any $a\in\field^S$ such that $P^{W,S}_a\neq 0$, we have that $h\cdot a =0$, i.e.\ $a$ satisfies the parity check 
Using the completeness property of $M$ it follows that $M$ must accept any $a$ such that $P^{W,\eq,j}_a\neq 0$, which shows that the strategy succeeds in the code test with probability $1$. 

It remains to verify that the anti-commutation test is passed with probability $1$. For this we observe that 
% To define $P^{(x_c,\omega)}$ and $P^{(x_a,\omega)}$ for $x_c\notin \{x_{Z,0},x_{Z,0}\}$ and $x_a \notin \{x_{X,1},x_{Z,1}\}$ we observe that 
the binary observables 
\[ U=\widehat{ P}^{x_{X,\gamma},\omega} \quad\text{and}\quad V= \widehat{P}^{x_{Z,\gamma},\omega} \]
commute in case $\gamma=0$ and anti-commute in case $\gamma=1$. This is because by construction $U=\sigma^X(E_\code i_X)$ and $V=\sigma^W(E_\code i_W)$, and because of the definition of $\gamma$. Hence the pair $(U,V)$ can be completed to a perfect strategy for the commutation game (if $\gamma=0)$ or anti-commutation game (if $\gamma=1)$. This defines the measurements $P^{(x,\omega)}$ for $x\notin \{x_{W,\gamma}:\,W\in\{X,Z\},\gamma\in\{0,1\}\}$. 

\bigskip 

\underline{Soundness:} Next we show soundness. Let $\strategy$ be a synchronous strategy for the braiding test  in  $(\mM,\tau)$ that succeeds with probability at least $1-\eps$. For $W\in\{X,Z\}$ let $\strategy^W$ be the strategy in $G_{\code,M}$ that is obtained by restricting $\strategy$ to the relevant measurements corresponding to the ``Code test'' part of the braiding test, i.e.\ the $P^{W,\eq,j}$ and $P^{W,\var,i}$.  Then $\strategy^W$ succeeds with probability at least $1-6\eps$ in $G_{\code,M}$. Using Proposition~\ref{prop:rep-game} it follows that $\{\widehat{P}^{W,\var,i}\}$ is an $O(\eps)$-homomorphism of $G(h)$. Under the assumption that $G(h)=\Z_2^k$ is $(\delta,\nu_R,\nu_S,\mC)$-stable, we deduce that there is a $\delta_1 = O({\delta(6\eps)})$ such that for each $W\in\{X,Z\}$, $\strategy^W$ is $(\delta_1,\nu)$-close to a perfect strategy $\tilde{\strategy}^W$ on $(\mN^W,\tau^W)$ for $G_{\code,M}$, where $\nu$ is uniform on $\{1,\ldots,n\}$. This strategy has measurement operators $\{ \tilde{P}^{W,\eq,j}_a\}$ and $\{\tilde{P}^{W,\var,i}_b\}$ which satisfy 
\begin{equation}\label{eq:main-0}
\Es{i\in\{1,\ldots,n\}}\sum_{b \in \F_2} \big\|P^{W,\var,i}_b - (w^W)^* \tilde{P}_b^{W,\var,i} w^W \big\|^2_2 \,=\, O(\delta_1)\;.
\end{equation}
Furthermore, using that $G(h)=\Z_2^k$ is Abelian, there is a  POVM $\{\tilde{P}^W_u\}_{u\in \field^n}$ such that $\sum_{u\in \code}\tilde{P}^W_u = \Id$ and for each $i\in \{1,\ldots,n\}$, $\tilde{P}^{W,i}_b = \sum_{u:u_i=b} \tilde{P}^W_u$.
 
Applying Lemma~\ref{lem:pull-back}, we obtain projective measurements $\{Q^W_u\}$ on $\mM$ such that 
\begin{equation}\label{eq:main-1}
\sum_u \big\|Q^W_u - (w^W)^* \tilde{P}_u^W w^W \big\|^2_2 \,=\, O(\delta_1)\;.
\end{equation}
For any $i\in\{1,\ldots,n\}$ let $Q^{W,i}_b = \sum_{u:\,u_i=b}  Q^W_u$. Then by Lemma~\ref{lem:dp},
\begin{align*}
\Es{i}\sum_b \tau\big( Q^{W,i}_b (w^W)^*\tilde{P}^{W,i}_b(w^W) \big)
&\geq \Es{i}\sum_u \tau\big( Q^{W}_u (w^W)^*\tilde{P}^{W}_u(w^W) \big)\\
&\geq 1-O(\delta_1)\;.
\end{align*}
For $W\in\{X,Z\}$ and $b\in \F_2^k$ let $R^W_b = Q^W_{G_\mC^T b}$, where by definition $G_\mC^T b\in \mC$. 

We now define a strategy $\strategy'$ for the game $G_{\dlS}$. On question $W\in \{X,Z\}$ the projective measurement is $\{R^W_b\}$. On question of the form $(x_c,\omega)$ for $x_c$ a question in the commutation game, the projective measurement is $\{P^{x_c,\omega}\}$, i.e.\ the same projective measurement as used in $\strategy$. Similarly, on a question of the form $(x_{ac},\omega)$ for $x_{ac}$ a question in the anti-commutation game, the projective measurement is $\{P^{x_{ac},\omega}\}$.

To conclude we show that this strategy succeeds in the game $G_{\dlS}$ with probability $1-O(\sqrt{\delta_1})$. Assuming that this has been shown, by Theorem~\ref{thm:dls-braid} the strategy $\strategy'$ is $O(\sqrt{\delta_1})$-close to a strategy $\strategy''$ on an algebra of the form $(M_{2^{k}}(\C)\otimes \mN,\tr\otimes \tau')$ such that $P^W_b = \sigma^W_b\otimes I_\mN$. By definition of $R$, 
\begin{equation}\label{eq:main-3}
 Q^{W,i}_b \,=\,  \sum_{a \in \F_2^n:\,a_i=b}  Q^W_a \,=\, \sum_{c \in \F^k_2: (G_\mC^T c)_i=b}  R^W_c \;,
\end{equation}
hence
\begin{equation*}
 \widehat{Q}^{W,i}\,=\, \sum_c (-1)^{c\cdot (G_\mC e_i)} R^W_c \,=\, \widehat{R}^W(G_\mC e_i)\;.
\end{equation*}
Using the definition of the game distribution, closeness of $\strategy'$ and $\strategy''$ thus implies that
\begin{equation*}
\Es{i\in\{1,\ldots,n\}} \big\|\widehat{Q^{W,i}} - (w'')^* {\sigma^W}(G_\mC e_i) (w'') \big\|_2^2 \,=\,O(\sqrt{\delta_1})\;.
\end{equation*}
Combining with~\eqref{eq:main-0} and~\eqref{eq:main-1}, this shows the theorem.

It remains to verify that $\strategy'$ succeeds in the game $G_{\dlS}$ with probability $1-O(\sqrt{\delta_1})$. By definition $\strategy'$ succeeds in the (anti)-commutation test with probability $1-O(\eps)$. It remains to check the $W$-consistency test, for $W\in\{X,Z\}$. Because $\strategy$ succeeds with probability $1-O(\eps)$ in the consistency test, 
\begin{equation*}
\Es{i_X,i_Z\in\{1,\ldots,n\}} \sum_b \tau\big( P^{W,\var,i}_b P^{x_{W,\gamma},\omega}_b\big) \,\geq\, 1-O(\eps)\;,\
\end{equation*}
where $\omega$ and $\gamma$ are defined as in Figure~\ref{fig:braiding-test}. Using~\eqref{eq:main-0},~\eqref{eq:main-1}
and Lemma~\ref{lem:close-value} it follows that 
\begin{equation*}
\Es{i_X,i_Z\in\{1,\ldots,n\}} \sum_b \tau\big( Q^{W,i}_b P^{x_{W,\gamma},\omega}_b\big) \,\geq\, 1-O(\sqrt{\delta_1})\;,\
\end{equation*}
Using~\eqref{eq:main-3}, this can be rewritten as 
\begin{equation}\label{eq:main-4}
\Es{i_X,i_Z\in\{1,\ldots,n\}} \sum_{b,c: (G_\mC^T c)_i=b} \tau\big( R^{W}_c P^{x_{W,\gamma},\omega}_b\big) \,\geq\, 1-O(\sqrt{\delta_1})\;.
\end{equation}
Since $\omega_W = G_\mC e_i$, $(G_\mC^T c)_i = c\cdot \omega_W$. Thus~\eqref{eq:main-4} shows that $\strategy'$ succeeds with probability $1-O(\sqrt{\delta_1})$ in the $W$-consistency test, as desired. 
\end{proof}



\subsection{The quantum low-degree test}
\label{sec:pbt}

By instantiating $\code$ using the Reed-Muller code from Section~\ref{sec:eff-z2k} we obtain an efficient qubit test.  Because we do not know if $G(h_\bRM)$ is Abelian, we need to introduce an additional test for the relations $\{R_k^\com\}$ in~\eqref{eq:z2k-eff}. The resulting test is described in Figure~\ref{fig:pbt}. It is a variant of a test first introduced in~\cite{natarajan2018low} (with a flawed analysis). This paper (together with the work on which our analysis relies) corrects this. In the next section we detail an important application of this test in the work~\ref{ji2020mip}.

\begin{figure}[!htbp]
  \centering
  \begin{gamespec}
Let $h_\bRM\in \F_2^{M\times N}$ be the parity check matrix for $\code_\bRM$ considered in Section~\ref{sec:eff-z2k}. Here, $N=q^{m+1}$ and $M=q^{m+2}(1+m)$. Let $\mu_R$ be the distribution on relations~\eqref{eq:z2k-eff} described in Section~\ref{sec:eff-z2k}. Execute either of the following tests with probability $1/4$ each. 
    \begin{enumerate}
      \setlength\itemsep{1pt}
    \item \textbf{Code test:} Identical to that in Figure~\ref{fig:braiding-test}.
    \item \textbf{(Anti-)commutation test:} Identical to that in Figure~\ref{fig:braiding-test}.
		 \item \textbf{Consistency test:} Identical to that in Figure~\ref{fig:braiding-test}.
		\item \textbf{Pairwise commutation test:} Sample $(i,i')\in \{1,\ldots,N\}^2$ according to the distribution $\mu_R$, conditioned on choosing a relation from $R_k^\com$, and $W\in \{X,Z\}$ uniformly at random. 	
		Let $\omega=(E_\code e_{i}, E_\code e_{i'})$. 
		Sample a pair of questions $(x_c,y_c)$ as in the commutation game. If either question is $x_{X,0}$ or $x_{Z,0}$, replace it with $(W,\var,i)$ or $(W,\var,i')$ respectively. Otherwise, send the original question together with $\omega$, i.e.\ $(x_c,\omega)$ or $(y_c,\omega)$ respectively. Accept if and only if the players' answers are accepted in the commutation game.  
    \end{enumerate}
  \end{gamespec}
  \caption{The quantum low-degree test, obtained by adapting the braiding test from Figure~\ref{fig:braiding-test} to the $[q^{m+1},t(d+1)^m,D']_2$ code $\code_\bRM$.}
  \label{fig:pbt}
	
\end{figure}


\begin{corollary}[Quantum low-degree test]
Let $\code_\bRM$ be the $[q^{m+1},t(d+1)^m,D']_2$ Reed-Muller from Section~\ref{sec:eff-z2k}, and $M=(h_\bRM,\nu_\bRM)$ the $(d+2)$-local tester for $\code_\bRM$ described in Figure~\ref{fig:bRM-tester}. Then the associated braiding test (Figure~\ref{fig:pbt}) is a $(k,\delta')$-qubit test with error function $\delta' = \poly(m,d,t)\cdot\poly(\eps,q^{-1})$.
\end{corollary}

\begin{proof}
Let $\strategy$ be a synchronous strategy that succeeds in the braiding test with probability at least $1-\eps$. Then in particular the strategy succeeds with probability at least $1-4\eps/3$ in the braiding test over $\code_\bRM$. Since $(\code_\bRM,M)$ is not known to be abelian, we cannot apply Theorem~\ref{thm:braiding} directly. However, we can follow its proof. 

The completeness part of the proof follows in a straightforward manner, since the measurement operators $P^{(W,\var,i)}$ and $P^{(W,\var,i')}$ defined in the proof pairwise commute, for any pair $(i,i')\in \{1,\ldots,N)^2$. 

For the soundness part, we first define the same pair of strategies $\strategy^X$ and $\strategy^Z$ for $G_{\code_\bRM,M}$. Applying Proposition~\ref{prop:rep-game}, we deduce an $O(d\eps)$-homomorphism of the presentation~\eqref{eq:def-gh-pres} of $G(h_\bRM)$. However, we are interested in constructing an approximate homomorphism of the presentation~\eqref{eq:z2k-eff}, which in addition contains the relations $R_k^\com$. The fact that $x_i \mapsto \widehat{P}^{(W,\var,i)}$ satisfies these relations, on average and according to the distribution $\mu_R$, follows from success in the pairwise commutation test executed as part of the Pauli braiding test (Figure~\ref{fig:pbt}). Thus we obtain that $x_i \mapsto \widehat{P}^{(W,\var,i)}$ is an $(O(d\eps),\mu_R)$-homomorphism of the presentation~\eqref{eq:z2k-eff}. Applying Theorem~\ref{thm:z2-stab}, and similarly to the proof of Theorem~\ref{thm:braiding} we obtain a pair of POVMs $\{\tilde{P}^W_u\}_{u\in\F_2^N}$, for $W\in\{X,Z\}$, such that defining $\tilde{P}^{W,i}_b = \sum_{u:u_i=b} \tilde{P}^W_u$ these operators satisfy~\eqref{eq:main-0}, with right-hand side $\delta_2 = \delta(O(d\eps))$, with $\delta$ the soundness function from Theorem~\ref{thm:z2-stab}. From here on the proof proceeds exactly as the proof of Theorem~\ref{thm:braiding}. 
\end{proof}



\subsection{Dimension bounds}



The next proposition states a simple consequence of a qubit test, which is that strategies with a high enough success probability must have a large dimension. This consequence is used in~\cite{ji2020mip}. 

\begin{proposition}
\label{prop:dim-test}
Let $G = (\mX,\mu,\mA,D)$ denote a $(k,\delta(\eps))$-qubit test. Then all synchronous strategies $\strategy$ in $(\mM,\tau)$ for $G$ that succeed with probability $1 - \eps$ must satisfy 
\[
\dim(\mM) \geq \Big( 1 + O(\sqrt{\delta(\eps)}) + \frac{\delta(\eps)}{1 - \delta(\eps)}\Big)^{-1} 2^k~.
\]
\end{proposition}
\begin{proof}
If $\mM$ is infinite-dimensional, then we are done. Suppose instead it were finite-dimensional. Then $\mM$ must be (isomorphic to) a direct sum of finite-dimensional matrix algebras. Without loss of generality we assume that $\mM = M_{d}(\C)$ with the dimension-normalized trace $\tau = \frac{1}{d} \Tr$. 

By the soundness property of qubit tests, the strategy $\strategy$ is $(\delta(\eps),\tilde{\mu})$-close to a strategy $\strategy'$ on an algebra $(M_{2^k}(\C) \otimes \mN,\tr_{2^k} \otimes \tau')$ for some tracial algebra $(\mN,\tau')$ where $\tr_{2^k} = 2^{-k} \Tr$. For notational brevity we write $\mR = M_{2^k}(\C) \otimes \mN$ and $\tau^{\mR} = \tr_{2^k} \otimes \tau'$. By definition there exists a projection $P \in \mM_\infty$ of finite trace and a partial isometry $w \in P \mM_\infty 1_\mM$ satisfying
\begin{enumerate}
	\item $\mR = P \mM_\infty P$. 
	\item $\max \left \{ \tau(1_\mM - w^* w), \tau^{\mR} (P - w w^*) \right \} \leq \delta(\eps)$.
	\item $\tau^{\mR} = \tau_\infty/\tau_\infty(P)$.
\end{enumerate}
%For $W \in \{X,Z\}$ and 
For $u \in \F_2^k$ let $\sigma^Z_u$ denote the projection
\[
	\sigma^Z_u = 2^{-k} \sum_{a \in \F_2^k} (-1)^{a \cdot u} \sigma^Z(a)~.
\]
It is easy to verify that $\{\sigma^Z_u \otimes I_\mN \}_{u \in \F_2^k}$ is a projective measurement in $\mR$ and furthermore $\tau^{\mR}(\sigma^Z_u \otimes I_\mN) = 2^{-k}$. Applying \Cref{lem:pull-back} we get that there exists a projective measurement $\{Q_u\}_{u \in \F_2^k}$ on $\mM$ such that
\[
	\sum_u \| Q_u - w^* (\sigma^Z_u \otimes I_\mN) w \|_2^2 \leq 56\, \delta(\eps)~.
\]
Applying \Cref{lem:l1-l2} we get
\[
	\sum_u \tau \Big ( \Big| Q_u - w^* (\sigma^Z_u \otimes I_\mN) w\Big| \Big) \leq O(\sqrt{\delta(\eps)})~.
\]
Then we have
\begin{align*}
	\sum_u \Big| \tau(Q_u) - 2^{-k} \Big| &\leq \sum_u \Big | \tau(w^* (\sigma^Z_u \otimes I_\mN) w) - 2^{-k} \Big| + \tau \Big ( \Big| Q_u - w^* (\sigma^Z_u \otimes I_\mN) w\Big| \Big) \\
	&= O(\sqrt{\delta(\eps)}) + \sum_u \Big | \tau_\infty (w w^* (\sigma^Z_u \otimes I_\mN)) - 2^{-k} \Big| \\
	&= O(\sqrt{\delta(\eps)}) + \sum_u \Big | \tau_\infty (P (\sigma^Z_u \otimes I_\mN)) - 2^{-k} \Big| + \Big | \tau_\infty((P - ww^*)(\sigma^Z_u \otimes I_\mN)) \Big|
%	&\leq O(\sqrt{\delta(\eps)}) + \sum_u \| P - ww^* \| \tau_\infty( |  \sigma^Z_u \otimes I_\mN |) 
\end{align*}
Notice that $\tau_\infty (P (\sigma^Z_u \otimes I_\mN)) = \tau_\infty (\sigma^Z_u \otimes I_\mN) = 2^{-k}$, and that $ww^* \leq P$ and thus $\tau_\infty((P - ww^*)(\sigma^Z_u \otimes I_\mN))$ is a nonnegative real number. Therefore the sum in the last line simplifies to
\[
\sum_u \tau_\infty((P - ww^*)(\sigma^Z_u \otimes I_\mN)) = \tau_\infty((P - ww^*) P) = \tau_\infty(P - ww^*) \leq \tau_\infty(P) \cdot \delta(\eps)~.
\]
On the other hand the proof of \Cref{lem:pull-back} shows that $\tau_\infty(P) \leq \frac{1}{1 - \delta(\eps)}$, and thus 
\[
\sum_u \Big| \tau(Q_u) - 2^{-k} \Big| \leq O(\sqrt{\delta(\eps)}) + \frac{\delta(\eps)}{1 - \delta(\eps)}~.
\]
By averaging, there exists a $u \in \F_2^k$ such that
\[
\tau(Q_u) = \frac{1}{d} \Tr(Q_u) \leq  \Big( 1 + O(\sqrt{\delta(\eps)}) + \frac{\delta(\eps)}{1 - \delta(\eps)}\Big) 2^{-k}~.
\]
Rearranging, this implies that $d$, the dimension of $\mM$, satisfies
\[
	d \geq \Big( 1 + O(\sqrt{\delta(\eps)}) + \frac{\delta(\eps)}{1 - \delta(\eps)}\Big)^{-1} 2^k
\]
as desired.
\end{proof}




\bibliography{qld}

\notesendofpaper

\end{document}
